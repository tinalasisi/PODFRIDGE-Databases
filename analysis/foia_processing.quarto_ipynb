{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"FOIA Document OCR Processing\"\n",
        "subtitle: \"Processing Murphy & Tong FOIA Documents about State DNA Database Racial Composition\"\n",
        "author: \"Tina Lasisi\"\n",
        "date: today\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 4\n",
        "    toc-expand: 3\n",
        "    toc-location: left   # margin TOC → uses website label\n",
        "    number-sections: true\n",
        "language:\n",
        "  toc-title-website: \"\"  # <- blank kills the “On this page” header\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "---\n",
        "\n",
        "\n",
        "# Overview\n",
        "\n",
        "This document details the processing of Freedom of Information Act (FOIA) responses from seven U.S. states regarding the demographic composition of their State DNA Index System (SDIS) databases. These responses were obtained by Professor Erin Murphy (NYU Law) in 2018 as part of research on racial disparities in DNA databases.\n",
        "\n",
        "# Materials and Methods\n",
        "\n",
        "## Data Sources\n",
        "\n",
        "### Raw FOIA Responses\n",
        "\n",
        "The original FOIA responses are stored in two formats:\n",
        "\n",
        "- **PDFs**: `raw/foia_pdfs/` - Original scanned documents\n",
        "- **HTML**: `raw/foia_html/` - OCR'd versions for easier extraction\n",
        "\n",
        "States included:\n",
        "\n",
        "- California\n",
        "- Florida  \n",
        "- Indiana\n",
        "- Maine\n",
        "- Nevada\n",
        "- South Dakota\n",
        "- Texas\n",
        "\n",
        "## File Structure and Contents\n",
        "\n",
        "### State-Specific Files: `per_state/[state]_foia_data.csv`\n",
        "\n",
        "**Purpose**: Individual files for each state containing only their reported data.\n",
        "\n",
        "**Structure**: Long format with columns:\n",
        "\n",
        "- `state`: State name\n",
        "- `offender_type`: Category of individuals (Convicted Offender, Arrestee, Combined, etc.)\n",
        "- `variable_category`: Type of data (total, gender, race, gender_race)\n",
        "- `variable_detailed`: Specific value (e.g., Male, Female, African American)\n",
        "- `value`: The reported number or percentage\n",
        "- `value_type`: Whether value is a \"count\" or \"percentage\"\n",
        "- `date`: Date of data snapshot, if reported\n",
        "\n",
        "### State Processing\n"
      ],
      "id": "401f150f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Markdown\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Display options\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", None)\n",
        "\n",
        "# Path to per‑state files (run notebook from analysis/)\n",
        "base_dir   = Path(\"..\")\n",
        "per_state  = base_dir / \"output\" / \"foia\" / \"per_state\"\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. Discover available per‑state CSV files\n",
        "# ------------------------------------------------------------------\n",
        "state_files = sorted(per_state.glob(\"*_foia_data.csv\"))\n",
        "\n",
        "if not state_files:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No per‑state FOIA files found in {per_state}. \"\n",
        "        \"Check the folder path.\"\n",
        "    )\n",
        "\n",
        "def stem_to_state(stem: str) -> str:\n",
        "    toks = stem.split(\"_\")\n",
        "    if \"foia\" in toks:\n",
        "        toks = toks[:toks.index(\"foia\")]\n",
        "    return \" \".join(t.title() for t in toks)\n",
        "\n",
        "states_available = [stem_to_state(f.stem) for f in state_files]\n",
        "\n",
        "\n",
        "print(f\"✓ Found {len(state_files)} per‑state files:\")\n",
        "for s in states_available:\n",
        "    print(\"  •\", s)\n",
        "\n",
        "display(Markdown(\n",
        "    f\"**States with data loaded:** {', '.join(states_available)}\"\n",
        "))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. Initialise empty containers for the loop that follows\n",
        "# ------------------------------------------------------------------\n",
        "foia_combined       = pd.DataFrame()   # merged tidy data\n",
        "foia_state_metadata = []               # list of dicts, one per state"
      ],
      "id": "setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing workflow\n",
        "\n",
        "For transparency, each state file is processed independently then merged into a single **combined long‑format table (`foia_combined`)**:\n",
        "\n",
        "1. **Load one file per state** from `output/foia/per_state/`.\n",
        "2. **Append** its rows to `foia_combined`.\n",
        "   A parallel dataframe, **`foia_state_metadata`**, records what each state reported (counts, percentages, which categories) and any state-specific characteristics (e.g. Nevada's \"flags\" terminology).\n",
        "3. **Quality‑check each state**:\n",
        "\n",
        "   * verify that race and gender percentages sum to ≈ 100 % when provided,\n",
        "   * confirm that demographic counts sum to the state's reported total profiles,\n",
        "   * **calculate** any missing counts or percentages and tag those rows `value_source = \"calculated\"`.\n",
        "4. **Save outputs**\n",
        "\n",
        "   * `output/foia/foia_data_clean.csv` — the fully combined tidy table with both reported and calculated values,\n",
        "   * `output/foia/foia_state_metadata.csv` — one row per state summarising coverage and caveats.\n",
        "     After QC passes, I will freeze `foia_data_clean.csv` to `data/v1.0/foia_state_race_v1.0.csv`.\n",
        "\n",
        "\n",
        "## Helper Functions\n",
        "\n",
        "The functions below perform each transformation required for harmonizing the state‑level FOIA tables.  \n",
        "Every step is documented for transparency and reproducibility.\n"
      ],
      "id": "1f6e9e7a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: helpers\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Columns retained from every raw table\n",
        "COLS_NEEDED = [\n",
        "    \"state\", \"offender_type\", \"variable_category\",\n",
        "    \"variable_detailed\", \"value\", \"value_type\"\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. Ingest and numeric coercion\n",
        "# ------------------------------------------------------------------\n",
        "def load_state(path):\n",
        "    \"\"\"\n",
        "    Read a *_foia_data.csv* file, enforce column order,\n",
        "    and convert <1 to 0.5 so that trace counts are retained.\n",
        "    Execution halts if non‑numeric values remain.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    if \"state\" not in df.columns:\n",
        "        df[\"state\"] = (\n",
        "            path.stem.replace(\"_foia_data\", \"\")\n",
        "            .replace(\"_\", \" \").title()\n",
        "        )\n",
        "    df = df[COLS_NEEDED]\n",
        "    df[\"value_source\"] = \"reported\"\n",
        "\n",
        "    df[\"value\"] = (\n",
        "        df[\"value\"].replace({\"<1\": 0.5})\n",
        "        .apply(pd.to_numeric, errors=\"coerce\")\n",
        "    )\n",
        "    nonnumeric = df[df[\"value\"].isna()]\n",
        "    if not nonnumeric.empty:\n",
        "        display(Markdown(f\"**Non‑numeric rows in {path.name}; please amend**\"))\n",
        "        display(nonnumeric)\n",
        "        raise ValueError(\"Numeric coercion failure\")\n",
        "    return df\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. Fill missing Male counts and Unknown race counts\n",
        "# ------------------------------------------------------------------\n",
        "def fill_demographic_gaps(df):\n",
        "    \"\"\"\n",
        "    If exactly one gender or the Unknown race category is absent and\n",
        "    totals permit a residual, calculate and insert the missing count.\n",
        "    \"\"\"\n",
        "    inserts = []\n",
        "    for ot in df.offender_type.unique():\n",
        "        tot = df.query(\n",
        "            \"offender_type == @ot and variable_category == 'total' and \"\n",
        "            \"variable_detailed == 'total_profiles' and value_type == 'count'\"\n",
        "        )\n",
        "        if tot.empty:\n",
        "            continue\n",
        "        total = tot[\"value\"].iat[0]\n",
        "\n",
        "        # gender residual ----------------------------------------------\n",
        "        g = df.query(\n",
        "            \"offender_type == @ot and variable_category == 'gender' and \"\n",
        "            \"value_type == 'count'\"\n",
        "        )\n",
        "        missing_gender = {\"Male\", \"Female\"} - set(g.variable_detailed)\n",
        "        if len(g) == 1 and missing_gender:\n",
        "            inserts.append({\n",
        "                \"state\"            : df.state.iat[0],\n",
        "                \"offender_type\"    : ot,\n",
        "                \"variable_category\": \"gender\",\n",
        "                \"variable_detailed\": missing_gender.pop(),\n",
        "                \"value\"            : total - g.value.sum(),\n",
        "                \"value_type\"       : \"count\",\n",
        "                \"value_source\"     : \"calculated\"\n",
        "            })\n",
        "\n",
        "        # race residual -----------------------------------------------\n",
        "        r = df.query(\n",
        "            \"offender_type == @ot and variable_category == 'race' and \"\n",
        "            \"value_type == 'count'\"\n",
        "        )\n",
        "        if not r.empty and \"Unknown\" not in r.variable_detailed.values:\n",
        "            gap = total - r.value.sum()\n",
        "            if gap > 0:\n",
        "                inserts.append({\n",
        "                    \"state\"            : df.state.iat[0],\n",
        "                    \"offender_type\"    : ot,\n",
        "                    \"variable_category\": \"race\",\n",
        "                    \"variable_detailed\": \"Unknown\",\n",
        "                    \"value\"            : gap,\n",
        "                    \"value_type\"       : \"count\",\n",
        "                    \"value_source\"     : \"calculated\"\n",
        "                })\n",
        "    if inserts:\n",
        "        df = pd.concat([df, pd.DataFrame(inserts)], ignore_index=True)\n",
        "    return df\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3. Construct Combined offender type if absent\n",
        "# ------------------------------------------------------------------\n",
        "def add_combined(df):\n",
        "    \"\"\"\n",
        "    When a state reports Convicted Offender and Arrestee counts but\n",
        "    omits Combined, create a Combined block by summing the two.\n",
        "    \"\"\"\n",
        "    if \"Combined\" in df.offender_type.unique():\n",
        "        return df\n",
        "    required = {\"Convicted Offender\", \"Arrestee\"}\n",
        "    if not required.issubset(df.offender_type.unique()):\n",
        "        return df  # cannot construct\n",
        "\n",
        "    grp_cols = [\"variable_category\", \"variable_detailed\", \"value_type\"]\n",
        "    summed = (\n",
        "        df.query(\"value_type == 'count'\")\n",
        "        .groupby(grp_cols, as_index=False)[\"value\"].sum()\n",
        "    )\n",
        "    summed[\"state\"]         = df.state.iat[0]\n",
        "    summed[\"offender_type\"] = \"Combined\"\n",
        "    summed[\"value_source\"]  = \"calculated\"\n",
        "    return pd.concat([df, summed], ignore_index=True)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 4. Derive percentages wherever only counts exist\n",
        "# ------------------------------------------------------------------\n",
        "def add_percentages(df):\n",
        "    \"\"\"\n",
        "    Ensure that every gender and race row has both count and percentage\n",
        "    values, derived from the offender‑type total if necessary.\n",
        "    \"\"\"\n",
        "    totals = (\n",
        "        df.query(\n",
        "            \"variable_category == 'total' and \"\n",
        "            \"variable_detailed == 'total_profiles' and \"\n",
        "            \"value_type == 'count'\"\n",
        "        )\n",
        "        .set_index(\"offender_type\")[\"value\"]\n",
        "        .to_dict()\n",
        "    )\n",
        "    new_pct_rows = []\n",
        "    need_pct = df.query(\n",
        "        \"value_type == 'count' and variable_category != 'total'\"\n",
        "    )\n",
        "    for _, row in need_pct.iterrows():\n",
        "        exists = df[\n",
        "            (df.state == row.state) &\n",
        "            (df.offender_type == row.offender_type) &\n",
        "            (df.variable_category == row.variable_category) &\n",
        "            (df.variable_detailed == row.variable_detailed) &\n",
        "            (df.value_type == \"percentage\")\n",
        "        ]\n",
        "        if not exists.empty:\n",
        "            continue\n",
        "        pct_value = round(\n",
        "            row.value / totals[row.offender_type] * 100, 2\n",
        "        )\n",
        "        new_pct_rows.append({\n",
        "            **row,\n",
        "            \"value\"       : pct_value,\n",
        "            \"value_type\"  : \"percentage\",\n",
        "            \"value_source\": \"calculated\"\n",
        "        })\n",
        "    if new_pct_rows:\n",
        "        df = pd.concat([df, pd.DataFrame(new_pct_rows)], ignore_index=True)\n",
        "    return df\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 5. Quality‑control utilities\n",
        "# ------------------------------------------------------------------\n",
        "def counts_consistent(df):\n",
        "    \"\"\"\n",
        "    Verifies that demographic counts sum to total_profiles for each\n",
        "    offender type and category.\n",
        "    \"\"\"\n",
        "    demo_sum = (\n",
        "        df.query(\"value_type == 'count' and variable_category != 'total'\")\n",
        "        .groupby([\"offender_type\", \"variable_category\"])[\"value\"]\n",
        "        .sum()\n",
        "    )\n",
        "    totals = (\n",
        "        df.query(\n",
        "            \"variable_category == 'total' and \"\n",
        "            \"variable_detailed == 'total_profiles' and \"\n",
        "            \"value_type == 'count'\"\n",
        "        )\n",
        "        .set_index(\"offender_type\")[\"value\"]\n",
        "    )\n",
        "    return all(\n",
        "        abs(demo_sum.loc[idx] - totals[idx[0]]) < 1e-6\n",
        "        for idx in demo_sum.index\n",
        "    )\n",
        "\n",
        "def percentages_consistent(df):\n",
        "    \"\"\"\n",
        "    Verifies that derived or reported percentages sum to 100 ± 0.5 %.\n",
        "    \"\"\"\n",
        "    for (ot, cat), grp in df.query(\n",
        "        \"value_type == 'percentage'\"\n",
        "    ).groupby([\"offender_type\", \"variable_category\"]):\n",
        "        if abs(grp.value.sum() - 100) > 0.5:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "## Helper Functions\n",
        "\n",
        "```{python}\n",
        "#| label: helper-functions\n",
        "#| echo: true\n",
        "\n",
        "# Define columns needed for foia_combined\n",
        "COLUMNS_NEEDED = ['state', 'offender_type', 'variable_category', \n",
        "                  'variable_detailed', 'value', 'value_type']\n",
        "\n",
        "def report_status(df, category):\n",
        "    values = df.loc[df[\"variable_category\"] == category, \"value_type\"].unique()\n",
        "    if {\"count\", \"percentage\"}.issubset(values):\n",
        "        return \"both\"\n",
        "    elif \"count\" in values:\n",
        "        return \"counts\"\n",
        "    elif \"percentage\" in values:\n",
        "        return \"percentages\"\n",
        "    else:\n",
        "        return \"neither\"\n",
        "\n",
        "def verify_category_totals(df):\n",
        "    \"\"\"\n",
        "    For every offender_type × variable_category pair:\n",
        "      • find the reported total_profiles,\n",
        "      • sum all count rows in that category,\n",
        "      • return the difference.\n",
        "    \"\"\"\n",
        "    # 1  pull total_profiles per offender_type\n",
        "    total_map = (df[(df[\"variable_category\"] == \"total\") &\n",
        "                    (df[\"variable_detailed\"] == \"total_profiles\")]\n",
        "                 .set_index(\"offender_type\")[\"value\"]\n",
        "                 .to_dict())\n",
        "\n",
        "    # 2  sum counts by offender_type and variable_category\n",
        "    demo_sum = (df[(df[\"value_type\"] == \"count\") &\n",
        "                   (df[\"variable_category\"] != \"total\")]\n",
        "                .groupby([\"offender_type\", \"variable_category\"])[\"value\"]\n",
        "                .sum()\n",
        "                .rename(\"sum_demo_counts\")\n",
        "                .reset_index())\n",
        "\n",
        "    # 3  attach total_profiles and compute difference\n",
        "    demo_sum[\"total_profiles\"] = demo_sum[\"offender_type\"].map(total_map)\n",
        "    demo_sum[\"difference\"] = demo_sum[\"total_profiles\"] - demo_sum[\"sum_demo_counts\"]\n",
        "\n",
        "    # tidy columns order\n",
        "    return demo_sum[[\"offender_type\",\n",
        "                     \"variable_category\",\n",
        "                     \"total_profiles\",\n",
        "                     \"sum_demo_counts\",\n",
        "                     \"difference\"]]\n",
        "\n",
        "def calculate_combined_totals(df, state_name):\n",
        "    \"\"\"\n",
        "    Calculate Combined totals by summing across offender types.\n",
        "    Returns a dataframe of Combined rows to add.\n",
        "    \"\"\"\n",
        "    # Get all counts\n",
        "    counts_df = df[(df['value_type'] == 'count')].copy()\n",
        "    \n",
        "    # Group by variable_category and variable_detailed, sum values\n",
        "    combined_sums = (counts_df.groupby(['variable_category', 'variable_detailed'])['value']\n",
        "                     .sum()\n",
        "                     .reset_index())\n",
        "    \n",
        "    # Create Combined rows\n",
        "    combined_rows = []\n",
        "    for _, row in combined_sums.iterrows():\n",
        "        combined_rows.append({\n",
        "            'state': state_name,\n",
        "            'offender_type': 'Combined',\n",
        "            'variable_category': row['variable_category'],\n",
        "            'variable_detailed': row['variable_detailed'],\n",
        "            'value': row['value'],\n",
        "            'value_type': 'count',\n",
        "            'value_source': 'calculated'\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(combined_rows)\n",
        "\n",
        "\n",
        "def calculate_percentages(df_combined, state_name):\n",
        "    \"\"\"\n",
        "    Calculate percentages for all demographic categories.\n",
        "    Returns a dataframe of percentage rows to add.\n",
        "    \"\"\"\n",
        "    # Get total profiles for each offender type\n",
        "    totals_map = (df_combined[\n",
        "        (df_combined['state'] == state_name) &\n",
        "        (df_combined['variable_category'] == 'total') &\n",
        "        (df_combined['variable_detailed'] == 'total_profiles')\n",
        "    ].set_index('offender_type')['value'].to_dict())\n",
        "    \n",
        "    percentage_rows = []\n",
        "    \n",
        "    for offender_type, total in totals_map.items():\n",
        "        # Get all demographic counts\n",
        "        demo_data = df_combined[\n",
        "            (df_combined['state'] == state_name) &\n",
        "            (df_combined['offender_type'] == offender_type) &\n",
        "            (df_combined['variable_category'].isin(['gender', 'race'])) &\n",
        "            (df_combined['value_type'] == 'count')\n",
        "        ]\n",
        "        \n",
        "        # Calculate percentage for each\n",
        "        for _, row in demo_data.iterrows():\n",
        "            percentage = (row['value'] / total) * 100\n",
        "            percentage_rows.append({\n",
        "                'state': state_name,\n",
        "                'offender_type': offender_type,\n",
        "                'variable_category': row['variable_category'],\n",
        "                'variable_detailed': row['variable_detailed'],\n",
        "                'value': round(percentage, 2),\n",
        "                'value_type': 'percentage',\n",
        "                'value_source': 'calculated'\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(percentage_rows)\n",
        "\n",
        "\n",
        "def calculate_counts_from_percentages(df_combined, state_name):\n",
        "    \"\"\"\n",
        "    Calculate counts from percentages when only percentages are provided.\n",
        "    Returns a dataframe of count rows to add.\n",
        "    \"\"\"\n",
        "    # Get total profiles for each offender type\n",
        "    totals_map = (df_combined[\n",
        "        (df_combined['state'] == state_name) &\n",
        "        (df_combined['variable_category'] == 'total') &\n",
        "        (df_combined['variable_detailed'] == 'total_profiles')\n",
        "    ].set_index('offender_type')['value'].to_dict())\n",
        "    \n",
        "    count_rows = []\n",
        "    \n",
        "    for offender_type, total in totals_map.items():\n",
        "        # Get all demographic percentages\n",
        "        demo_data = df_combined[\n",
        "            (df_combined['state'] == state_name) &\n",
        "            (df_combined['offender_type'] == offender_type) &\n",
        "            (df_combined['variable_category'].isin(['gender', 'race'])) &\n",
        "            (df_combined['value_type'] == 'percentage')\n",
        "        ]\n",
        "        \n",
        "        # Calculate count for each\n",
        "        for _, row in demo_data.iterrows():\n",
        "            count = round(total * (row['value'] / 100))\n",
        "            count_rows.append({\n",
        "                'state': state_name,\n",
        "                'offender_type': offender_type,\n",
        "                'variable_category': row['variable_category'],\n",
        "                'variable_detailed': row['variable_detailed'],\n",
        "                'value': int(count),\n",
        "                'value_type': 'count',\n",
        "                'value_source': 'calculated'\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(count_rows)\n",
        "\n",
        "\n",
        "def standardize_offender_types(df):\n",
        "    \"\"\"\n",
        "    Standardize offender type terminology across states.\n",
        "    \"\"\"\n",
        "    replacements = {\n",
        "        'Offenders': 'Convicted Offender',\n",
        "        'Convicted offenders': 'Convicted Offender',\n",
        "        'Arrested offender': 'Arrestee',\n",
        "        'All': 'Combined'\n",
        "    }\n",
        "    \n",
        "    df = df.copy()\n",
        "    df['offender_type'] = df['offender_type'].replace(replacements)\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_state_for_combined(df, state_name):\n",
        "    \"\"\"\n",
        "    Prepare state data for appending to foia_combined.\n",
        "    Selects only needed columns and adds value_source if missing.\n",
        "    \"\"\"\n",
        "    df_prepared = df[COLUMNS_NEEDED].copy()\n",
        "    \n",
        "    # Add value_source if not present\n",
        "    if 'value_source' not in df_prepared.columns:\n",
        "        df_prepared['value_source'] = 'reported'\n",
        "    else:\n",
        "        df_prepared['value_source'] = df_prepared['value_source'].fillna('reported')\n",
        "    \n",
        "    return df_prepared\n",
        "\n",
        "\n",
        "def format_compact(x, p=None):\n",
        "    \"\"\"\n",
        "    Format numbers in compact notation (k for thousands, M for millions).\n",
        "    \n",
        "    Args:\n",
        "        x: The number to format\n",
        "        p: Position parameter (not used, but kept for compatibility with matplotlib)\n",
        "    \n",
        "    Returns:\n",
        "        Formatted string with k/M suffix\n",
        "    \"\"\"\n",
        "    if x >= 1000000:\n",
        "        # For millions, show one decimal place if not a whole million\n",
        "        return f'{x/1000000:.1f}M' if x/1000000 != int(x/1000000) else f'{int(x/1000000)}M'\n",
        "    elif x >= 1000:\n",
        "        # For thousands, always show as integer\n",
        "        return f'{int(x/1000)}k'\n",
        "    else:\n",
        "        # For values under 1000, show as integer\n",
        "        return f'{int(x)}'\n",
        "\n",
        "\n",
        "def create_state_visualizations(df_combined, state_name):\n",
        "    \"\"\"\n",
        "    Create count and percentage pie charts for a state.\n",
        "    \"\"\"\n",
        "    state_data = df_combined[df_combined['state'] == state_name]\n",
        "    \n",
        "    # Determine offender types for this state\n",
        "    offender_types = sorted(state_data['offender_type'].unique())\n",
        "    n_types = len(offender_types)\n",
        "    \n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(4, n_types, figsize=(5*n_types, 16))\n",
        "    if n_types == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "    \n",
        "    fig.suptitle(f'{state_name} DNA Database Demographics - Counts and Percentages', fontsize=18)\n",
        "    \n",
        "    # Create pie charts for each metric\n",
        "    for i, offender_type in enumerate(offender_types):\n",
        "        # Gender counts\n",
        "        create_pie_chart(axes[0, i], state_data, offender_type, 'gender', 'count', \n",
        "                        f'{offender_type}\\nGender Counts', show_values=True)\n",
        "        \n",
        "        # Gender percentages\n",
        "        create_pie_chart(axes[1, i], state_data, offender_type, 'gender', 'percentage',\n",
        "                        f'{offender_type}\\nGender Percentages')\n",
        "        \n",
        "        # Race counts\n",
        "        create_pie_chart(axes[2, i], state_data, offender_type, 'race', 'count',\n",
        "                        f'{offender_type}\\nRace Counts', show_values=True)\n",
        "        \n",
        "        # Race percentages\n",
        "        create_pie_chart(axes[3, i], state_data, offender_type, 'race', 'percentage',\n",
        "                        f'{offender_type}\\nRace Percentages')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Display count summary\n",
        "    print(f\"\\n{state_name} profile counts by offender type:\")\n",
        "    count_summary = state_data[\n",
        "        (state_data['variable_category'] == 'total') &\n",
        "        (state_data['variable_detailed'] == 'total_profiles') &\n",
        "        (state_data['value_type'] == 'count')\n",
        "    ][['offender_type', 'value']].set_index('offender_type')\n",
        "    count_summary.columns = ['Total Profiles']\n",
        "    count_summary['Total Profiles'] = count_summary['Total Profiles'].apply(lambda x: f\"{x:,}\")\n",
        "    display(count_summary)\n",
        "\n",
        "\n",
        "def create_pie_chart(ax, data, offender_type, category, value_type, title, show_values=False):\n",
        "    \"\"\"\n",
        "    Helper to create a single pie chart.\n",
        "    \"\"\"\n",
        "    chart_data = data[\n",
        "        (data['offender_type'] == offender_type) &\n",
        "        (data['variable_category'] == category) &\n",
        "        (data['value_type'] == value_type)\n",
        "    ].sort_values('value', ascending=False)\n",
        "    \n",
        "    if len(chart_data) > 0:\n",
        "        if show_values and value_type == 'count':\n",
        "            labels = [f\"{row['variable_detailed']}\\n({row['value']:,.0f})\" \n",
        "                     for _, row in chart_data.iterrows()]\n",
        "        else:\n",
        "            labels = chart_data['variable_detailed']\n",
        "        \n",
        "        colors = plt.cm.Set3(range(len(chart_data)))\n",
        "        wedges, texts, autotexts = ax.pie(chart_data['value'], \n",
        "                                          labels=labels,\n",
        "                                          autopct='%1.1f%%',\n",
        "                                          startangle=90,\n",
        "                                          colors=colors)\n",
        "        \n",
        "        # Adjust text size for readability\n",
        "        for text in texts:\n",
        "            text.set_fontsize(10 if category == 'race' else 11)\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_fontsize(10)\n",
        "            \n",
        "        ax.set_title(title)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_title(title)\n",
        "\n",
        "\n",
        "def verify_percentage_consistency(df_combined, state_name):\n",
        "    \"\"\"\n",
        "    Verify that reported percentages match calculated percentages (within tolerance).\n",
        "    Returns True if consistent, False otherwise.\n",
        "    \"\"\"\n",
        "    state_data = df_combined[df_combined['state'] == state_name]\n",
        "    \n",
        "    # Get all offender types that have both counts and percentages\n",
        "    offender_types = state_data['offender_type'].unique()\n",
        "    \n",
        "    consistency_results = []\n",
        "    \n",
        "    for offender_type in offender_types:\n",
        "        offender_data = state_data[state_data['offender_type'] == offender_type]\n",
        "        \n",
        "        # Check if we have both reported and calculated percentages\n",
        "        for category in ['gender', 'race']:\n",
        "            reported_pcts = offender_data[\n",
        "                (offender_data['variable_category'] == category) &\n",
        "                (offender_data['value_type'] == 'percentage') &\n",
        "                (offender_data['value_source'] == 'reported')\n",
        "            ]\n",
        "            \n",
        "            calculated_pcts = offender_data[\n",
        "                (offender_data['variable_category'] == category) &\n",
        "                (offender_data['value_type'] == 'percentage') &\n",
        "                (offender_data['value_source'] == 'calculated')\n",
        "            ]\n",
        "            \n",
        "            if len(reported_pcts) > 0 and len(calculated_pcts) > 0:\n",
        "                # Compare each demographic value\n",
        "                for _, rep_row in reported_pcts.iterrows():\n",
        "                    calc_match = calculated_pcts[\n",
        "                        calculated_pcts['variable_detailed'] == rep_row['variable_detailed']\n",
        "                    ]\n",
        "                    if len(calc_match) > 0:\n",
        "                        diff = abs(rep_row['value'] - calc_match.iloc[0]['value'])\n",
        "                        consistency_results.append({\n",
        "                            'offender_type': offender_type,\n",
        "                            'category': category,\n",
        "                            'variable': rep_row['variable_detailed'],\n",
        "                            'reported': rep_row['value'],\n",
        "                            'calculated': calc_match.iloc[0]['value'],\n",
        "                            'difference': diff,\n",
        "                            'consistent': diff < 0.5  # 0.5% tolerance\n",
        "                        })\n",
        "    \n",
        "    if consistency_results:\n",
        "        consistency_df = pd.DataFrame(consistency_results)\n",
        "        print(f\"\\nPercentage consistency check for {state_name}:\")\n",
        "        print(f\"All values consistent: {consistency_df['consistent'].all()}\")\n",
        "        \n",
        "        if not consistency_df['consistent'].all():\n",
        "            print(\"\\nInconsistent values:\")\n",
        "            display(consistency_df[~consistency_df['consistent']])\n",
        "        \n",
        "        return consistency_df['consistent'].all()\n",
        "    else:\n",
        "        # No comparison possible - state only has one type of data\n",
        "        return True\n",
        "\n",
        "\n",
        "def create_demographic_bar_charts(df_combined, state_name):\n",
        "    \"\"\"\n",
        "    Create clean bar charts showing demographics by offender type.\n",
        "    Uses counts for exact values and includes percentage labels.\n",
        "    \"\"\"\n",
        "    state_data = df_combined[df_combined['state'] == state_name]\n",
        "    \n",
        "    # Get offender types and ensure Combined is last\n",
        "    offender_types = sorted(state_data[state_data['value_type'] == 'count']['offender_type'].unique())\n",
        "    if 'Combined' in offender_types:\n",
        "        offender_types.remove('Combined')\n",
        "        offender_types.append('Combined')\n",
        "    \n",
        "    # Create figure with side-by-side subplots for gender and race\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'{state_name} DNA Database Demographics', fontsize=20, fontweight='bold', y=1.01)\n",
        "    \n",
        "    # Color palettes - using a modern, visually appealing palette\n",
        "    gender_colors = {'Male': '#4E79A7', 'Female': '#E15759'}\n",
        "    race_colors = {\n",
        "        'White': '#4E79A7',\n",
        "        'African American': '#F28E2B', \n",
        "        'Hispanic': '#E15759',\n",
        "        'Asian': '#76B7B2',\n",
        "        'Native American': '#59A14F',\n",
        "        'Unknown': '#AF7AA1',\n",
        "        'Other': '#9C755F'\n",
        "    }\n",
        "    \n",
        "    # Gender subplot - horizontal bars\n",
        "    ax1.set_title('Gender Distribution', fontsize=18, pad=15)\n",
        "    gender_data = state_data[\n",
        "        (state_data['variable_category'] == 'gender') &\n",
        "        (state_data['value_type'] == 'count')\n",
        "    ]\n",
        "    \n",
        "    # Prepare data for grouped horizontal bars\n",
        "    y_positions = np.arange(len(offender_types))\n",
        "    bar_height = 0.35\n",
        "    \n",
        "    # Process each gender\n",
        "    for i, gender in enumerate(['Female', 'Male']):  # Female first to be on top\n",
        "        values = []\n",
        "        percentages = []\n",
        "        \n",
        "        for offender_type in offender_types:\n",
        "            # Get count\n",
        "            count_val = gender_data[\n",
        "                (gender_data['offender_type'] == offender_type) &\n",
        "                (gender_data['variable_detailed'] == gender)\n",
        "            ]['value'].values\n",
        "            \n",
        "            # Get percentage\n",
        "            pct_val = state_data[\n",
        "                (state_data['offender_type'] == offender_type) &\n",
        "                (state_data['variable_detailed'] == gender) &\n",
        "                (state_data['variable_category'] == 'gender') &\n",
        "                (state_data['value_type'] == 'percentage')\n",
        "            ]['value'].values\n",
        "            \n",
        "            values.append(count_val[0] if len(count_val) > 0 else 0)\n",
        "            percentages.append(pct_val[0] if len(pct_val) > 0 else 0)\n",
        "        \n",
        "        # Plot horizontal bars\n",
        "        positions = y_positions + bar_height * (i - 0.5)\n",
        "        bars = ax1.barh(positions, values, bar_height, label=gender, \n",
        "                        color=gender_colors.get(gender, '#333333'))\n",
        "        \n",
        "        # Add count and percentage labels to the right of bars\n",
        "        for bar, pct, val in zip(bars, percentages, values):\n",
        "            width = bar.get_width()\n",
        "            if width > 0:\n",
        "                # Put percentage and count to the right of the bar\n",
        "                ax1.text(width, bar.get_y() + bar.get_height()/2,\n",
        "                        f'  {pct:.1f}% ({int(val):,})', ha='left', va='center', fontsize=14)\n",
        "    \n",
        "    ax1.set_xlabel('Number of Profiles', fontsize=16)\n",
        "    ax1.set_yticks(y_positions)\n",
        "    ax1.set_yticklabels(offender_types, fontsize=14)\n",
        "    ax1.legend(loc='upper right', fontsize=12)\n",
        "    # Remove grid lines and spines for cleaner look\n",
        "    ax1.spines['top'].set_visible(False)\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "    # Add some padding to x-axis for labels\n",
        "    ax1.set_xlim(0, max([v for sublist in [gender_data[\n",
        "        (gender_data['offender_type'] == ot) &\n",
        "        (gender_data['variable_detailed'].isin(['Male', 'Female']))\n",
        "    ]['value'].values for ot in offender_types] for v in sublist]) * 1.25)\n",
        "    \n",
        "    # Format x-axis with compact notation (k for thousands, M for millions)\n",
        "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(format_compact))\n",
        "    ax1.tick_params(axis='x', labelsize=12)\n",
        "    ax1.invert_yaxis()  # Invert y-axis to have first offender type at top\n",
        "    \n",
        "    # Race subplot - horizontal bars\n",
        "    ax2.set_title('Race Distribution', fontsize=18, pad=15)\n",
        "    race_data = state_data[\n",
        "        (state_data['variable_category'] == 'race') &\n",
        "        (state_data['value_type'] == 'count')\n",
        "    ]\n",
        "    \n",
        "    # Get all unique races for this state\n",
        "    races = sorted(race_data['variable_detailed'].unique())\n",
        "    \n",
        "    # Adjust bar height based on number of races\n",
        "    race_height = min(0.8 / len(races), 0.15)  # Cap at 0.15 to prevent too thick bars\n",
        "    \n",
        "    # Create race positions for grouping\n",
        "    for i, race in enumerate(races):\n",
        "        values = []\n",
        "        percentages = []\n",
        "        \n",
        "        for offender_type in offender_types:\n",
        "            # Get count\n",
        "            count_val = race_data[\n",
        "                (race_data['offender_type'] == offender_type) &\n",
        "                (race_data['variable_detailed'] == race)\n",
        "            ]['value'].values\n",
        "            \n",
        "            # Get percentage\n",
        "            pct_val = state_data[\n",
        "                (state_data['offender_type'] == offender_type) &\n",
        "                (state_data['variable_detailed'] == race) &\n",
        "                (state_data['variable_category'] == 'race') &\n",
        "                (state_data['value_type'] == 'percentage')\n",
        "            ]['value'].values\n",
        "            \n",
        "            values.append(count_val[0] if len(count_val) > 0 else 0)\n",
        "            percentages.append(pct_val[0] if len(pct_val) > 0 else 0)\n",
        "        \n",
        "        # Plot horizontal bars\n",
        "        positions = y_positions + race_height * (i - len(races)/2 + 0.5)\n",
        "        bars = ax2.barh(positions, values, race_height, label=race,\n",
        "                        color=race_colors.get(race, '#333333'))\n",
        "        \n",
        "        # Add count and percentage labels to the right of bars\n",
        "        for bar, pct, val in zip(bars, percentages, values):\n",
        "            width = bar.get_width()\n",
        "            if width > 0:\n",
        "                # Put percentage and count to the right of the bar\n",
        "                ax2.text(width, bar.get_y() + bar.get_height()/2,\n",
        "                        f'  {pct:.1f}% ({int(val):,})', ha='left', va='center', fontsize=12)\n",
        "    \n",
        "    ax2.set_xlabel('Number of Profiles', fontsize=16)\n",
        "    ax2.set_yticks(y_positions)\n",
        "    ax2.set_yticklabels(offender_types, fontsize=14)\n",
        "    ax2.legend(loc='upper right', ncol=1, fontsize=11)\n",
        "    # Remove grid lines and spines for cleaner look\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "    ax2.spines['right'].set_visible(False)\n",
        "    # Add some padding to x-axis for labels\n",
        "    ax2.set_xlim(0, max([v for sublist in [race_data[\n",
        "        race_data['offender_type'] == ot\n",
        "    ]['value'].values for ot in offender_types] for v in sublist if v > 0]) * 1.25)\n",
        "    \n",
        "    # Format x-axis with compact notation (k for thousands, M for millions)\n",
        "    ax2.xaxis.set_major_formatter(plt.FuncFormatter(format_compact))\n",
        "    ax2.tick_params(axis='x', labelsize=12)\n",
        "    ax2.invert_yaxis()  # Invert y-axis to have first offender type at top\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Also display a summary table with totals\n",
        "    print(f\"\\n{state_name} profile totals by offender type:\")\n",
        "    totals_data = state_data[\n",
        "        (state_data['variable_category'] == 'total') &\n",
        "        (state_data['variable_detailed'] == 'total_profiles') &\n",
        "        (state_data['value_type'] == 'count')\n",
        "    ][['offender_type', 'value']].copy()\n",
        "    totals_data['value'] = totals_data['value'].apply(lambda x: f\"{int(x):,}\")\n",
        "    totals_data.columns = ['Offender Type', 'Total Profiles']\n",
        "    display(totals_data.set_index('Offender Type'))"
      ],
      "id": "helpers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyses\n",
        "\n",
        "## California\n"
      ],
      "id": "4b5b2aa0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-load-preview\n",
        "#| echo: true\n",
        "\n",
        "ca_path = per_state / \"california_foia_data.csv\"\n",
        "ca      = pd.read_csv(ca_path)\n",
        "\n",
        "display(ca)"
      ],
      "id": "ca-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin by loading California's file. California supplies **counts only** for gender and race plus a separate total for each offender type; no percentages are reported.\n",
        "\n",
        "Recording California's reporting structure:\n"
      ],
      "id": "95717dcf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"California\",\n",
        "    \"race_report_values\":   report_status(ca, \"race\"),\n",
        "    \"gender_report_values\": report_status(ca, \"gender\")\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "ca-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying that demographic counts match reported totals\n",
        "\n",
        "Using the `verify_category_totals` helper function:\n"
      ],
      "id": "e6e80731"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-run-category-verify\n",
        "#| echo: true\n",
        "\n",
        "ca_category_qc = verify_category_totals(ca)\n",
        "ca_category_qc"
      ],
      "id": "ca-run-category-verify",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpreting the race shortfall\n",
        "\n",
        "> *\"Racial classification is not considered a required field on the collection card; thus, an unknown number of offenders may have **no racial classification listed**.\"*\n",
        "> — California DOJ FOIA letter, July 10 2018 (`raw/foia_pdfs/FOIA_RacialComp_California.pdf`)\n",
        "\n",
        "The 393  887 Convicted‑Offender profiles and 96  127 Arrestee profiles that do **not** appear in any of the four reported race categories must therefore belong to an unreported \"Unknown/Other\" bucket. To keep row totals consistent and enable percentage calculations later, we add one new race row per offender type:\n",
        "\n",
        "* `variable_category = \"race\"`\n",
        "* `variable_detailed = \"Unknown\"`\n",
        "* `value_type = \"count\"`\n",
        "* `value_source = \"calculated\"`\n"
      ],
      "id": "a09d129e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-insert-unknown\n",
        "#| echo: true\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1.  Remove any prior Unknown‑race rows \n",
        "# ------------------------------------------------------------------\n",
        "ca = ca[~(\n",
        "    (ca[\"variable_category\"] == \"race\") &\n",
        "    (ca[\"variable_detailed\"] == \"Unknown\")\n",
        ")].copy()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2.  Add one Unknown‑race row per offender type\n",
        "# ------------------------------------------------------------------\n",
        "unknown_rows = pd.DataFrame([\n",
        "    {\n",
        "        \"state\": \"California\",\n",
        "        \"offender_type\": \"Convicted Offender\",\n",
        "        \"variable_category\": \"race\",\n",
        "        \"variable_detailed\": \"Unknown\",\n",
        "        \"value\": 393887,           \n",
        "        \"value_type\": \"count\",\n",
        "        \"value_source\": \"calculated\",\n",
        "    },\n",
        "    {\n",
        "        \"state\": \"California\",\n",
        "        \"offender_type\": \"Arrestee\",\n",
        "        \"variable_category\": \"race\",\n",
        "        \"variable_detailed\": \"Unknown\",\n",
        "        \"value\": 96127,\n",
        "        \"value_type\": \"count\",\n",
        "        \"value_source\": \"calculated\",\n",
        "    },\n",
        "])\n",
        "\n",
        "ca = pd.concat([ca, unknown_rows], ignore_index=True)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3.  Confirm race and gender now reconcile to totals\n",
        "# ------------------------------------------------------------------\n",
        "print(\"Category‑level check after adding Unknown rows:\")\n",
        "display(verify_category_totals(ca))"
      ],
      "id": "ca-insert-unknown",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Combined totals\n",
        "\n",
        "California reported data separately for Convicted Offenders and Arrestees. Combined totals are calculated by summing across both offender types for all categories and demographic values.\n"
      ],
      "id": "ce3bc6d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-create-combined\n",
        "#| echo: true\n",
        "\n",
        "# Calculate Combined totals using helper function\n",
        "combined_df = calculate_combined_totals(ca, \"California\")\n",
        "\n",
        "# Add Combined rows to ca\n",
        "ca = pd.concat([ca, combined_df], ignore_index=True)\n",
        "\n",
        "print(\"✓ Created Combined totals for California\")\n",
        "print(f\"  Combined total profiles: {combined_df[combined_df['variable_detailed'] == 'total_profiles']['value'].values[0]:,}\")\n",
        "\n",
        "# Display Combined gender counts\n",
        "print(\"\\nCombined gender counts:\")\n",
        "display(combined_df[combined_df['variable_category'] == 'gender'].sort_values('variable_detailed'))\n",
        "\n",
        "# Display Combined race counts  \n",
        "print(\"\\nCombined race counts:\")\n",
        "display(combined_df[combined_df['variable_category'] == 'race'].sort_values('variable_detailed'))\n",
        "\n",
        "# Verify Combined calculations\n",
        "print(\"\\n✓ Verification of Combined calculations:\")\n",
        "\n",
        "# Get counts dataframe for verification\n",
        "counts_df = ca[(ca['value_type'] == 'count') & (ca['offender_type'] != 'Combined')].copy()\n",
        "\n",
        "conv_total = counts_df[(counts_df['offender_type'] == 'Convicted Offender') & \n",
        "                       (counts_df['variable_detailed'] == 'total_profiles')]['value'].values[0]\n",
        "arr_total = counts_df[(counts_df['offender_type'] == 'Arrestee') & \n",
        "                      (counts_df['variable_detailed'] == 'total_profiles')]['value'].values[0]\n",
        "comb_total = combined_df[combined_df['variable_detailed'] == 'total_profiles']['value'].values[0]\n",
        "\n",
        "print(f\"  Convicted Offender total: {conv_total:,}\")\n",
        "print(f\"  Arrestee total: {arr_total:,}\")\n",
        "print(f\"  Sum: {conv_total + arr_total:,}\")\n",
        "print(f\"  Combined total: {comb_total:,}\")\n",
        "print(f\"  Match: {conv_total + arr_total == comb_total}\")"
      ],
      "id": "ca-create-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing California data for the combined dataset\n",
        "\n",
        "The California data requires selection of specific columns for inclusion in the combined dataset.\n"
      ],
      "id": "698a8627"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Create California data for foia_combined with only needed columns\n",
        "# ------------------------------------------------------------------\n",
        "# Select existing California data with the columns we want\n",
        "ca_for_combined = ca[['state', 'offender_type', 'variable_category', \n",
        "                      'variable_detailed', 'value', 'value_type']].copy()\n",
        "\n",
        "# Add value_source column\n",
        "ca_for_combined['value_source'] = 'reported'\n",
        "\n",
        "# Update value_source for calculated rows (Unknown race and Combined totals)\n",
        "ca_for_combined.loc[\n",
        "    ((ca_for_combined['variable_category'] == 'race') & \n",
        "     (ca_for_combined['variable_detailed'] == 'Unknown')) |\n",
        "    (ca_for_combined['offender_type'] == 'Combined'), \n",
        "    'value_source'\n",
        "] = 'calculated'\n",
        "\n",
        "# Display sample of data structure\n",
        "print(\"California data structure verification:\")\n",
        "print(f\"Unique offender types: {ca_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {ca_for_combined['variable_category'].unique()}\")\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, ca_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(ca_for_combined)} California rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "ca-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating percentages\n",
        "\n",
        "California provided only counts. For comparative analysis, percentages are calculated for each demographic category as the proportion of each demographic value relative to the total profiles for that offender type.\n"
      ],
      "id": "1dfd5484"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: ca-calculate-percentages\n",
        "#| echo: true\n",
        "\n",
        "# Calculate percentages using helper function\n",
        "percentages_df = calculate_percentages(foia_combined, \"California\")\n",
        "\n",
        "# Add percentages to foia_combined\n",
        "foia_combined = pd.concat([foia_combined, percentages_df], ignore_index=True)\n",
        "\n",
        "print(f\"✓ Calculated and added {len(percentages_df)} percentage rows for California\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")\n",
        "\n",
        "# Display the actual percentage values\n",
        "print(\"\\nGender percentages by offender type:\")\n",
        "gender_pct = percentages_df[percentages_df['variable_category'] == 'gender'].pivot_table(\n",
        "    index='variable_detailed', columns='offender_type', values='value'\n",
        ")\n",
        "display(gender_pct)\n",
        "\n",
        "print(\"\\nRace percentages by offender type:\")\n",
        "race_pct = percentages_df[percentages_df['variable_category'] == 'race'].pivot_table(\n",
        "    index='variable_detailed', columns='offender_type', values='value'\n",
        ")\n",
        "display(race_pct)\n",
        "\n",
        "# Verify percentages sum to approximately 100% for each category\n",
        "print(\"\\nVerification of percentage totals by category:\")\n",
        "verification = (percentages_df.groupby(['offender_type', 'variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2)\n",
        "                .reset_index()\n",
        "                .rename(columns={'value': 'sum_of_percentages'}))\n",
        "display(verification)\n",
        "\n",
        "# Note about rounding\n",
        "print(\"\\nNote: Percentage sums may not equal exactly 100% due to rounding to 2 decimal places.\")"
      ],
      "id": "ca-calculate-percentages",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing California demographics\n"
      ],
      "id": "1c53d2a8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: ca-visualize\n",
        "#| echo: true\n",
        "\n",
        "# Create cleaner bar chart visualization\n",
        "create_demographic_bar_charts(foia_combined, \"California\")"
      ],
      "id": "ca-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of California processing\n",
        "\n",
        "California data processing complete. The dataset now includes:\n",
        "\n",
        "- Reported counts for Convicted Offenders and Arrestees\n",
        "- Calculated Unknown race counts to reconcile reported totals\n",
        "- Calculated Combined totals for gender and race categories\n",
        "- Calculated percentages for all offender types and demographic categories\n",
        "\n",
        "All values include appropriate `value_source` indicators distinguishing reported from calculated values.\n",
        "\n",
        "## Florida\n"
      ],
      "id": "e94a8575"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fl-load-preview\n",
        "#| echo: true\n",
        "\n",
        "fl_path = per_state / \"florida_foia_data.csv\"\n",
        "fl = pd.read_csv(fl_path)\n",
        "\n",
        "display(fl)"
      ],
      "id": "fl-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Florida provides both counts and percentages for gender and race categories. The state already includes Combined totals, simplifying our processing.\n",
        "\n",
        "Recording Florida's reporting structure in our metadata:\n"
      ],
      "id": "89baeb30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fl-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"Florida\",\n",
        "    \"race_report_values\": report_status(fl, \"race\"),\n",
        "    \"gender_report_values\": report_status(fl, \"gender\")\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "fl-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying demographic consistency\n"
      ],
      "id": "0c6b8dfe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fl-verify-totals\n",
        "#| echo: true\n",
        "\n",
        "fl_category_qc = verify_category_totals(fl)\n",
        "display(fl_category_qc)"
      ],
      "id": "fl-verify-totals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Florida's demographic counts sum correctly to the reported total. The state data appears internally consistent.\n",
        "\n",
        "### Preparing Florida data for the combined dataset\n"
      ],
      "id": "ef59636f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fl-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# Prepare Florida data with only needed columns\n",
        "fl_for_combined = prepare_state_for_combined(fl, \"Florida\")\n",
        "\n",
        "# Display structure verification\n",
        "print(\"Florida data structure verification:\")\n",
        "print(f\"Unique offender types: {fl_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {fl_for_combined['variable_category'].unique()}\")\n",
        "print(f\"Value types present: {fl_for_combined['value_type'].unique()}\")\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, fl_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(fl_for_combined)} Florida rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "fl-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Florida demographics\n"
      ],
      "id": "3e7fbc41"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: fl-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_demographic_bar_charts(foia_combined, \"Florida\")"
      ],
      "id": "fl-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Florida processing\n",
        "\n",
        "Florida data processing complete. The state provided:\n",
        "- Both counts and percentages for all demographic categories\n",
        "- Combined totals already calculated\n",
        "- Internally consistent data requiring no adjustments\n",
        "\n",
        "All values maintain `value_source = \"reported\"` as no calculations were necessary.\n",
        "\n",
        "## Indiana\n"
      ],
      "id": "9bda4847"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-load-preview\n",
        "#| echo: true\n",
        "\n",
        "in_path = per_state / \"indiana_foia_data.csv\"\n",
        "indiana = pd.read_csv(in_path)\n",
        "\n",
        "display(indiana)"
      ],
      "id": "in-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Indiana presents a unique reporting pattern: total counts are provided, but demographic breakdowns are given only as percentages. Additionally, the value column contains String data that requires conversion.\n"
      ],
      "id": "88d6cb9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-convert-values\n",
        "#| echo: true\n",
        "\n",
        "# First, let's examine the data to see what values we have\n",
        "print(\"Unique values in Indiana data before conversion:\")\n",
        "print(indiana['value'].unique())\n",
        "\n",
        "# Convert string values to numeric, handling \"<1\" as 0.5\n",
        "indiana['value'] = indiana['value'].apply(lambda x: 0.5 if x == '<1' else pd.to_numeric(x))\n",
        "\n",
        "print(\"\\n✓ Converted Indiana values from String to numeric\")\n",
        "print(f\"Value data type after conversion: {indiana['value'].dtype}\")\n",
        "print(f\"Values after conversion: {indiana['value'].unique()}\")"
      ],
      "id": "in-convert-values",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recording Indiana's reporting structure:\n"
      ],
      "id": "c865354a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"Indiana\",\n",
        "    \"race_report_values\": report_status(indiana, \"race\"),\n",
        "    \"gender_report_values\": report_status(indiana, \"gender\"),\n",
        "    \"notes\": \"Provides percentages for demographics, counts for totals only\"\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "in-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Indiana's unique reporting structure\n",
        "\n",
        "Indiana provides an unusual reporting pattern:\n",
        "- Total profile counts for Convicted Offender and Arrestee separately\n",
        "- Demographic percentages only for Combined totals (not broken down by offender type)\n",
        "\n",
        "First, let's calculate the Combined total:\n"
      ],
      "id": "d5374c9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-calculate-combined-total\n",
        "#| echo: true\n",
        "\n",
        "# Calculate Combined total from the separate offender type totals\n",
        "conv_total = indiana[(indiana['offender_type'] == 'Convicted Offender') & \n",
        "                     (indiana['variable_detailed'] == 'total_profiles')]['value'].values[0]\n",
        "arr_total = indiana[(indiana['offender_type'] == 'Arrestee') & \n",
        "                    (indiana['variable_detailed'] == 'total_profiles')]['value'].values[0]\n",
        "combined_total = conv_total + arr_total\n",
        "\n",
        "print(f\"Convicted Offender total: {conv_total:,.0f}\")\n",
        "print(f\"Arrestee total: {arr_total:,.0f}\")\n",
        "print(f\"Combined total: {combined_total:,.0f}\")\n",
        "\n",
        "# Add Combined total to Indiana data\n",
        "combined_total_row = pd.DataFrame([{\n",
        "    'state': 'Indiana',\n",
        "    'offender_type': 'Combined',\n",
        "    'variable_category': 'total',\n",
        "    'variable_detailed': 'total_profiles',\n",
        "    'value': combined_total,\n",
        "    'value_type': 'count',\n",
        "    'value_source': 'calculated'\n",
        "}])\n",
        "\n",
        "indiana = pd.concat([indiana, combined_total_row], ignore_index=True)\n",
        "print(\"\\n✓ Added Combined total to Indiana data\")"
      ],
      "id": "in-calculate-combined-total",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating demographic counts from percentages\n",
        "\n",
        "Now we can calculate the actual counts from the Combined percentages:\n"
      ],
      "id": "4d2f243f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-prepare-and-calculate\n",
        "#| echo: true\n",
        "\n",
        "# First, prepare and append the reported data\n",
        "in_for_combined = prepare_state_for_combined(indiana, \"Indiana\")\n",
        "\n",
        "# Update value_source for the calculated Combined total\n",
        "in_for_combined.loc[\n",
        "    (in_for_combined['offender_type'] == 'Combined') & \n",
        "    (in_for_combined['variable_detailed'] == 'total_profiles'),\n",
        "    'value_source'\n",
        "] = 'calculated'\n",
        "\n",
        "foia_combined = pd.concat([foia_combined, in_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"✓ Appended {len(in_for_combined)} Indiana reported rows to foia_combined\")\n",
        "\n",
        "# Now calculate counts from the percentages\n",
        "in_counts = calculate_counts_from_percentages(foia_combined, \"Indiana\")\n",
        "\n",
        "# Append calculated counts\n",
        "if len(in_counts) > 0:\n",
        "    foia_combined = pd.concat([foia_combined, in_counts], ignore_index=True)\n",
        "    print(f\"✓ Calculated and added {len(in_counts)} count rows for Indiana\")\n",
        "    \n",
        "    # Display sample of calculated counts\n",
        "    print(\"\\nSample of calculated Indiana counts:\")\n",
        "    display(in_counts[in_counts['variable_category'] == 'race'].head())\n",
        "else:\n",
        "    print(\"✗ No counts could be calculated (this shouldn't happen)\")\n",
        "\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "in-prepare-and-calculate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying calculated totals\n"
      ],
      "id": "1cb4223b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: in-verify-calculated\n",
        "#| echo: true\n",
        "\n",
        "# Create temporary dataframe with Indiana's complete data for verification\n",
        "in_complete = pd.concat([indiana, in_counts], ignore_index=True)\n",
        "in_category_qc = verify_category_totals(in_complete)\n",
        "display(in_category_qc)\n",
        "\n",
        "# Check if percentages sum to ~100%\n",
        "print(\"\\nVerifying Indiana percentages sum to ~100%:\")\n",
        "in_pct_check = (indiana[indiana['value_type'] == 'percentage']\n",
        "                .groupby(['offender_type', 'variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2))\n",
        "display(in_pct_check)"
      ],
      "id": "in-verify-calculated",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Indiana demographics\n"
      ],
      "id": "f7d8df1a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: in-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_demographic_bar_charts(foia_combined, \"Indiana\")"
      ],
      "id": "in-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Indiana processing\n",
        "\n",
        "Indiana data processing complete. The state's unique reporting required:\n",
        "- Conversion of String values to numeric format\n",
        "- Calculation of demographic counts from reported percentages\n",
        "- All demographic values now available in both count and percentage formats\n",
        "\n",
        "Mixed `value_source` attribution: percentages are \"reported\", counts are \"calculated\".\n",
        "\n",
        "## Maine\n"
      ],
      "id": "9b2d6d52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: me-load-preview\n",
        "#| echo: true\n",
        "\n",
        "me_path = per_state / \"maine_foia_data.csv\"\n",
        "maine = pd.read_csv(me_path)\n",
        "\n",
        "display(maine)"
      ],
      "id": "me-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maine provides comprehensive reporting with both counts and percentages for all demographic categories, including Combined totals.\n",
        "\n",
        "Recording Maine's reporting structure:\n"
      ],
      "id": "9caf61d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: me-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"Maine\",\n",
        "    \"race_report_values\": report_status(maine, \"race\"),\n",
        "    \"gender_report_values\": report_status(maine, \"gender\")\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "me-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying demographic consistency\n"
      ],
      "id": "d1e7758b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: me-verify-totals\n",
        "#| echo: true\n",
        "\n",
        "me_category_qc = verify_category_totals(maine)\n",
        "display(me_category_qc)\n",
        "\n",
        "# Also verify that reported percentages sum to ~100%\n",
        "print(\"\\nVerifying Maine percentages sum to ~100%:\")\n",
        "me_pct_check = (maine[maine['value_type'] == 'percentage']\n",
        "                .groupby(['variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2))\n",
        "display(me_pct_check)"
      ],
      "id": "me-verify-totals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maine's data shows excellent internal consistency with both counts and percentages properly aligned.\n",
        "\n",
        "### Preparing Maine data for the combined dataset\n"
      ],
      "id": "b300a60c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: me-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# Prepare Maine data with only needed columns\n",
        "me_for_combined = prepare_state_for_combined(maine, \"Maine\")\n",
        "\n",
        "# Display structure verification\n",
        "print(\"Maine data structure verification:\")\n",
        "print(f\"Unique offender types: {me_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {me_for_combined['variable_category'].unique()}\")\n",
        "print(f\"Value types present: {me_for_combined['value_type'].unique()}\")\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, me_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(me_for_combined)} Maine rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "me-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Maine demographics\n"
      ],
      "id": "2f0faac0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: me-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_demographic_bar_charts(foia_combined, \"Maine\")"
      ],
      "id": "me-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Maine processing\n",
        "\n",
        "Maine data processing complete. The state provided:\n",
        "- Complete reporting with both counts and percentages\n",
        "- Combined totals already calculated\n",
        "- Internally consistent data with percentages summing to 100%\n",
        "\n",
        "All values maintain `value_source = \"reported\"` as no calculations were necessary.\n",
        "\n",
        "## Nevada\n"
      ],
      "id": "c2b58b01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: nv-load-preview\n",
        "#| echo: true\n",
        "\n",
        "nv_path = per_state / \"nevada_foia_data.csv\"\n",
        "nevada = pd.read_csv(nv_path)\n",
        "\n",
        "display(nevada)"
      ],
      "id": "nv-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nevada uses non-standard terminology that requires standardization:\n",
        "- \"All\" instead of \"Combined\"\n",
        "- \"Arrested offender\" instead of \"Arrestee\"\n",
        "- \"Convicted offenders\" instead of \"Convicted Offender\"\n",
        "- Uses \"flags\" terminology instead of \"profiles\"\n"
      ],
      "id": "2bd6275b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: nv-standardize\n",
        "#| echo: true\n",
        "\n",
        "# Standardize offender types\n",
        "nevada = standardize_offender_types(nevada)\n",
        "\n",
        "print(\"✓ Standardized Nevada offender type terminology\")\n",
        "print(f\"Offender types after standardization: {sorted(nevada['offender_type'].unique())}\")"
      ],
      "id": "nv-standardize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recording Nevada's reporting structure:\n"
      ],
      "id": "bc27af85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: nv-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"Nevada\",\n",
        "    \"race_report_values\": report_status(nevada, \"race\"),\n",
        "    \"gender_report_values\": report_status(nevada, \"gender\"),\n",
        "    \"notes\": \"Uses 'flags' terminology instead of 'profiles'\"\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "nv-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying demographic consistency\n"
      ],
      "id": "a9245c33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: nv-verify-totals\n",
        "#| echo: true\n",
        "\n",
        "nv_category_qc = verify_category_totals(nevada)\n",
        "display(nv_category_qc)\n",
        "\n",
        "# Verify percentages sum to ~100%\n",
        "print(\"\\nVerifying Nevada percentages sum to ~100%:\")\n",
        "nv_pct_check = (nevada[nevada['value_type'] == 'percentage']\n",
        "                .groupby(['offender_type', 'variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2))\n",
        "display(nv_pct_check)"
      ],
      "id": "nv-verify-totals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nevada's data shows good internal consistency after terminology standardization.\n",
        "\n",
        "### Preparing Nevada data for the combined dataset\n"
      ],
      "id": "61f6bc61"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: nv-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# Prepare Nevada data with only needed columns\n",
        "nv_for_combined = prepare_state_for_combined(nevada, \"Nevada\")\n",
        "\n",
        "# Display structure verification\n",
        "print(\"Nevada data structure verification:\")\n",
        "print(f\"Unique offender types: {nv_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {nv_for_combined['variable_category'].unique()}\")\n",
        "print(f\"Value types present: {nv_for_combined['value_type'].unique()}\")\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, nv_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(nv_for_combined)} Nevada rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "nv-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Nevada demographics\n"
      ],
      "id": "832c4296"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: nv-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_demographic_bar_charts(foia_combined, \"Nevada\")"
      ],
      "id": "nv-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Nevada processing\n",
        "\n",
        "Nevada data processing complete. The state required:\n",
        "- Standardization of offender type terminology for consistency\n",
        "- Recognition of \"flags\" as equivalent to \"profiles\" in other states\n",
        "- Both counts and percentages were provided for all categories\n",
        "\n",
        "All values maintain `value_source = \"reported\"` as only terminology changes were necessary.\n",
        "\n",
        "## South Dakota\n"
      ],
      "id": "65fdf538"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: sd-load-preview\n",
        "#| echo: true\n",
        "\n",
        "sd_path = per_state / \"south_dakota_foia_data.csv\"\n",
        "south_dakota = pd.read_csv(sd_path)\n",
        "\n",
        "display(south_dakota.head(20))\n",
        "print(f\"\\n... showing first 20 of {len(south_dakota)} rows\")"
      ],
      "id": "sd-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "South Dakota provides the most comprehensive reporting with 41 rows, including:\n",
        "- Standard gender and race breakdowns\n",
        "- Unique `gender_race` cross-tabulation showing intersectional demographics\n",
        "- Both counts and percentages for all categories\n",
        "\n",
        "Recording South Dakota's reporting structure:\n"
      ],
      "id": "559b8713"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: sd-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"South Dakota\",\n",
        "    \"race_report_values\": report_status(south_dakota, \"race\"),\n",
        "    \"gender_report_values\": report_status(south_dakota, \"gender\"),\n",
        "    \"notes\": \"Includes gender_race cross-tabulation for intersectional analysis\"\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "sd-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examining the intersectional data\n"
      ],
      "id": "62690faf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: sd-examine-intersectional\n",
        "#| echo: true\n",
        "\n",
        "# Display the unique gender_race combinations\n",
        "gender_race_data = south_dakota[south_dakota['variable_category'] == 'gender_race']\n",
        "print(\"South Dakota's intersectional gender × race categories:\")\n",
        "print(f\"Total gender_race rows: {len(gender_race_data)}\")\n",
        "print(\"\\nUnique combinations:\")\n",
        "for combo in sorted(gender_race_data['variable_detailed'].unique()):\n",
        "    print(f\"  • {combo}\")"
      ],
      "id": "sd-examine-intersectional",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying demographic consistency\n"
      ],
      "id": "4b731a33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: sd-verify-totals\n",
        "#| echo: true\n",
        "\n",
        "sd_category_qc = verify_category_totals(south_dakota)\n",
        "display(sd_category_qc)\n",
        "\n",
        "# Verify percentages sum to ~100%\n",
        "print(\"\\nVerifying South Dakota percentages sum to ~100%:\")\n",
        "sd_pct_check = (south_dakota[south_dakota['value_type'] == 'percentage']\n",
        "                .groupby(['variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2))\n",
        "display(sd_pct_check)"
      ],
      "id": "sd-verify-totals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "South Dakota's data demonstrates excellent internal consistency across all categories, including the intersectional data.\n",
        "\n",
        "### Preparing South Dakota data for the combined dataset\n"
      ],
      "id": "a22d5872"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: sd-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# Prepare South Dakota data with only needed columns\n",
        "sd_for_combined = prepare_state_for_combined(south_dakota, \"South Dakota\")\n",
        "\n",
        "# Display structure verification\n",
        "print(\"South Dakota data structure verification:\")\n",
        "print(f\"Unique offender types: {sd_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {sd_for_combined['variable_category'].unique()}\")\n",
        "print(f\"Value types present: {sd_for_combined['value_type'].unique()}\")\n",
        "\n",
        "# Show breakdown by category\n",
        "print(\"\\nRows by variable category:\")\n",
        "print(sd_for_combined['variable_category'].value_counts())\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, sd_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(sd_for_combined)} South Dakota rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "sd-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing South Dakota demographics\n"
      ],
      "id": "42d49a4b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 18,
        "fig-height": 12
      },
      "source": [
        "#| label: sd-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_demographic_bar_charts(foia_combined, \"South Dakota\")"
      ],
      "id": "sd-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of South Dakota processing\n",
        "\n",
        "South Dakota data processing complete. The state provided:\n",
        "- Most comprehensive reporting with 41 rows of data\n",
        "- Standard gender and race categories plus unique intersectional gender×race data\n",
        "- Complete counts and percentages for all categories\n",
        "- Exemplary data quality with perfect internal consistency\n",
        "\n",
        "All values maintain `value_source = \"reported\"`. The intersectional data provides unique insights unavailable from other states.\n",
        "\n",
        "## Texas\n"
      ],
      "id": "ef5987e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-load-preview\n",
        "#| echo: true\n",
        "\n",
        "tx_path = per_state / \"texas_foia_data.csv\"\n",
        "texas = pd.read_csv(tx_path)\n",
        "\n",
        "display(texas)"
      ],
      "id": "tx-load-preview",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Texas provides counts only and uses \"Offenders\" instead of \"Convicted Offender\". Like California, Texas will need Combined totals and percentages calculated.\n"
      ],
      "id": "4b2faafc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-standardize\n",
        "#| echo: true\n",
        "\n",
        "# Standardize offender types\n",
        "texas = standardize_offender_types(texas)\n",
        "\n",
        "print(\"✓ Standardized Texas offender type terminology\")\n",
        "print(f\"Offender types after standardization: {sorted(texas['offender_type'].unique())}\")"
      ],
      "id": "tx-standardize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recording Texas's reporting structure:\n"
      ],
      "id": "aae913b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-add-metadata\n",
        "#| echo: true\n",
        "\n",
        "foia_state_metadata.append({\n",
        "    \"state\": \"Texas\",\n",
        "    \"race_report_values\": report_status(texas, \"race\"),\n",
        "    \"gender_report_values\": report_status(texas, \"gender\")\n",
        "})\n",
        "\n",
        "print(\"✓ Added metadata row:\", foia_state_metadata[-1])"
      ],
      "id": "tx-add-metadata",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying demographic consistency\n"
      ],
      "id": "cba9f5c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-verify-totals\n",
        "#| echo: true\n",
        "\n",
        "tx_category_qc = verify_category_totals(texas)\n",
        "display(tx_category_qc)"
      ],
      "id": "tx-verify-totals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Texas shows perfect internal consistency with all demographic counts matching reported totals.\n",
        "\n",
        "### Creating Combined totals\n"
      ],
      "id": "3af33bcf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-create-combined\n",
        "#| echo: true\n",
        "\n",
        "# Calculate Combined totals using helper function\n",
        "tx_combined = calculate_combined_totals(texas, \"Texas\")\n",
        "\n",
        "# Add Combined rows to texas dataframe\n",
        "texas = pd.concat([texas, tx_combined], ignore_index=True)\n",
        "\n",
        "print(\"✓ Created Combined totals for Texas\")\n",
        "print(f\"  Combined total profiles: {tx_combined[tx_combined['variable_detailed'] == 'total_profiles']['value'].values[0]:,}\")\n",
        "\n",
        "# Display Combined counts\n",
        "print(\"\\nCombined gender counts:\")\n",
        "display(tx_combined[tx_combined['variable_category'] == 'gender'].sort_values('variable_detailed'))\n",
        "\n",
        "print(\"\\nCombined race counts:\")\n",
        "display(tx_combined[tx_combined['variable_category'] == 'race'].sort_values('variable_detailed'))\n",
        "\n",
        "# Verify Combined calculations\n",
        "print(\"\\n✓ Verification of Combined calculations:\")\n",
        "\n",
        "# Get original counts for verification\n",
        "conv_total = texas[(texas['offender_type'] == 'Convicted Offender') & \n",
        "                   (texas['variable_detailed'] == 'total_profiles') &\n",
        "                   (texas['value_type'] == 'count')]['value'].values[0]\n",
        "arr_total = texas[(texas['offender_type'] == 'Arrestee') & \n",
        "                  (texas['variable_detailed'] == 'total_profiles') &\n",
        "                  (texas['value_type'] == 'count')]['value'].values[0]\n",
        "comb_total = tx_combined[tx_combined['variable_detailed'] == 'total_profiles']['value'].values[0]\n",
        "\n",
        "print(f\"  Convicted Offender total: {conv_total:,}\")\n",
        "print(f\"  Arrestee total: {arr_total:,}\")\n",
        "print(f\"  Sum: {conv_total + arr_total:,}\")\n",
        "print(f\"  Combined total: {comb_total:,}\")\n",
        "print(f\"  Match: {conv_total + arr_total == comb_total}\")"
      ],
      "id": "tx-create-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing Texas data for the combined dataset\n"
      ],
      "id": "69f41cc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-append-to-combined\n",
        "#| echo: true\n",
        "\n",
        "# Prepare Texas data with only needed columns\n",
        "tx_for_combined = prepare_state_for_combined(texas, \"Texas\")\n",
        "\n",
        "# Update value_source for Combined rows\n",
        "tx_for_combined.loc[\n",
        "    tx_for_combined['offender_type'] == 'Combined', \n",
        "    'value_source'\n",
        "] = 'calculated'\n",
        "\n",
        "# Display structure verification\n",
        "print(\"Texas data structure verification:\")\n",
        "print(f\"Unique offender types: {tx_for_combined['offender_type'].unique()}\")\n",
        "print(f\"Unique variable categories: {tx_for_combined['variable_category'].unique()}\")\n",
        "\n",
        "# Append to the combined dataframe\n",
        "foia_combined = pd.concat([foia_combined, tx_for_combined], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Appended {len(tx_for_combined)} Texas rows to foia_combined\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")"
      ],
      "id": "tx-append-to-combined",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating percentages\n"
      ],
      "id": "53074bde"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tx-calculate-percentages\n",
        "#| echo: true\n",
        "\n",
        "# Calculate percentages using helper function\n",
        "tx_percentages = calculate_percentages(foia_combined, \"Texas\")\n",
        "\n",
        "# Add percentages to foia_combined\n",
        "foia_combined = pd.concat([foia_combined, tx_percentages], ignore_index=True)\n",
        "\n",
        "print(f\"✓ Calculated and added {len(tx_percentages)} percentage rows for Texas\")\n",
        "print(f\"✓ Total rows in foia_combined: {len(foia_combined)}\")\n",
        "\n",
        "# Display sample of calculated percentages\n",
        "print(\"\\nGender percentages by offender type:\")\n",
        "gender_pct = tx_percentages[tx_percentages['variable_category'] == 'gender'].pivot_table(\n",
        "    index='variable_detailed', columns='offender_type', values='value'\n",
        ")\n",
        "display(gender_pct)\n",
        "\n",
        "# Verify percentages sum to ~100%\n",
        "print(\"\\nVerification of percentage totals by category:\")\n",
        "verification = (tx_percentages.groupby(['offender_type', 'variable_category'])['value']\n",
        "                .sum()\n",
        "                .round(2)\n",
        "                .reset_index()\n",
        "                .rename(columns={'value': 'sum_of_percentages'}))\n",
        "display(verification)"
      ],
      "id": "tx-calculate-percentages",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Texas demographics\n"
      ],
      "id": "45dc8d17"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 15,
        "fig-height": 16
      },
      "source": [
        "#| label: tx-visualize\n",
        "#| echo: true\n",
        "\n",
        "create_state_visualizations(foia_combined, \"Texas\")"
      ],
      "id": "tx-visualize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Texas processing\n",
        "\n",
        "Texas data processing complete. The state required:\n",
        "- Standardization of \"Offenders\" to \"Convicted Offender\"\n",
        "- Calculation of Combined totals across offender types\n",
        "- Calculation of percentages from provided counts\n",
        "\n",
        "Mixed `value_source` attribution: original counts are \"reported\", Combined totals and all percentages are \"calculated\".\n",
        "\n",
        "# Conclusions\n",
        "\n",
        "## Final Processing Summary\n",
        "\n",
        "All seven states have been successfully processed and combined into a unified dataset.\n"
      ],
      "id": "07dabd19"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: final-summary-all-states\n",
        "#| echo: true\n",
        "\n",
        "# Display final metadata summary\n",
        "print(\"State Processing Metadata:\")\n",
        "print(\"=\" * 80)\n",
        "metadata_df = pd.DataFrame(foia_state_metadata)\n",
        "display(metadata_df)\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\n✓ Total rows in foia_combined: {len(foia_combined)}\")\n",
        "print(f\"✓ States processed: {sorted(foia_combined['state'].unique())}\")\n",
        "print(f\"✓ Offender types: {sorted(foia_combined['offender_type'].unique())}\")\n",
        "print(f\"✓ Variable categories: {sorted(foia_combined['variable_category'].unique())}\")\n",
        "\n",
        "# Value source breakdown\n",
        "print(\"\\nValue source breakdown:\")\n",
        "source_counts = foia_combined['value_source'].value_counts()\n",
        "for source, count in source_counts.items():\n",
        "    pct = (count / len(foia_combined)) * 100\n",
        "    print(f\"  • {source}: {count} rows ({pct:.1f}%)\")\n",
        "\n",
        "# Show sample of final combined data\n",
        "print(\"\\nSample of final combined dataset:\")\n",
        "display(foia_combined.sample(10, random_state=42))"
      ],
      "id": "final-summary-all-states",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Processed Data\n"
      ],
      "id": "1df125bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: save-outputs\n",
        "#| echo: true\n",
        "\n",
        "# Define output paths\n",
        "output_dir = base_dir / \"output\" / \"foia\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save the combined dataset\n",
        "foia_output_path = output_dir / \"foia_data_clean.csv\"\n",
        "foia_combined.to_csv(foia_output_path, index=False)\n",
        "print(f\"✓ Saved combined FOIA data to: {foia_output_path}\")\n",
        "\n",
        "# Save the metadata\n",
        "metadata_output_path = output_dir / \"foia_state_metadata.csv\"\n",
        "metadata_df.to_csv(metadata_output_path, index=False)\n",
        "print(f\"✓ Saved state metadata to: {metadata_output_path}\")\n",
        "\n",
        "# Create final frozen version\n",
        "frozen_dir = base_dir / \"data\" / \"v1.0\"\n",
        "frozen_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "frozen_path = frozen_dir / \"foia_state_race_v1.0.csv\"\n",
        "foia_combined.to_csv(frozen_path, index=False)\n",
        "print(f\"✓ Created frozen version at: {frozen_path}\")\n",
        "\n",
        "print(\"\\n✅ All processing complete!\")"
      ],
      "id": "save-outputs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings and Notes\n",
        "\n",
        "1. **Data Completeness**: All states provided total profile counts and demographic breakdowns, though reporting formats varied significantly.\n",
        "\n",
        "2. **Calculated Values**: \n",
        "   - California and Texas required Combined totals and percentage calculations\n",
        "   - Indiana required count calculations from percentages\n",
        "   - All calculated values are clearly marked with `value_source = \"calculated\"`\n",
        "\n",
        "3. **Terminology Standardization**:\n",
        "   - Nevada: \"All\" → \"Combined\", \"Arrested offender\" → \"Arrestee\"\n",
        "   - Texas: \"Offenders\" → \"Convicted Offender\"\n",
        "\n",
        "4. **Unique Features**:\n",
        "   - South Dakota provided intersectional gender×race data unavailable from other states\n",
        "   - Nevada uses \"flags\" terminology instead of \"profiles\"\n",
        "   - California acknowledged missing race data, requiring \"Unknown\" category calculation\n",
        "\n",
        "5. **Data Quality**: After processing, all states show internally consistent data with demographic counts summing to reported totals and percentages summing to approximately 100% (accounting for rounding).\n",
        "\n",
        "This standardized dataset enables direct state-to-state comparisons of DNA database demographics while maintaining full transparency about data sources and calculations.\n",
        "\n",
        "This processing pipeline has successfully transformed heterogeneous FOIA responses from seven states into a standardized, analysis-ready dataset. By maintaining clear attribution of reported versus calculated values and documenting all processing decisions, this work supports reproducible research on racial disparities in DNA databases.\n",
        "\n",
        "The unified dataset (`foia_state_race_v1.0.csv`) and accompanying metadata provide researchers with accessible, transparent data to examine critical questions about equity and representation in forensic DNA databases. As noted in the introduction, making this data more accessible represents an important contribution to research ethics and transparency in criminal justice studies."
      ],
      "id": "aaea13ff"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}