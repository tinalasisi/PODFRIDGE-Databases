[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PODFRIDGE-Databases",
    "section": "",
    "text": "PODFRIDGE-Databases is a comprehensive research platform analyzing forensic DNA database systems in the United States. This project combines multiple data sources to examine the growth, composition, and demographic patterns within national and state DNA index systems."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "PODFRIDGE-Databases",
    "section": "",
    "text": "PODFRIDGE-Databases is a comprehensive research platform analyzing forensic DNA database systems in the United States. This project combines multiple data sources to examine the growth, composition, and demographic patterns within national and state DNA index systems."
  },
  {
    "objectID": "index.html#research-projects",
    "href": "index.html#research-projects",
    "title": "PODFRIDGE-Databases",
    "section": "Research Projects",
    "text": "Research Projects\n\n1. NDIS Database Analysis\nTracking FBIâ€™s National DNA Index System (2001-2025)\n\nObjective: Reconstruct NDIS growth through Wayback Machine archives\nKey Findings: Exponential profile growth, jurisdictional participation patterns\nMethods: Web scraping, data validation, time-series analysis\n\nView Full Analysis â†’\n\n\n2. SDIS Summary Analysis\nState DNA Database Policies and Practices\n\nObjective: Examine variation in state DNA database policies\nKey Findings: Arrestee collection policies, familial search allowances\nMethods: Legal statute analysis, policy documentation\n\nView Full Analysis â†’\n\n\n3. FOIA Document Processing\nRacial Composition of State DNA Databases\n\nObjective: Process FOIA responses on demographic disparities\nKey Findings: Standardized data from 7 states, transparency framework\nMethods: OCR processing, data standardization, quality control\n\nView Full Analysis â†’\n\n\nComplementary: Racial Disparities Methodology\nMurphy & Tong Study Transparency Appendix\n\nObjective: Document data sources and methodology for racial disparity research\nKey Findings: Consistent disparities, data limitations, methodological challenges\nMethods: Data provenance tracking, methodology documentation\n\nView Methodology â†’"
  },
  {
    "objectID": "analysis/sdis_summary.html",
    "href": "analysis/sdis_summary.html",
    "title": "SDIS Summary Analysis",
    "section": "",
    "text": "This analysis examines State DNA Index System (SDIS) data that includes information reported separately for each stateâ€™s DNA database. The data captures key dimensions including:\n\nTotal size of each stateâ€™s DNA database\nWhether states collect DNA from arrestees (not just convicted offenders)\nWhether states allow familial DNA searching\nReferences to relevant state statutes (from Murphy & Tong appendix)\n\nThis information provides insight into the variation in DNA database policies, practices, and legal frameworks across U.S. states."
  },
  {
    "objectID": "analysis/sdis_summary.html#overview",
    "href": "analysis/sdis_summary.html#overview",
    "title": "SDIS Summary Analysis",
    "section": "",
    "text": "This analysis examines State DNA Index System (SDIS) data that includes information reported separately for each stateâ€™s DNA database. The data captures key dimensions including:\n\nTotal size of each stateâ€™s DNA database\nWhether states collect DNA from arrestees (not just convicted offenders)\nWhether states allow familial DNA searching\nReferences to relevant state statutes (from Murphy & Tong appendix)\n\nThis information provides insight into the variation in DNA database policies, practices, and legal frameworks across U.S. states."
  },
  {
    "objectID": "analysis/sdis_summary.html#setup",
    "href": "analysis/sdis_summary.html#setup",
    "title": "SDIS Summary Analysis",
    "section": "Setup",
    "text": "Setup\nLoad necessary packages for the analysis.\n\n\nShow setup code\n# List of required packages\nrequired_packages &lt;- c(\n  \"tidyverse\",    # Data manipulation and visualization\n  \"readr\",      # Reading CSV files\n  \"dplyr\",      # Data manipulation\n  \"tidyr\",      # Data tidying\n  \"purrr\",      # Functional programming tools\n  \"ggplot2\",    # Data visualization\n  \"heatmaply\",  # Interactive heatmaps\n  \"kableExtra\", # Enhanced tables for reporting\n  \"DT\",         # Interactive tables\n  \"flextable\",  # Flexible tables for reporting\n  \"maps\",       # Mapping tools\n  \"here\"        # File path management\n)\n\n# Function to install missing packages\ninstall_missing &lt;- function(packages) {\n  for (pkg in packages) {\n    if (!requireNamespace(pkg, quietly = TRUE)) {\n      message(paste(\"Installing missing package:\", pkg))\n      install.packages(pkg, dependencies = TRUE)\n    }\n  }\n}\n\n# Install any missing packages\ninstall_missing(required_packages)\n\n# Load all packages\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(purrr)\n  library(ggplot2)\n  library(heatmaply)\n  library(kableExtra)\n  library(DT)\n  library(flextable)\n  library(maps)\n  library(here)\n})\n\n# Verify all packages loaded successfully\nloaded_packages &lt;- sapply(required_packages, require, character.only = TRUE)\nif (all(loaded_packages)) {\n  message(\"All packages loaded successfully!\")\n} else {\n  warning(\"The following packages failed to load: \", \n          paste(names(loaded_packages)[!loaded_packages], collapse = \", \"))\n}"
  },
  {
    "objectID": "analysis/sdis_summary.html#import-sdis-data",
    "href": "analysis/sdis_summary.html#import-sdis-data",
    "title": "SDIS Summary Analysis",
    "section": "Import SDIS data",
    "text": "Import SDIS data\nLoad the SDIS dataset and display a glimpse of its structure, including data types, missing values, and unique counts.\nDatabase Columns Definition\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nstate\nName of the U.S. state or jurisdiction\n\n\nn_total\nTotal number of DNA profiles in the state database\n\n\nn_arrestees\nNumber of arrestee DNA profiles in the database\n\n\nn_offenders\nNumber of convicted offender DNA profiles in the database\n\n\nn_forensic\nNumber of forensic/crime scene DNA profiles in the database\n\n\narrestee_collection\nWhether the state collects DNA from arrestees (â€˜yesâ€™/â€˜noâ€™)\n\n\ncollection_statute\nCitation to the stateâ€™s DNA collection statute\n\n\nfam_search\nFamily search policy status (â€˜permittedâ€™, â€˜prohibitedâ€™, â€˜unspecifiedâ€™)\n\n\ndatabase_source\nURL source for the database statistics\n\n\ndatabase_source_year\nYear the database statistics were reported\n\n\nverification_comment\nAdditional notes or comments about data verification\n\n\n\n\n\nShow import code\n# Set up path to data file\ndata_file &lt;- file.path(here(\"raw\", \"sdis_file\", \"sdis_raw.csv\"))\n\n# Load the SDIS data\nsdis_data &lt;- read_csv(data_file)\n\n# Display data types for each column\nenhanced_glimpse &lt;- function(df) {\n  glimpse_data &lt;- data.frame(\n    Column = names(df),\n    Type = sapply(df, function(x) paste(class(x), collapse = \", \")),\n    Rows = nrow(df),\n    Missing = sapply(df, function(x) sum(is.na(x))),\n    Unique = sapply(df, function(x) length(unique(x))),\n    First_Values = sapply(df, function(x) {\n      if(is.numeric(x)) {\n        paste(round(head(x, 3), 2), collapse = \", \")\n      } else {\n        paste(encodeString(head(as.character(x), 3)), collapse = \", \")\n      }\n    })\n  )\n  \n  ft &lt;- flextable(glimpse_data) %&gt;%\n    theme_zebra() %&gt;%\n    set_caption(paste(\"Enhanced Data Glimpse:\", deparse(substitute(df)))) %&gt;%\n    autofit() %&gt;%\n    align(align = \"left\", part = \"all\") %&gt;%\n    colformat_num(j = c(\"Rows\", \"Missing\", \"Unique\"), big.mark = \"\") %&gt;%\n    bg(j = \"Missing\", bg = function(x) ifelse(x &gt; 0, \"#FFF3CD\", \"transparent\")) %&gt;%\n    bg(j = \"Unique\", bg = function(x) ifelse(x == 1, \"#FFF3CD\", \"transparent\")) %&gt;%\n    add_footer_lines(paste(\"Data frame dimensions:\", nrow(df), \"rows Ã—\", ncol(df), \"columns\")) %&gt;%\n    fontsize(size = 10, part = \"all\") %&gt;%\n    set_table_properties(layout = \"autofit\", width = 1)\n  \n  return(ft)\n}\n\nenhanced_glimpse(sdis_data)\n\n\nColumnTypeRowsMissingUniqueFirst_Valuesstatecharacter50050Alabama, Alaska, Arizonan_totalnumeric502328360000, 79146, NAn_arresteesnumeric50278NA, 52149, NAn_offendersnumeric503417NA, 26997, NAn_forensicnumeric503912NA, 3866, NAarrestee_collectioncharacter5002yes, yes, yescollection_statutecharacter50050Ala. Code Sec.36-18-25, AK Stat Sec.44.41.035 (2014), AZ Rev Stat Sec.13-610 (2016)fam_searchcharacter5003unspecified, unspecified, unspecifieddatabase_sourcecharacter502031https://adfs.alabama.gov/services/fb/fb-statistics, https://dps.alaska.gov/Statewide/CrimeLab/Forensic-Biology/DNA, &lt;NA&gt;database_source_yearnumeric5020112024, 2024, NAverification_commentcharacter503516Alabama Department of Forensic Sciences notes that as of JanuaryÂ 2024 the state DNA database contains about 360,000 convicted offender and arrestee profileshttps://adfs.alabama.gov/services/fb/fb-statistics#:~:text=The%20DNA%20Databank%20laboratory%20receives,DNA%20profiles%20are%20being%20searched., Alaska DPS crimeâ€‘lab CODIS metrics (FebÂ 2024) list 52,149 arrestee profiles, 26,997 convicted offender profiles and 3,866 forensic profiles in the Alaska state DNA databasehttps://dps.alaska.gov/Statewide/CrimeLab/Forensic-Biology/DNA#:~:text=CODIS%20Metrics%20as%20of%C2%A0February%202024,Offenders%20in%20database%2026%2C997%2015%2C268%2C774., &lt;NA&gt;Data frame dimensions: 50 rows Ã— 11 columns"
  },
  {
    "objectID": "analysis/sdis_summary.html#arrestee-collection-information",
    "href": "analysis/sdis_summary.html#arrestee-collection-information",
    "title": "SDIS Summary Analysis",
    "section": "Arrestee Collection Information",
    "text": "Arrestee Collection Information\nIn the United States, the collection of DNA from individuals upon arrest, prior to any conviction, is a significant law enforcement practice with complex legal and ethical dimensions.\nThe following map and table illustrate the current patchwork of state laws governing this practice.\n\n\nShow arrestee collection visualization code\n# Create summary data for arrestee collection\narrestee_summary &lt;- sdis_data %&gt;%\n  group_by(arrestee_collection) %&gt;%\n  summarise(\n    count = n(),\n    states = list(state),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(count))\n\n# Get US state map data\nus_states &lt;- map_data(\"state\")\n\n# Prepare map data\nmap_data &lt;- sdis_data %&gt;%\n  mutate(region = tolower(state)) %&gt;%\n  right_join(us_states, by = \"region\") %&gt;%\n  filter(!is.na(arrestee_collection))\n\n# Option 1: US Map Visualization\nmap_plot &lt;- ggplot(map_data, aes(x = long, y = lat, group = group, fill = arrestee_collection)) +\n  geom_polygon(color = \"white\", linewidth = 0.2) +\n  coord_fixed(1.3) +\n  scale_fill_manual(\n    values = c(\n      \"yes\" = \"#2E86AB\",      # Blue for collecting states\n      \"no\" = \"#FF6B6B\"       # Red for non-collecting states\n    ),\n    name = \"Collects DNA from Arrestees\",\n    labels = c(\"Yes\", \"No\")\n  ) +\n  labs(\n    title = \"DNA Collection from Arrestees by State\",\n    subtitle = \"States that collect DNA samples from individuals upon arrest\",\n    caption = \"Source: SDIS Database Analysis\"\n  ) +\n  theme_void() +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, color = \"gray40\", size = 12),\n    legend.position = \"right\",\n    legend.title = element_text(face = \"bold\")\n  )\n\n# Create detailed summary table\nsummary_table &lt;- arrestee_summary %&gt;%\n  mutate(\n    state_list = map_chr(states, ~paste(.x, collapse = \", \")),\n    percentage = round(count / sum(count) * 100, 1)\n  ) %&gt;%\n  select(Status = arrestee_collection, Count = count, Percentage = percentage, States = state_list)\n\n# Display the visualizations\nprint(map_plot)\n\n\n\n\n\n\n\n\n\nShow arrestee collection visualization code\n# Create a nice flextable for the report\nft &lt;- flextable(summary_table) %&gt;%\n  theme_zebra() %&gt;%\n  set_caption(\"Arrestee DNA Collection Status by State\") %&gt;%\n  autofit() %&gt;%\n  align(align = \"left\", part = \"all\") %&gt;%\n  bg(j = \"Status\", bg = function(x) ifelse(x == \"yes\", \"#2E86AB\", ifelse(x == \"no\", \"#FF6B6B\", \"#CCCCCC\"))) %&gt;%\n  color(j = \"Status\", color = \"white\") %&gt;%\n  bold(j = \"Status\") %&gt;%\n  fontsize(size = 11, part = \"all\")\n\nft\n\n\nStatusCountPercentageStatesyes3366Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Florida, Georgia, Illinois, Indiana, Kansas, Louisiana, Maryland, Michigan, Minnesota, Mississippi, Missouri, Nevada, New Jersey, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Virginia, Wisconsinno1734Delaware, Hawaii, Idaho, Iowa, Kentucky, Maine, Massachusetts, Montana, Nebraska, New Hampshire, New York, Oregon, Pennsylvania, Vermont, Washington, West Virginia, Wyoming\n\n\n\nAdjusting n_arrestees\n\nAdjust the dataset to ensure consistency in arrestee DNA collection reporting.\nSetting n_arrestees to 0 for states that do not collect arrestee DNA, even if they report non-zero values.\nRemoved the arrestee_colection column after adjustments were made.\n\n\n\nShow pre-processing code\n# Create a copy of the data for processing\nsdis_data_processed &lt;- sdis_data\n\n# Count states affected by this adjustment\nstates_with_no_collection &lt;- sdis_data_processed %&gt;% \n  filter(arrestee_collection == 'no')\n\nstates_to_adjust &lt;- states_with_no_collection %&gt;% \n  filter(!is.na(n_arrestees) & n_arrestees != 0)\n\nif (nrow(states_to_adjust) &gt; 0) {\n  cat(\"States with arrestee_collection='no' but non-zero n_arrestees values:\\n\")\n  for (i in 1:nrow(states_to_adjust)) {\n    state &lt;- states_to_adjust[i, ]\n    cat(paste0(\"  â€¢ \", state$state, \": n_arrestees = \", format(state$n_arrestees, big.mark = \",\"), \"\\n\"))\n  }\n}\n\n# Set n_arrestees to 0 for states that don't collect arrestee DNA\nsdis_data_processed &lt;- sdis_data_processed %&gt;%\n  mutate(n_arrestees = ifelse(arrestee_collection == 'no', 0, n_arrestees))  %&gt;%\n  select(-arrestee_collection)\n\ncat(paste(\"\\nAdjusted N_arrestees to 0 for\", nrow(states_with_no_collection), \n          \"states that do not collect arrestee DNA:\\n\"))\n\nunique(states_with_no_collection$state)\n\n# Use processed data for all subsequent analyses\nsdis_data &lt;- sdis_data_processed\n\n\n\nAdjusted N_arrestees to 0 for 17 states that do not collect arrestee DNA:\n [1] \"Delaware\"      \"Hawaii\"        \"Idaho\"         \"Iowa\"         \n [5] \"Kentucky\"      \"Maine\"         \"Massachusetts\" \"Montana\"      \n [9] \"Nebraska\"      \"New Hampshire\" \"New York\"      \"Oregon\"       \n[13] \"Pennsylvania\"  \"Vermont\"       \"Washington\"    \"West Virginia\"\n[17] \"Wyoming\""
  },
  {
    "objectID": "analysis/sdis_summary.html#family-search-policy-status",
    "href": "analysis/sdis_summary.html#family-search-policy-status",
    "title": "SDIS Summary Analysis",
    "section": "Family Search Policy Status",
    "text": "Family Search Policy Status\nFamilial DNA searching is an advanced forensic technique that uses partial DNA matches to identify potential relatives of an unknown suspect in a criminal database.\nThe following visualization maps the current patchwork of state policies (â€˜permittedâ€™, â€˜prohibitedâ€™, â€˜unspecifiedâ€™).\n\n\nShow family search policy visualization code\n# Create summary data for family search policies\nfamily_search_summary &lt;- sdis_data %&gt;%\n  mutate(\n    fam_search = factor(fam_search, \n                       levels = c(\"permitted\", \"prohibited\", \"unspecified\"),\n                       labels = c(\"Permitted\", \"Prohibited\", \"Unspecified\")),\n    fam_search_simple = case_when(\n      fam_search == \"Permitted\" ~ \"Permitted\",\n      fam_search == \"Prohibited\" ~ \"Prohibited\",\n      TRUE ~ \"Unspecified/No Policy\"\n    )\n  ) %&gt;%\n  group_by(fam_search, fam_search_simple) %&gt;%\n  summarise(\n    count = n(),\n    states = list(state),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(count))\n\n# Get complete data for mapping (include states with missing data)\nall_states_map &lt;- map_data(\"state\") %&gt;%\n  as_tibble() %&gt;%\n  distinct(region) %&gt;%\n  mutate(\n    state_name = str_to_title(region),\n    has_data = state_name %in% sdis_data$state\n  )\n\n# Prepare map data for family search policies\nfamily_search_map_data &lt;- sdis_data %&gt;%\n  mutate(\n    region = tolower(state)) %&gt;%\n  right_join(map_data(\"state\"), by = c(\"region\" = \"region\")) %&gt;%\n  filter(!is.na(fam_search))\n\n# Option 1: US Map Visualization\nfamily_map_plot &lt;- ggplot(family_search_map_data, \n                         aes(x = long, y = lat, group = group, fill = fam_search)) +\n  geom_polygon(color = \"white\", linewidth = 0.2) +\n  coord_fixed(1.3) +\n  scale_fill_manual(\n    values = c(\n      \"permitted\" = \"#2E86AB\",      # Blue for permitted\n      \"prohibited\" = \"#F9A03F\",   # Orange for prohibited\n      \"unspecified\" = \"#CCCCCC\"  # Light gray for unspecified\n    ),\n    name = \"Familial Search Policy\",\n    drop = FALSE\n  ) +\n  labs(\n    title = \"Familial DNA Search Policies by State\",\n    subtitle = \"State policies regarding familial DNA searching in databases\",\n    caption = \"Source: SDIS Database Analysis\"\n  ) +\n  theme_void() +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, color = \"gray40\", size = 12),\n    legend.position = \"right\",\n    legend.title = element_text(face = \"bold\")\n  )\n\n# Display the visualizations\nprint(family_map_plot)\n\n\n\n\n\n\n\n\n\nShow family search policy visualization code\n# Create a comprehensive summary table\nsummary_table_data &lt;- family_search_summary %&gt;%\n  mutate(\n    state_list = map_chr(states, ~paste(.x, collapse = \", \")),\n    percentage = round(count / sum(count) * 100, 1),\n    icon = case_when(\n      fam_search == \"Allowed\" ~ \"ðŸ”µ\",\n      fam_search == \"Restricted\" ~ \"ðŸŸ \",\n      TRUE ~ \"âšª\"\n    )\n  ) %&gt;%\n  select(Icon = icon, Policy = fam_search, Count = count, Percentage = percentage, States = state_list)\n\n# Create a nice flextable for the report\nft &lt;- flextable(summary_table_data) %&gt;%\n  theme_zebra() %&gt;%\n  set_caption(\"Familial DNA Search Policy Status by State\") %&gt;%\n  autofit() %&gt;%\n  align(align = \"center\", part = \"all\") %&gt;%\n  align(align = \"left\", j = \"States\") %&gt;%\n  bg(j = \"Policy\", bg = function(x) {\n    case_when(\n      x == \"Permitted\" ~ \"#2E86AB\",\n      x == \"Prohibited\" ~ \"#F9A03F\",\n      TRUE ~ \"#CCCCCC\"\n    )\n  }) %&gt;%\n  color(j = \"Policy\", color = \"white\") %&gt;%\n  bold(j = \"Policy\") %&gt;%\n  fontsize(size = 11, part = \"all\") %&gt;%\n  width(j = \"States\", width = 3)\n\nft\n\n\nIconPolicyCountPercentageStatesâšªUnspecified3774Alabama, Alaska, Arizona, Connecticut, Delaware, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Massachusetts, Minnesota, Mississippi, Missouri, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Vermont, Washington, West VirginiaâšªPermitted1224Arkansas, California, Colorado, Florida, Michigan, Montana, New York, Texas, Utah, Virginia, Wisconsin, WyomingâšªProhibited12Maryland"
  },
  {
    "objectID": "analysis/sdis_summary.html#data-availability-overview",
    "href": "analysis/sdis_summary.html#data-availability-overview",
    "title": "SDIS Summary Analysis",
    "section": "Data Availability Overview",
    "text": "Data Availability Overview\nAssess the completeness of data across states, including which states are missing and the availability of key fields.\n\n\nShow overview code\n# Identify states present in the dataset\nstates_in_data &lt;- unique(sdis_data$state) %&gt;% sort()\n\n# Check if all 50 states are represented\nall_states &lt;- c('Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n                'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n                'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n                'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n                'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n                'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n                'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n                'Wisconsin', 'Wyoming')\n\nmissing_states &lt;- setdiff(all_states, states_in_data)\nif (length(missing_states) &gt; 0) {\n  cat(paste(\"\\nMissing states:\", paste(missing_states, collapse = \", \"), \"\\n\"))\n} else {\n  cat(\"\\nAll 50 states are represented in the dataset\\n\")\n}\n\n# Assess data completeness for each state\n# Improved heatmap with enhanced visualization\ndata_availability &lt;- sdis_data %&gt;%\n  group_by(state) %&gt;%\n  summarise(across(everything(), ~sum(!is.na(.)))) %&gt;%\n  select(-state) %&gt;%\n  as.data.frame()\n\nrownames(data_availability) &lt;- unique(sdis_data$state)\n\n# Generate visualization of data completeness\nkey_fields &lt;- c('n_total', 'n_arrestees', 'n_offenders', 'n_forensic')\n\n# Filter to include only key fields that exist in the data\navailable_key_fields &lt;- intersect(key_fields, names(data_availability))\n\nif (length(available_key_fields) &gt; 0) {\n  availability_subset &lt;- data_availability[, available_key_fields, drop = FALSE]\n  availability_binary &lt;- as.data.frame(ifelse(availability_subset &gt; 0, 1, 0))\n  \n  # Create heatmap data in long format\n  heatmap_long &lt;- availability_binary %&gt;%\n    rownames_to_column(\"state\") %&gt;%\n    pivot_longer(cols = -state, names_to = \"field\", values_to = \"available\") %&gt;%\n    mutate(\n      state = factor(state, levels = rownames(availability_binary)),\n      state = factor(state, levels = sort(unique(state), decreasing = TRUE)),\n      field = factor(field, levels = available_key_fields),\n      # Create labels with different symbols\n      label = case_when(\n        available == 1 ~ \"âœ“\",\n        available == 0 ~ \"!\",\n        TRUE ~ \"\"\n      ),\n      # Color coding for different values\n      fill_color = case_when(\n        available == 1 ~ \"Available\",\n        available == 0 ~ \"Missing\",\n        TRUE ~ \"Unknown\"\n      )\n    )\n  \n  # Create the enhanced heatmap\nggplot(heatmap_long, aes(x = field, y = state, fill = fill_color)) +\n  geom_tile(color = \"white\", linewidth = 0.8, width = 0.9, height = 0.9) +\n  geom_text(aes(label = label, color = fill_color), \n            size = 4, fontface = \"bold\", vjust = 0.8) +\n  scale_fill_manual(values = c(\n    \"Available\" = \"#2E86AB\",\n    \"Missing\" = \"#FF6B6B\",\n    \"Unknown\" = \"#f0f0f0\"\n  )) +\n  scale_color_manual(values = c(\n    \"Available\" = \"white\",\n    \"Missing\" = \"white\",\n    \"Unknown\" = \"gray30\"\n  )) +\n  labs(\n    title = \"Data Availability Heatmap by State\",\n    subtitle = \"âœ“ = Data available | ! = Data missing (0 values)\",\n    x = NULL,\n    y = NULL,\n    fill = \"Data Status\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, face = \"bold\"),\n    axis.text.x.top = element_text(angle = 45, hjust = 0, face = \"bold\"), \n    axis.text.y = element_text(face = \"bold\"),\n    axis.title.y = element_text(face = \"bold\", vjust = 0),\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, color = \"gray40\", size = 10),\n    panel.grid = element_blank(),\n    legend.position = \"top\",\n    legend.title = element_text(face = \"bold\"),\n    axis.ticks.x = element_line(),\n    axis.ticks.x.top = element_line()\n  ) +\n  guides(color = \"none\") +\n  coord_fixed() +\n  scale_x_discrete(position = \"top\")\n  \n} else {\n  message(\"No key fields available for heatmap visualization\")\n}\n\n\n\n\n\n\n\n\n\nShow overview code\n# Data coverage summary\ncat(\"\\nData field coverage across states:\\n\")\n\nkey_fields &lt;- c('n_total', 'n_arrestees', 'n_offenders', 'n_forensic', 'fam_search', 'collection_statute')\n\nfor (col in key_fields) {\n  if (col %in% names(sdis_data)) {\n    states_with_data &lt;- sum(!is.na(sdis_data[[col]]))\n    coverage_pct &lt;- states_with_data / length(states_in_data) * 100\n    cat(paste0(col, \": \", states_with_data, \" states (\", round(coverage_pct, 1), \"%)\\n\"))\n  }\n}\n\n\n\nAll 50 states are represented in the dataset\n\nData field coverage across states:\nn_total: 27 states (54%)\nn_arrestees: 23 states (46%)\nn_offenders: 16 states (32%)\nn_forensic: 11 states (22%)\nfam_search: 50 states (100%)\ncollection_statute: 50 states (100%)"
  },
  {
    "objectID": "analysis/sdis_summary.html#total-profile-calculations-verification",
    "href": "analysis/sdis_summary.html#total-profile-calculations-verification",
    "title": "SDIS Summary Analysis",
    "section": "Total Profile Calculations Verification",
    "text": "Total Profile Calculations Verification\nThis section examines states reporting n_total alongside component counts to determine whether totals represent:\n\nSum of all profile types including forensic (n_arrestees + n_offenders + n_forensic)\nSum of combined profiles only (n_arrestees + n_offenders)\n\n\n\nShow calculations code\n# Identify states with n_total and at least one component count\nstates_with_totals &lt;- sdis_data %&gt;%\n  filter(!is.na(n_total)) %&gt;%\n  mutate(\n    sum_all = rowSums(select(., n_arrestees, n_offenders, n_forensic), na.rm = TRUE),\n    sum_arrestees_offenders = rowSums(select(., n_arrestees, n_offenders), na.rm = TRUE),\n    # Check if all components are available\n    all_components_available = !is.na(n_arrestees) & !is.na(n_offenders) & !is.na(n_forensic),\n    both_arrestees_offenders = !is.na(n_arrestees) & !is.na(n_offenders)\n  )\n\n# Check matches with tolerance\ntolerance &lt;- 10\n\nstates_with_totals &lt;- states_with_totals %&gt;%\n  mutate(\n    matches_combined_forensic = ifelse(\n      all_components_available,\n      abs(n_total - sum_all) &lt;= tolerance,\n      FALSE\n    ),\n    matches_combined = ifelse(\n      both_arrestees_offenders,\n      (abs(n_total - sum_arrestees_offenders) &lt;= tolerance) & \n        (n_arrestees &gt; 0),\n      FALSE\n    )\n  )\n\n# Filter to states with at least one component count\nhas_components &lt;- states_with_totals %&gt;%\n  filter(!is.na(n_arrestees) | !is.na(n_offenders) | !is.na(n_forensic))\n\ncat(paste(\"States with n_total and component data:\", nrow(has_components), \"\\n\"))\ncat(\"\\nTotal calculation patterns:\\n\")\n\n# Categorize states\nincludes_all &lt;- has_components %&gt;% filter(matches_combined_forensic) %&gt;% pull(state)\nforensic_only &lt;- has_components %&gt;% filter(matches_combined & !matches_combined_forensic) %&gt;% pull(state)\nneither &lt;- has_components %&gt;% filter(!matches_combined_forensic & !matches_combined) %&gt;% pull(state)\n\nif (length(includes_all) &gt; 0) {\n  cat(\"\\nn_total matches combined profiles with forensic (arrestees + offenders + forensic):\\n\")\n  for (state in includes_all) {\n    cat(paste(\"  â€¢\", state, \"\\n\"))\n  }\n} else {\n  cat(\"\\nStates where n_total matches the sum of arrestees + offenders + forensic: None\\n\")\n}\n\nif (length(forensic_only) &gt; 0) {\n  cat(\"\\nStates where n_total includes combined profiles only (arrestees + offenders):\\n\")\n  for (state in forensic_only) {\n    cat(paste(\"  â€¢\", state, \"\\n\"))\n  }\n}\n\nif (length(neither) &gt; 0) {\n  cat(\"\\nStates where n_total does not match calculated sums:\\n\")\n  for (state in neither) {\n    state_data &lt;- has_components %&gt;% filter(state == !!state)\n    cat(paste0(\"  â€¢ \", state, \":\\n n_total=\", format(state_data$n_total, big.mark = \",\"), \n               \"\\n Sum_all=\", format(state_data$sum_all, big.mark = \",\"),\n               \"\\n Sum_arrestees_offenders =\", format(state_data$sum_arrestees_offenders, big.mark = \",\"), \"\\n\\n\"))\n  }\n}\n\n# Display detailed breakdown\ncat(\"\\nDetailed breakdown:\\n\")\nhas_components %&gt;%\n  select(state, n_total, n_arrestees, n_offenders, n_forensic, matches_combined_forensic, matches_combined) %&gt;%\n  mutate(across(where(is.numeric), ~ifelse(is.na(.), \"\", format(., big.mark = \",\")))) %&gt;%\n  flextable()\n\n\nStates with n_total and component data: 17 \n\nTotal calculation patterns:\n\nStates where n_total matches the sum of arrestees + offenders + forensic: None\n\nStates where n_total includes combined profiles only (arrestees + offenders):\n  â€¢ Alaska \n  â€¢ North Carolina \n  â€¢ Rhode Island \n  â€¢ Tennessee \n\nStates where n_total does not match calculated sums:\n  â€¢ California:\n n_total=3,365,402\n Sum_all=167,053\n Sum_arrestees_offenders =0\n\n  â€¢ Connecticut:\n n_total=127,940\n Sum_all=151,140\n Sum_arrestees_offenders =127,940\n\n  â€¢ Georgia:\n n_total=347,145\n Sum_all=347,145\n Sum_arrestees_offenders =324,864\n\n  â€¢ Idaho:\n n_total=39,000\n Sum_all=39,000\n Sum_arrestees_offenders =39,000\n\n  â€¢ Illinois:\n n_total=689,297\n Sum_all=759,224\n Sum_arrestees_offenders =689,297\n\n  â€¢ Indiana:\n n_total=449,000\n Sum_all=470,400\n Sum_arrestees_offenders =448,000\n\n  â€¢ Minnesota:\n n_total=180,000\n Sum_all=180,000\n Sum_arrestees_offenders =180,000\n\n  â€¢ Missouri:\n n_total=4e+05\n Sum_all=386,000\n Sum_arrestees_offenders =386,000\n\n  â€¢ Montana:\n n_total=32,284\n Sum_all=33,162\n Sum_arrestees_offenders =32,284\n\n  â€¢ South Carolina:\n n_total=175,629\n Sum_all=11,127\n Sum_arrestees_offenders =0\n\n  â€¢ Texas:\n n_total=1,308,774\n Sum_all=1,308,774\n Sum_arrestees_offenders =1,308,774\n\n  â€¢ Washington:\n n_total=272,000\n Sum_all=280,800\n Sum_arrestees_offenders =272,000\n\n  â€¢ West Virginia:\n n_total=47,444\n Sum_all=51,349\n Sum_arrestees_offenders =47,444\n\n\nDetailed breakdown:\n\n\nstaten_totaln_arresteesn_offendersn_forensicmatches_combined_forensicmatches_combinedAlaska   79,146 52,149   26,997  3,866FALSETRUECalifornia3,365,402167,053FALSEFALSEConnecticut  127,940  127,940 23,200FALSEFALSEGeorgia  347,145  324,864 22,281FALSEFALSEIdaho   39,000      0   39,000FALSEFALSEIllinois  689,297  689,297 69,927FALSEFALSEIndiana  449,000144,000  304,000 22,400FALSEFALSEMinnesota  180,000  180,000FALSEFALSEMissouri  400,000  386,000FALSEFALSEMontana   32,284      0   32,284    878FALSEFALSENorth Carolina  350,000 50,000  300,000FALSETRUERhode Island   27,818    484   27,334  1,798FALSETRUESouth Carolina  175,629 11,127FALSEFALSETennessee  518,614226,569  292,045FALSETRUETexas1,308,7741,308,774FALSEFALSEWashington  272,000      0  272,000  8,800FALSEFALSEWest Virginia   47,444      0   47,444  3,905FALSEFALSE"
  },
  {
    "objectID": "analysis/sdis_summary.html#analysis-of-database-totals-and-data-quality-issues",
    "href": "analysis/sdis_summary.html#analysis-of-database-totals-and-data-quality-issues",
    "title": "SDIS Summary Analysis",
    "section": "Analysis of Database Totals and Data Quality Issues",
    "text": "Analysis of Database Totals and Data Quality Issues\nExamine states where N_total values reveal potential data quality issues or reporting inconsistencies.\n\n\nShow data quality assessment code\n# Create enhanced data quality analysis\nsdis_enhanced &lt;- sdis_data %&gt;%\n  rename(n_total_reported = n_total)\n\n# Calculate different total relationships with small tolerance\ntolerance &lt;- 10\n\nsdis_enhanced &lt;- sdis_enhanced %&gt;%\n  mutate(\n    total_equals_offenders = ifelse(\n      !is.na(n_total_reported) & !is.na(n_offenders) & n_offenders &gt; 0,\n      abs(n_total_reported - n_offenders) &lt;= tolerance,\n      FALSE\n    ),\n    total_equals_off_arr = ifelse(\n      !is.na(n_total_reported) & !is.na(n_offenders) & !is.na(n_arrestees) &\n        n_offenders &gt; 0 & n_arrestees &gt; 0,\n      abs(n_total_reported - (n_offenders + n_arrestees)) &lt;= tolerance,\n      FALSE\n    ),\n    total_equals_all = ifelse(\n      !is.na(n_total_reported) & !is.na(n_offenders) & !is.na(n_arrestees) & \n        !is.na(n_forensic) & n_offenders &gt; 0 & n_arrestees &gt; 0 & n_forensic &gt; 0,\n      abs(n_total_reported - (n_offenders + n_arrestees + n_forensic)) &lt;= tolerance,\n      FALSE\n    ),\n    total_method = case_when(\n      total_equals_all ~ \"All components\",\n      total_equals_off_arr ~ \"Offenders + Arrestees\",\n      total_equals_offenders ~ \"Offenders only\",\n      TRUE ~ \"Unknown\"\n    )\n  )\n\n# Create n_total_estimated based on the rules specified\nsdis_enhanced &lt;- sdis_enhanced %&gt;%\n  mutate(\n    n_total_estimated = NA_real_,\n    n_total_estimated_comment = \"\"\n  )\n\n# Rule 1: States where n_total == n_offenders + n_arrestees\nmask_off_arr &lt;- sdis_enhanced$total_equals_off_arr\nsdis_enhanced$n_total_estimated[mask_off_arr] &lt;- sdis_enhanced$n_total_reported[mask_off_arr]\nsdis_enhanced$n_total_estimated_comment[mask_off_arr] &lt;- \"Used reported total (matches offenders + arrestees)\"\n\n# Rule 2: States where n_total == n_offenders + n_arrestees + n_forensic\nmask_all &lt;- sdis_enhanced$total_equals_all\nsdis_enhanced$n_total_estimated[mask_all] &lt;- sdis_enhanced$n_total_reported[mask_all] - sdis_enhanced$n_forensic[mask_all]\nsdis_enhanced$n_total_estimated_comment[mask_all] &lt;- \"Subtracted forensic from reported total\"\n\n# Rule 3: States where n_total == n_offenders\nmask_off_only &lt;- sdis_enhanced$total_equals_offenders\nsdis_enhanced$n_total_estimated[mask_off_only] &lt;- sdis_enhanced$n_total_reported[mask_off_only]\nsdis_enhanced$n_total_estimated_comment[mask_off_only] &lt;- \"Used reported total (matches offenders only)\"\n\n# Rule 4: For remaining states with n_total\nmask_total_only &lt;- !is.na(sdis_enhanced$n_total_reported) & \n  is.na(sdis_enhanced$n_total_estimated) &\n  (is.na(sdis_enhanced$n_arrestees) | sdis_enhanced$n_arrestees == 0) &\n  (is.na(sdis_enhanced$n_offenders) | sdis_enhanced$n_offenders == 0) &\n  (is.na(sdis_enhanced$n_forensic) | sdis_enhanced$n_forensic == 0)\n\nsdis_enhanced$n_total_estimated[mask_total_only] &lt;- sdis_enhanced$n_total_reported[mask_total_only]\nsdis_enhanced$n_total_estimated_comment[mask_total_only] &lt;- \"Total only reported (no breakdown available)\"\n\n# Special case: States with n_total and n_forensic only\nmask_total_forensic_only &lt;- !is.na(sdis_enhanced$n_total_reported) & \n  is.na(sdis_enhanced$n_total_estimated) &\n  (is.na(sdis_enhanced$n_arrestees) | sdis_enhanced$n_arrestees == 0) &\n  (is.na(sdis_enhanced$n_offenders) | sdis_enhanced$n_offenders == 0) &\n  !is.na(sdis_enhanced$n_forensic) & sdis_enhanced$n_forensic &gt; 0\n\nsdis_enhanced$n_total_estimated[mask_total_forensic_only] &lt;- sdis_enhanced$n_total_reported[mask_total_forensic_only]\nsdis_enhanced$n_total_estimated_comment[mask_total_forensic_only] &lt;- \"Total only reported (forensic reported separately)\"\n\n# States with total and some components but unclear calculation\nmask_has_total_unclear &lt;- !is.na(sdis_enhanced$n_total_reported) & is.na(sdis_enhanced$n_total_estimated)\nsdis_enhanced$n_total_estimated[mask_has_total_unclear] &lt;- sdis_enhanced$n_total_reported[mask_has_total_unclear]\nsdis_enhanced$n_total_estimated_comment[mask_has_total_unclear] &lt;- \"Total with discrepancy (calculation unclear)\"\n\n# For states without any total but with offenders and arrestees\nmask_no_total &lt;- is.na(sdis_enhanced$n_total_reported) & \n  !is.na(sdis_enhanced$n_offenders) & sdis_enhanced$n_offenders &gt; 0 &\n  !is.na(sdis_enhanced$n_arrestees) & sdis_enhanced$n_arrestees &gt; 0\n\nsdis_enhanced$n_total_estimated[mask_no_total] &lt;- sdis_enhanced$n_offenders[mask_no_total] + sdis_enhanced$n_arrestees[mask_no_total]\nsdis_enhanced$n_total_estimated_comment[mask_no_total] &lt;- \"Calculated from offenders + arrestees (no total reported)\"\n\n# For states without total but with only offenders &gt; 0\nmask_no_total_off_only &lt;- is.na(sdis_enhanced$n_total_reported) & \n  !is.na(sdis_enhanced$n_offenders) & sdis_enhanced$n_offenders &gt; 0 &\n  (is.na(sdis_enhanced$n_arrestees) | sdis_enhanced$n_arrestees == 0)\n\nsdis_enhanced$n_total_estimated[mask_no_total_off_only] &lt;- sdis_enhanced$n_offenders[mask_no_total_off_only]\nsdis_enhanced$n_total_estimated_comment[mask_no_total_off_only] &lt;- \"Used offenders count (no total reported, no arrestee data)\"\n\n# Create enhanced data availability matrix with better visualization\navailability_matrix &lt;- sdis_enhanced %&gt;%\n  transmute(\n    State = state,\n    Arrestees = ifelse(!is.na(n_arrestees) & n_arrestees &gt; 0, \"âœ“\", \"!\"),\n    Offenders = ifelse(!is.na(n_offenders) & n_offenders &gt; 0, \"âœ“\", \"!\"),\n    Forensic = ifelse(!is.na(n_forensic) & n_forensic &gt; 0, \"âœ“\", \"!\"),\n    `Total Reported` = ifelse(!is.na(n_total_reported), \"âœ“\", \"!\"),\n    `Total Method` = case_when(\n      total_method == \"Offenders only\" ~ \"O\",\n      total_method == \"Offenders + Arrestees\" ~ \"O+A\",\n      total_method == \"All components\" ~ \"All\",\n      TRUE ~ \"?\"\n    )\n  )\n\n# Convert to long format for ggplot\navailability_long &lt;- availability_matrix %&gt;%\n  pivot_longer(cols = -State, names_to = \"Field\", values_to = \"Value\") %&gt;%\n  mutate(\n    State = factor(State, levels = sort(unique(State), decreasing = TRUE)),\n    Field = factor(Field, levels = c(\"Arrestees\", \"Offenders\", \"Forensic\", \"Total Reported\", \"Total Method\")),\n    # Create numeric values for coloring\n    NumericValue = case_when(\n      Value == \"âœ“\" ~ 1,\n      Value == \"!\" ~ 0,\n      Value == \"O\" ~ 2,\n      Value == \"O+A\" ~ 3,\n      Value == \"All\" ~ 4,\n      Value == \"?\" ~ 0,\n      TRUE ~ 0\n    ),\n    # Create display labels\n    DisplayLabel = case_when(\n      Field == \"Total Method\" & Value == \"?\" ~ \"?\",\n      Field == \"Total Method\" ~ Value,\n      TRUE ~ Value\n    )\n  )\n\n# Summary of how n_total_estimated was calculated\ncat(\"n_total_estimated Column Calculation Summary:\\n\")\ncat(\"=\", strrep(\"=\", 48), \"\\n\", sep = \"\")\n\n# Group states by how their n_total_estimated was determined\nestimation_groups &lt;- sdis_enhanced %&gt;%\n  group_by(n_total_estimated_comment) %&gt;%\n  summarise(\n    states = list(state),\n    count = n(),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(count))\n\n# Print summary in organized sections\ncat(\"\\n1. States with n_total reported and matching patterns:\\n\")\nmatching_patterns &lt;- estimation_groups %&gt;%\n  filter(str_detect(n_total_estimated_comment, \"matches|Subtracted\"))\nfor (i in 1:nrow(matching_patterns)) {\n  group &lt;- matching_patterns[i, ]\n  cat(sprintf(\"   â€¢ %s: %d states \\n(%s)\\n\", \n              group$n_total_estimated_comment, \n              group$count,\n              paste(unlist(group$states), collapse = \", \")))\n}\n\ncat(\"\\n2. States with only n_total reported (no breakdown):\\n\")\ntotal_only &lt;- estimation_groups %&gt;%\n  filter(str_detect(n_total_estimated_comment, \"Total only reported\"))\nfor (i in 1:nrow(total_only)) {\n  group &lt;- total_only[i, ]\n  cat(sprintf(\"   â€¢ %s: %d states \\n(%s)\\n\", \n              group$n_total_estimated_comment, \n              group$count,\n              paste(unlist(group$states), collapse = \", \")))\n}\n\ncat(\"\\n3. States without n_total reported (calculated):\\n\")\ncalculated &lt;- estimation_groups %&gt;%\n  filter(str_detect(n_total_estimated_comment, \"Calculated|Used offenders count\"))\nfor (i in 1:nrow(calculated)) {\n  group &lt;- calculated[i, ]\n  cat(sprintf(\"   â€¢ %s: %d states (%s)\\n\", \n              group$n_total_estimated_comment, \n              group$count,\n              paste(unlist(group$states), collapse = \", \")))\n}\n\ncat(\"\\n4. States with unclear calculation patterns:\\n\")\nunclear &lt;- estimation_groups %&gt;%\n  filter(str_detect(n_total_estimated_comment, \"discrepancy|unclear\"))\nfor (i in 1:nrow(unclear)) {\n  group &lt;- unclear[i, ]\n  cat(sprintf(\"   â€¢ %s: %d states (%s)\\n\", \n              group$n_total_estimated_comment, \n              group$count,\n              paste(unlist(group$states), collapse = \", \")))\n  \n  # Show details for unclear states\n  unclear_states &lt;- sdis_enhanced %&gt;% \n    filter(state %in% unlist(group$states)) %&gt;%\n    select(state, n_total_reported, n_offenders, n_arrestees, n_forensic)\n  \n  for (j in 1:nrow(unclear_states)) {\n    s &lt;- unclear_states[j, ]\n    cat(sprintf(\"      - %s: Total=%s, Offenders=%s, Arrestees=%s, Forensic=%s\\n\",\n                s$state, \n                format(s$n_total_reported %||% 0, big.mark = \",\"),\n                format(s$n_offenders %||% 0, big.mark = \",\"),\n                format(s$n_arrestees %||% 0, big.mark = \",\"),\n                format(s$n_forensic %||% 0, big.mark = \",\")))\n  }\n}\n\n# Create enhanced heatmap with legend at top and x-labels on both top and bottom\np &lt;- ggplot(availability_long, aes(x = Field, y = State, fill = factor(NumericValue))) +\n  geom_tile(color = \"white\", linewidth = 0.8, width = 0.9, height = 0.9) +\n  geom_text(aes(label = DisplayLabel, color = factor(NumericValue)), \n            size = 3.5, fontface = \"bold\", vjust = 0.8) +\n  scale_fill_manual(\n    name = \"Legend\",\n    values = c(\n      \"0\" = \"#FF6B6B\",      # Red/Orange for missing/unknown\n      \"1\" = \"#2E86AB\",      # Blue for available\n      \"2\" = \"#4ECDC4\",      # Teal for Offenders only\n      \"3\" = \"#45B7D1\",      # Light blue for Offenders + Arrestees\n      \"4\" = \"#1A535C\"       # Dark teal for All components\n    ),\n    labels = c(\n      \"0\" = \"Missing/Unknown data\",\n      \"1\" = \"Data available\",\n      \"2\" = \"Total = Offenders only\",\n      \"3\" = \"Total = Offenders + Arrestees\",\n      \"4\" = \"Total = All components\"\n    )\n  ) +\n  scale_color_manual(values = c(\n    \"0\" = \"white\",        # White text on red\n    \"1\" = \"white\",        # White text on blue\n    \"2\" = \"white\",        # White text on teal\n    \"3\" = \"white\",        # White text on light blue\n    \"4\" = \"white\"         # White text on dark teal\n  )) +\n  labs(\n    title = \"Data Field Availability and Total Calculation Method\",\n    subtitle = \"âœ“ = Available | ! = Missing | O = Offenders only | O+A = Offenders + Arrestees | All = All components\",\n    x = \"\", \n    y = \"\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, face = \"bold\"),\n    axis.text.x.top = element_text(angle = 45, hjust = 0, face = \"bold\"),\n    axis.text.y = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 14),\n    plot.subtitle = element_text(hjust = 0.5, color = \"gray40\", size = 9),\n    panel.grid = element_blank(),\n    legend.position = \"top\",\n    legend.title = element_text(face = \"bold\"),\n    legend.text = element_text(size = 9),\n    axis.ticks.x = element_line(),\n    axis.ticks.x.top = element_line()\n  ) +\n  guides(color = \"none\") +\n  coord_fixed() +\n  scale_x_discrete(position = \"top\")\n\n# Update the main dataframe for subsequent analyses\nsdis_data &lt;- sdis_enhanced\n\n# Helper function for null coalescing\n`%||%` &lt;- function(a, b) if (!is.null(a) && !is.na(a)) a else b\n\n\nn_total_estimated Column Calculation Summary:\n=================================================\n\n1. States with n_total reported and matching patterns:\n   â€¢ Used reported total (matches offenders only): 8 states \n(Connecticut, Idaho, Illinois, Minnesota, Montana, Texas, Washington, West Virginia)\n   â€¢ Used reported total (matches offenders + arrestees): 4 states \n(Alaska, North Carolina, Rhode Island, Tennessee)\n\n2. States with only n_total reported (no breakdown):\n   â€¢ Total only reported (no breakdown available): 10 states \n(Alabama, Arkansas, Colorado, Florida, Louisiana, Mississippi, Nevada, New Jersey, South Dakota, Virginia)\n   â€¢ Total only reported (forensic reported separately): 2 states \n(California, South Carolina)\n\n3. States without n_total reported (calculated):\n   â€¢ Calculated from offenders + arrestees (no total reported): 1 states (Maryland)\n\n4. States with unclear calculation patterns:\n   â€¢ Total with discrepancy (calculation unclear): 3 states (Georgia, Indiana, Missouri)\n      - Georgia: Total=347,145, Offenders=324,864, Arrestees=NA, Forensic=22,281\n      - Indiana: Total=449,000, Offenders=304,000, Arrestees=144,000, Forensic=22,400\n      - Missouri: Total=4e+05, Offenders=386,000, Arrestees=NA, Forensic=NA\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow summary visualization code\n# Create summary data\nsummary_data &lt;- sdis_data %&gt;%\n  mutate(\n    data_category = case_when(\n      str_detect(n_total_estimated_comment, \"matches offenders only\") ~ \"Matches Offenders Only\",\n      str_detect(n_total_estimated_comment, \"matches offenders \\\\+ arrestees\") ~ \"Matches Offenders + Arrestees\",\n      str_detect(n_total_estimated_comment, \"Total only reported \\\\(no breakdown\\\\)\") ~ \"Total Only (No Breakdown)\",\n      str_detect(n_total_estimated_comment, \"Total only reported \\\\(forensic\") ~ \"Total Only (Forensic Separate)\",\n      str_detect(n_total_estimated_comment, \"Calculated from offenders \\\\+ arrestees\") ~ \"Calculated (Offenders + Arrestees)\",\n      str_detect(n_total_estimated_comment, \"Used offenders count\") ~ \"Calculated (Offenders Only)\",\n      str_detect(n_total_estimated_comment, \"discrepancy|unclear\") ~ \"Unclear Calculation\",\n      TRUE ~ \"Other\"\n    ),\n    has_arrestees = !is.na(n_arrestees) & n_arrestees &gt; 0,\n    has_offenders = !is.na(n_offenders) & n_offenders &gt; 0,\n    has_forensic = !is.na(n_forensic) & n_forensic &gt; 0,\n    has_total_reported = !is.na(n_total_reported)\n  )\n\n# Create a summary table by category\ncategory_summary &lt;- summary_data %&gt;%\n  group_by(data_category) %&gt;%\n  summarise(\n    count = n(),\n    states = paste(sort(state), collapse = \", \"),\n    avg_total = mean(n_total_estimated, na.rm = TRUE),\n    median_total = median(n_total_estimated, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(count))\n\n# Print summary statistics\ncat(\"SUMMARY STATISTICS\\n\")\ncat(\"=================\\n\\n\")\n\ncat(\"Calculation Methods Distribution:\\n\")\nfor (i in 1:nrow(category_summary)) {\n  cat(sprintf(\"\\n%s: %d states (%s)\\n\", \n              category_summary$data_category[i], \n              category_summary$count[i],\n              category_summary$states[i]))\n}\n\ncat(\"\\nOverall Data Availability:\\n\")\ncat(sprintf(\"States with arrestee data: %d\\n\", sum(summary_data$has_arrestees)))\ncat(sprintf(\"States with offender data: %d\\n\", sum(summary_data$has_offenders)))\ncat(sprintf(\"States with forensic data: %d\\n\", sum(summary_data$has_forensic)))\ncat(sprintf(\"States with total reported: %d\\n\", sum(summary_data$has_total_reported)))\n\n\nSUMMARY STATISTICS\n=================\n\nCalculation Methods Distribution:\n\nOther: 32 states (Alabama, Arizona, Arkansas, Colorado, Delaware, Florida, Hawaii, Iowa, Kansas, Kentucky, Louisiana, Maine, Massachusetts, Michigan, Mississippi, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, South Dakota, Utah, Vermont, Virginia, Wisconsin, Wyoming)\n\nMatches Offenders Only: 8 states (Connecticut, Idaho, Illinois, Minnesota, Montana, Texas, Washington, West Virginia)\n\nMatches Offenders + Arrestees: 4 states (Alaska, North Carolina, Rhode Island, Tennessee)\n\nUnclear Calculation: 3 states (Georgia, Indiana, Missouri)\n\nTotal Only (Forensic Separate): 2 states (California, South Carolina)\n\nCalculated (Offenders + Arrestees): 1 states (Maryland)\n\nOverall Data Availability:\nStates with arrestee data: 6\nStates with offender data: 16\nStates with forensic data: 11\nStates with total reported: 27"
  },
  {
    "objectID": "analysis/sdis_summary.html#export-enhanced-dataset",
    "href": "analysis/sdis_summary.html#export-enhanced-dataset",
    "title": "SDIS Summary Analysis",
    "section": "Export Enhanced Dataset",
    "text": "Export Enhanced Dataset\nExport the enhanced dataset with the new n_total_estimated values and documentation.\n\n\nShow exportation code\n# Prepare final dataset with key columns in logical order\nfinal_columns &lt;- c(\n  'state', \n  'n_total_estimated',\n  'n_total_reported',\n  'n_arrestees', \n  'n_offenders', \n  'n_forensic',\n  'fam_search',\n  'collection_statute',\n  'n_total_estimated_comment',\n  'total_method'\n)\n\n# Select columns that exist in the dataset\navailable_columns &lt;- intersect(final_columns, names(sdis_enhanced))\nsdis_final &lt;- sdis_enhanced %&gt;% select(all_of(available_columns))\n\n# Export to CSV\noutput_path &lt;- file.path(here(\"output\", \"sdis\", \"sdis_clean.csv\"))\nwrite_csv(sdis_final, output_path)\ncat(paste(\"Exported enhanced SDIS dataset to:\", output_path, \"\\n\"))\n\n# Display final summary statistics\ncat(\"\\n\\nFinal Summary Statistics:\\n\")\ncat(\"=\", strrep(\"=\", 48), \"\\n\", sep = \"\")\ncat(paste(\"Total states in dataset:\", nrow(sdis_final), \"\\n\"))\ncat(paste(\"States with n_total_estimated:\", sum(!is.na(sdis_final$n_total_estimated)), \"\\n\"))\ncat(paste(\"States with n_total_reported:\", sum(!is.na(sdis_final$n_total_reported)), \"\\n\"))\ncat(paste(\"Total profiles (estimated):\", format(sum(sdis_final$n_total_estimated, na.rm = TRUE), big.mark = \",\"), \"\\n\"))\n\n# Prepare the data for the interactive table\nsummary_table &lt;- sdis_data %&gt;%\n  select(state, n_total_estimated, n_total_reported, n_offenders, n_arrestees, \n         n_forensic, n_total_estimated_comment) %&gt;%\n  mutate(across(where(is.numeric), ~ifelse(is.na(.), NA, format(., big.mark = \",\", scientific = FALSE))))\n\n# Create interactive table\ndatatable(\n  summary_table,\n  extensions = c('Buttons', 'ColReorder', 'Scroller'),\n  options = list(\n    dom = 'Bfrtip',\n    buttons = c('copy', 'csv', 'excel', 'colvis'),\n    scrollX = TRUE,\n    scrollY = \"600px\",\n    scroller = TRUE,\n    pageLength = 20,\n    columnDefs = list(\n      list(className = 'dt-right', targets = 1:5),  # Right-align numeric columns\n      list(className = 'dt-left', targets = c(0, 6))  # Left-align state and comment columns\n    )\n  ),\n  rownames = FALSE,\n  filter = 'top',\n  caption = \"Enhanced Data with Estimated Totals\"\n)\n\n\nExported enhanced SDIS dataset to: C:/Users/Donadio/Documents/PODFRIDGE-3/PODFRIDGE-Databases/output/sdis/sdis_clean.csv \n\n\nFinal Summary Statistics:\n=================================================\nTotal states in dataset: 50 \nStates with n_total_estimated: 28 \nStates with n_total_reported: 27 \nTotal profiles (estimated): 12,814,222"
  },
  {
    "objectID": "analysis/appendix_analysis.html",
    "href": "analysis/appendix_analysis.html",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "",
    "text": "This document provides complete transparency regarding the data sources and methodology used to compile racial disparities in DNA collection across U.S. states. The original data was collected in Summer 2017, with most data points from 2013-2016.\n\n\n\nConsistent racial disparities: Black populations show the highest DNA collection rates relative to their population percentage in nearly all states\nData limitations: Many states lack comprehensive conviction data, requiring the use of prison admission proxies\nMethodological challenges: Hispanic/Latino populations often uncounted or miscategorized in state data"
  },
  {
    "objectID": "analysis/appendix_analysis.html#executive-summary",
    "href": "analysis/appendix_analysis.html#executive-summary",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "",
    "text": "This document provides complete transparency regarding the data sources and methodology used to compile racial disparities in DNA collection across U.S. states. The original data was collected in Summer 2017, with most data points from 2013-2016.\n\n\n\nConsistent racial disparities: Black populations show the highest DNA collection rates relative to their population percentage in nearly all states\nData limitations: Many states lack comprehensive conviction data, requiring the use of prison admission proxies\nMethodological challenges: Hispanic/Latino populations often uncounted or miscategorized in state data"
  },
  {
    "objectID": "analysis/appendix_analysis.html#methodology-overview",
    "href": "analysis/appendix_analysis.html#methodology-overview",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "Methodology Overview",
    "text": "Methodology Overview\n\nData Collection Period\n\nPrimary collection: Summer 2017\nData years used: Single year per state (2012-2016, varies by availability)\nCensus baseline: 2010 U.S. Census for demographic comparisons\n\n\n\nGeneral Challenges Encountered\n\nConviction Data Scarcity: Most states do not publicly disclose comprehensive felony conviction data\nPrison Admission Proxy: Prison admissions used as substitute for conviction data in majority of states\nRacial Classification Inconsistencies:\n\n-   Many states only report \"Black\" and \"White\" categories\n\n-   Hispanic/Latino often classified as ethnicity rather than race\n\n-   \"Other\" category frequently used without specification\n\nArrest Data Gaps: Racial makeup of arrests often unavailable or incomplete"
  },
  {
    "objectID": "analysis/appendix_analysis.html#national-summary-table",
    "href": "analysis/appendix_analysis.html#national-summary-table",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "National Summary Table",
    "text": "National Summary Table\n\n\nShow summary code\n# Function to parse DNA collection data from text file\nparse_dna_data &lt;- function(file_path) {\n  \n  # Read the entire file\n  text_data &lt;- readLines(file_path, warn = FALSE)\n  \n  # Remove empty lines\n  text_data &lt;- text_data[text_data != \"\"]\n  \n  # Initialize list to store parsed data\n  parsed_data &lt;- list()\n  \n  # State abbreviations (for reference)\n  state_abbrevs &lt;- c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n                     \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n                     \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n                     \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n                     \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\")\n  \n  # Function to extract percentage and count from patterns like \"46% B (18,253)\"\n  extract_race_data &lt;- function(text, race_letter) {\n    pattern &lt;- paste0(\"([0-9.]+)%\\\\s*\", race_letter, \"\\\\s*\\\\(([0-9,]+)\\\\)\")\n    matches &lt;- str_match(text, pattern)\n    if (!is.na(matches[1])) {\n      pct &lt;- as.numeric(matches[2])\n      count &lt;- as.numeric(gsub(\",\", \"\", matches[3]))\n      return(list(pct = pct, count = count))\n    }\n    return(list(pct = NA, count = NA))\n  }\n  \n  # Function to extract just percentage (for demographics and collection rates)\n  extract_percentage &lt;- function(text, race_letter) {\n    pattern &lt;- paste0(\"([0-9.]+)%\\\\s*\", race_letter)\n    matches &lt;- str_match(text, pattern)\n    if (!is.na(matches[1])) {\n      return(as.numeric(matches[2]))\n    }\n    return(NA)\n  }\n  \n  # Process each line\n  i &lt;- 1\n  while (i &lt;= length(text_data)) {\n    line &lt;- text_data[i]\n    \n    # Check if line is a state abbreviation\n    if (line %in% state_abbrevs) {\n      state &lt;- line\n      \n      # Initialize data structure for this state\n      state_data &lt;- list(\n        State = state,\n        Black_DNA_Pct = NA, Black_DNA_N = NA,\n        Hispanic_DNA_Pct = NA, Hispanic_DNA_N = NA,\n        Asian_DNA_Pct = NA, Asian_DNA_N = NA,\n        Native_American_DNA_Pct = NA, Native_American_DNA_N = NA,\n        White_DNA_Pct = NA, White_DNA_N = NA,\n        Black_Pop_Pct = NA, Hispanic_Pop_Pct = NA, Asian_Pop_Pct = NA,\n        Native_American_Pop_Pct = NA, White_Pop_Pct = NA,\n        Black_Collection_Rate = NA, Hispanic_Collection_Rate = NA,\n        Asian_Collection_Rate = NA, Native_American_Collection_Rate = NA,\n        White_Collection_Rate = NA\n      )\n      \n      # Collect all lines for this state until we hit the next state or end of file\n      state_lines &lt;- c()\n      i &lt;- i + 1\n      while (i &lt;= length(text_data) && !(text_data[i] %in% state_abbrevs)) {\n        state_lines &lt;- c(state_lines, text_data[i])\n        i &lt;- i + 1\n      }\n      \n      # Combine all lines for this state into one text block\n      state_text &lt;- paste(state_lines, collapse = \" \")\n      \n      # Split into sections based on the pattern of % B occurrences\n      # We need to identify the three sections: DNA Collection, Demographics, Collection Rates\n      \n      # Find all \"% B\" patterns to help identify sections\n      b_patterns &lt;- str_locate_all(state_text, \"[0-9.]+%\\\\s*B\")[[1]]\n      \n      if (nrow(b_patterns) &gt;= 1) {\n        # First section: DNA Collection (has counts in parentheses)\n        dna_section_start &lt;- 1\n        dna_section_end &lt;- if(nrow(b_patterns) &gt;= 2) b_patterns[2,1] - 1 else nchar(state_text)\n        dna_section &lt;- substr(state_text, dna_section_start, dna_section_end)\n        \n        # Extract DNA collection data (with counts)\n        black_dna &lt;- extract_race_data(dna_section, \"B\")\n        hispanic_dna &lt;- extract_race_data(dna_section, \"H\")\n        asian_dna &lt;- extract_race_data(dna_section, \"A\")\n        native_dna &lt;- extract_race_data(dna_section, \"N\")\n        white_dna &lt;- extract_race_data(dna_section, \"W\")\n        \n        state_data$Black_DNA_Pct &lt;- black_dna$pct\n        state_data$Black_DNA_N &lt;- black_dna$count\n        state_data$Hispanic_DNA_Pct &lt;- hispanic_dna$pct\n        state_data$Hispanic_DNA_N &lt;- hispanic_dna$count\n        state_data$Asian_DNA_Pct &lt;- asian_dna$pct\n        state_data$Asian_DNA_N &lt;- asian_dna$count\n        state_data$Native_American_DNA_Pct &lt;- native_dna$pct\n        state_data$Native_American_DNA_N &lt;- native_dna$count\n        state_data$White_DNA_Pct &lt;- white_dna$pct\n        state_data$White_DNA_N &lt;- white_dna$count\n      }\n      \n      if (nrow(b_patterns) &gt;= 2) {\n        # Second section: Demographics (percentages only, no parentheses)\n        demo_section_start &lt;- b_patterns[2,1]\n        demo_section_end &lt;- if(nrow(b_patterns) &gt;= 3) b_patterns[3,1] - 1 else nchar(state_text)\n        demo_section &lt;- substr(state_text, demo_section_start, demo_section_end)\n        \n        # Extract demographic percentages\n        state_data$Black_Pop_Pct &lt;- extract_percentage(demo_section, \"B\")\n        state_data$Hispanic_Pop_Pct &lt;- extract_percentage(demo_section, \"H\")\n        state_data$Asian_Pop_Pct &lt;- extract_percentage(demo_section, \"A\")\n        state_data$Native_American_Pop_Pct &lt;- extract_percentage(demo_section, \"N\")\n        state_data$White_Pop_Pct &lt;- extract_percentage(demo_section, \"W\")\n      }\n      \n      if (nrow(b_patterns) &gt;= 3) {\n        # Third section: Collection Rates (percentages only, no parentheses)\n        rate_section_start &lt;- b_patterns[3,1]\n        rate_section &lt;- substr(state_text, rate_section_start, nchar(state_text))\n        \n        # Extract collection rate percentages\n        state_data$Black_Collection_Rate &lt;- extract_percentage(rate_section, \"B\")\n        state_data$Hispanic_Collection_Rate &lt;- extract_percentage(rate_section, \"H\")\n        state_data$Asian_Collection_Rate &lt;- extract_percentage(rate_section, \"A\")\n        state_data$Native_American_Collection_Rate &lt;- extract_percentage(rate_section, \"N\")\n        state_data$White_Collection_Rate &lt;- extract_percentage(rate_section, \"W\")\n      }\n      \n      # Add to parsed data\n      parsed_data[[length(parsed_data) + 1]] &lt;- state_data\n      \n      # Don't increment i here since we already did it in the while loop\n      i &lt;- i - 1\n    }\n    \n    i &lt;- i + 1\n  }\n  \n  # Convert to data frame\n  df &lt;- do.call(rbind, lapply(parsed_data, data.frame))\n  \n  return(df)\n}\n\ndata_path &lt;- file.path(here(\"raw\", \"foia_pdfs\", \"MurphyTong_Racial_Breakdown.txt\"))\n\nsummary_data &lt;- parse_dna_data(data_path)\n\n# Display interactive table\ndatatable(summary_data, \n          options = list(pageLength = 10, scrollX = TRUE),\n          caption = \"Complete state-by-state breakdown of DNA collection by race\")\n\n\n\n\nTableÂ 1: Racial Breakdown of Annual DNA Collection for Each State"
  },
  {
    "objectID": "analysis/appendix_analysis.html#disparity-analysis",
    "href": "analysis/appendix_analysis.html#disparity-analysis",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "Disparity Analysis",
    "text": "Disparity Analysis\n\n\nShow disparity analysis code\n# Calculate disparity ratios\ndisparity_data &lt;- summary_data %&gt;%\n  filter(!is.na(Black_Collection_Rate) & !is.na(White_Collection_Rate)) %&gt;%\n  mutate(Black_White_Ratio = Black_Collection_Rate / White_Collection_Rate) %&gt;%\n  arrange(desc(Black_White_Ratio))\n\n# Create visualization\nggplot(disparity_data %&gt;% head(20), aes(x = reorder(State, Black_White_Ratio), y = Black_White_Ratio)) +\n  geom_bar(stat = \"identity\", fill = \"darkred\") +\n  coord_flip() +\n  labs(title = \"Top 20 States: Black-White DNA Collection Disparity Ratio\",\n       subtitle = \"Ratio of collection rates (higher = greater disparity)\",\n       x = \"State\",\n       y = \"Black/White Collection Rate Ratio\") +\n  theme_minimal() +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"gray50\")\n\n\n\n\n\n\n\n\nFigureÂ 1: DNA Collection Rates by Race Relative to Population Percentage"
  },
  {
    "objectID": "analysis/appendix_analysis.html#state-by-state-detailed-methodology",
    "href": "analysis/appendix_analysis.html#state-by-state-detailed-methodology",
    "title": "Transparency Appendix from Murphy & Tong Study",
    "section": "State-by-State Detailed Methodology",
    "text": "State-by-State Detailed Methodology\n\n\nShow paragraph extraction code\n# Pre-define all 50 U.S. states\nus_states &lt;- c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \n               \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n               \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \n               \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \n               \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \n               \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n               \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \n               \"Wisconsin\", \"Wyoming\")\n\n# Read the text file\ndata_file &lt;- file.path(here(\"raw\", \"foia_pdfs\", \"MurphyTong_States_Paragraphs.txt\"))\n\ntext_content &lt;- readLines(data_file, warn = FALSE)\n\n# Combine all lines into a single string\nfull_text &lt;- paste(text_content, collapse = \"\\n\")\n\n# Create a pattern to match state names\nstate_pattern &lt;- paste0(\"\\\\b(\", paste(us_states, collapse = \"|\"), \")\\\\b\")\nstate_matches &lt;- str_locate_all(full_text, state_pattern)[[1]]\n\n# Extract state sections\nstate_sections &lt;- list()\nstate_names &lt;- character()\n\nif (nrow(state_matches) &gt; 0) {\n  for (i in 1:nrow(state_matches)) {\n    start_pos &lt;- state_matches[i, \"start\"]\n    if (i &lt; nrow(state_matches)) {\n      end_pos &lt;- state_matches[i + 1, \"start\"] - 1\n    } else {\n      end_pos &lt;- nchar(full_text)\n    }\n    \n    state_name &lt;- substr(full_text, start_pos, state_matches[i, \"end\"])\n    state_content &lt;- substr(full_text, start_pos, end_pos)\n    \n    state_names &lt;- c(state_names, state_name)\n    state_sections &lt;- c(state_sections, state_content)\n  }\n}\n\n# Function to extract information from each state section\nparse_state_section &lt;- function(section, state_name) {\n  if (is.na(state_name)) return(NULL)\n  \n  # Extract legal framework\n  legal_framework &lt;- str_extract(section, \"Legal Framework:[^\\n]+\") %&gt;%\n    {ifelse(is.na(.), NA, str_remove(., \"Legal Framework:\") %&gt;% str_trim())}\n  \n  # Extract collection triggers\n  collection_triggers &lt;- str_extract(section, \"Collection Triggers:[^\\n]+\") %&gt;%\n    {ifelse(is.na(.), NA, str_remove(., \"Collection Triggers:\") %&gt;% str_trim())}\n  \n  # Extract data sources - capture everything until Source URLs or Data Limitations\n  data_sources_text &lt;- str_extract(section, \"Data Sources:[\\\\s\\\\S]*?(?=Source URLs:|Data Limitations:|$)\")\n  data_source_df &lt;- tibble(data_source_type = NA_character_, data_source_note = NA_character_)\n  \n  if (!is.na(data_sources_text)) {\n    data_sources_text &lt;- str_remove(data_sources_text, \"Data Sources:\") %&gt;% str_trim()\n    # Split by newlines and clean up\n    data_source_lines &lt;- str_split(data_sources_text, \"\\\\n\")[[1]] %&gt;% \n      str_trim() %&gt;% \n      discard(~ .x == \"\" | str_detect(.x, \"^Source URLs:|^Data Limitations:\"))\n    \n    if (length(data_source_lines) &gt; 0) {\n      data_source_df &lt;- map_df(data_source_lines, function(line) {\n        if (str_detect(line, \":\")) {\n          tibble(\n            data_source_type = str_extract(line, \"^[^:]+\") %&gt;% str_trim(),\n            data_source_note = str_remove(line, \"^[^:]+:\") %&gt;% str_trim()\n          )\n        } else {\n          tibble(\n            data_source_type = line,\n            data_source_note = NA_character_\n          )\n        }\n      })\n    }\n  }\n  \n  # Extract source URLs\n  source_urls_text &lt;- str_extract(section, \"Source URLs:[\\\\s\\\\S]*?(?=Data Limitations:|$)\")\n  source_urls &lt;- character(0)\n  \n  if (!is.na(source_urls_text)) {\n    source_urls_text &lt;- str_remove(source_urls_text, \"Source URLs:\") %&gt;% str_trim()\n    source_url_lines &lt;- str_split(source_urls_text, \"\\\\n\")[[1]] %&gt;% \n      str_trim() %&gt;% \n      discard(~ .x == \"\" | str_detect(.x, \"^Data Limitations:\"))\n    \n    if (length(source_url_lines) &gt; 0) {\n      source_urls &lt;- source_url_lines\n    }\n  }\n  \n  # Extract data limitations - capture everything until next state or end\n  data_limitations_text &lt;- str_extract(section, \"Data Limitations:[\\\\s\\\\S]*?(?=\\\\b(A|Ala|Alas|Ari|Arka|Cali|Colo|Conn|Del|Flo|Geo|Haw|Ida|Ill|Ind|Iow|Kan|Ken|Lou|Mai|Mar|Mas|Mic|Min|Mis|Mon|Neb|Nev|New|Nor|Ohi|Okl|Ore|Pen|Rho|Sou|Ten|Tex|Uta|Ver|Vir|Was|Wis|Wyo)\\\\b|$)\")\n  data_limitations &lt;- NA_character_\n  \n  if (!is.na(data_limitations_text)) {\n    data_limitations_text &lt;- str_remove(data_limitations_text, \"Data Limitations:\") %&gt;% str_trim()\n    data_limitations_lines &lt;- str_split(data_limitations_text, \"\\\\n\")[[1]] %&gt;% \n      str_trim() %&gt;% \n      discard(~ .x == \"\" | str_detect(.x, \"^\\\\b(A|Ala|Alas|Ari|Arka|Cali|Colo|Conn|Del|Flo|Geo|Haw|Ida|Ill|Ind|Iow|Kan|Ken|Lou|Mai|Mar|Mas|Mic|Min|Mis|Mon|Neb|Nev|New|Nor|Ohi|Okl|Ore|Pen|Rho|Sou|Ten|Tex|Uta|Ver|Vir|Was|Wis|Wyo)\\\\b\"))\n    \n    if (length(data_limitations_lines) &gt; 0) {\n      data_limitations &lt;- paste(data_limitations_lines, collapse = \"; \")\n    }\n  }\n  \n  # If no data sources were found, create at least one row for the state\n  if (nrow(data_source_df) == 0) {\n    data_source_df &lt;- tibble(data_source_type = NA_character_, data_source_note = NA_character_)\n  }\n  \n  # Create result dataframe\n  result_df &lt;- data_source_df %&gt;%\n    mutate(\n      state = state_name,\n      legal_framework = legal_framework,\n      collection_triggers = collection_triggers,\n      source_url = ifelse(length(source_urls) &gt; 0, paste(source_urls, collapse = \"; \"), NA_character_),\n      data_limitations = data_limitations,\n      .before = everything()\n    )\n  \n  return(result_df)\n}\n\n# Parse all state sections\nstate_data &lt;- map2_df(state_sections, state_names, parse_state_section, .progress = TRUE)\n\n\n â– â– â– â– â– â– â– â– â– â– â– â– â– â–                     43% |  ETA:  2s\n\n\nShow paragraph extraction code\n# Clean up the data - remove rows where all data columns are NA\nfinal_df &lt;- state_data %&gt;%\n  mutate(across(where(is.character), ~ ifelse(.x == \"\" | is.na(.x), NA, .x))) %&gt;%\n  filter(!(is.na(data_source_type) & is.na(source_url) & is.na(data_limitations)))\n\n# Fill in the missing legal_framework and other metadata for each state\nfinal_df_clean &lt;- final_df %&gt;%\n  group_by(state) %&gt;%\n  fill(legal_framework, collection_triggers, .direction = \"downup\") %&gt;%\n  ungroup() %&gt;%\n  # Remove rows where legal_framework is NA (these seem to be incomplete entries)\n  filter(!is.na(legal_framework))\n\n# Now let's fill source_url and data_limitations across all rows for each state\nfinal_df_clean &lt;- final_df_clean %&gt;%\n  group_by(state) %&gt;%\n  mutate(\n    source_url = ifelse(all(is.na(source_url)), NA, \n                       paste(na.omit(unique(source_url)), collapse = \"; \")),\n    data_limitations = ifelse(all(is.na(data_limitations)), NA,\n                             paste(na.omit(unique(data_limitations)), collapse = \"; \"))\n  ) %&gt;%\n  ungroup()\n\n# Create categorization columns for easier analysis\nfinal_df_clean &lt;- final_df_clean %&gt;%\n  mutate(\n    # Categorize collection triggers\n    collection_trigger_category = case_when(\n      str_detect(collection_triggers, \"(?i)all felony.*convictions.*arrests.*all felonies\") ~ \"Comprehensive: All felonies + broad arrests\",\n      str_detect(collection_triggers, \"(?i)all felony.*convictions.*arrests.*certain|specific\") ~ \"Selective: All felonies + specific arrests\",\n      str_detect(collection_triggers, \"(?i)all felony.*convictions.*arrests\") ~ \"Broad: All felonies + various arrests\",\n      str_detect(collection_triggers, \"(?i)all felony.*convictions\") ~ \"Felony convictions only\",\n      str_detect(collection_triggers, \"(?i)felony.*misdemeanor.*convictions\") ~ \"Mixed: Felony + misdemeanor convictions\",\n      TRUE ~ \"Other/Unspecified\"\n    ),\n    \n    # Categorize data limitations\n    data_limitation_category = case_when(\n      is.na(data_limitations) ~ \"No limitations noted\",\n      str_detect(data_limitations, \"(?i)no direct.*conviction data\") ~ \"Missing conviction data\",\n      str_detect(data_limitations, \"(?i)prison admissions.*proxy\") ~ \"Prison data as proxy\",\n      str_detect(data_limitations, \"(?i)hispanic|ethnicity\") ~ \"Ethnicity categorization issues\",\n      str_detect(data_limitations, \"(?i)racial.*limited|black.*white.*only\") ~ \"Limited racial categories\",\n      str_detect(data_limitations, \"(?i)no.*data.*available|unavailable\") ~ \"Various data unavailable\",\n      TRUE ~ \"Other limitations\"\n    ),\n    \n    # Categorize data source types\n    data_source_category = case_when(\n      str_detect(data_source_type, \"(?i)conviction\") ~ \"Conviction Data\",\n      str_detect(data_source_type, \"(?i)arrest\") ~ \"Arrest Data\",\n      str_detect(data_source_type, \"(?i)sex|sexual\") ~ \"Sex Crime Data\",\n      str_detect(data_source_type, \"(?i)prison|admission|correction\") ~ \"Prison/Incarceration Data\",\n      TRUE ~ \"Other Data Source\"\n    )\n  )\n\n# Create a summary table for quick overview\nsummary_table &lt;- final_df_clean %&gt;%\n  distinct(state, legal_framework, collection_triggers, collection_trigger_category, \n           data_limitations, data_limitation_category, source_url) %&gt;%\n  arrange(state)\n\n# Create a categorized view of data sources\ndata_source_summary &lt;- final_df_clean %&gt;%\n  filter(!is.na(data_source_type)) %&gt;%\n  group_by(state, data_source_category) %&gt;%\n  summarize(\n    data_sources = paste(unique(data_source_type), collapse = \"; \"),\n    .groups = \"drop\"\n  ) %&gt;%\n  pivot_wider(\n    names_from = data_source_category,\n    values_from = data_sources,\n    values_fill = NA\n  )\n\n# Join the summary information\nfinal_summary &lt;- summary_table %&gt;%\n  left_join(data_source_summary, by = \"state\") %&gt;%\n  select(state, legal_framework, collection_trigger_category, data_limitation_category)\n\n# Create interactive tables for exploration\ndatatable_summary &lt;- datatable(\n  final_summary,\n  extensions = c('Buttons', 'ColReorder', 'Scroller'),\n  options = list(\n    dom = 'Bfrtip',\n    buttons = c('copy', 'csv', 'excel', 'colvis'),\n    scrollX = TRUE,\n    scrollY = \"600px\",\n    scroller = TRUE,\n    pageLength = 10,\n    columnDefs = list(\n      list(className = 'dt-left', targets = 0:(ncol(final_summary)-1)),\n      # Only apply width styling to columns that actually exist\n      list(width = '200px', targets = c(1, 2, 3)) # Adjust based on your actual column count\n    ),\n    autoWidth = TRUE\n  ),\n  rownames = FALSE,\n  filter = 'top',\n  class = 'cell-border stripe hover'\n) %&gt;%\n  formatStyle(\n    columns = names(final_summary),\n    fontSize = '12px',\n    lineHeight = '90%'\n  )\n\n# Show the tables\ndatatable_summary"
  },
  {
    "objectID": "analysis/foia_processing.html",
    "href": "analysis/foia_processing.html",
    "title": "FOIA Document OCR Processing",
    "section": "",
    "text": "This document details the processing of Freedom of Information Act (FOIA) responses from seven U.S. states regarding the demographic composition of their State DNA Index System (SDIS) databases. These responses were obtained by Professor Erin Murphy (NYU Law) in 2018 as part of research on racial disparities in DNA databases."
  },
  {
    "objectID": "analysis/foia_processing.html#data-sources",
    "href": "analysis/foia_processing.html#data-sources",
    "title": "FOIA Document OCR Processing",
    "section": "2.1 Data Sources",
    "text": "2.1 Data Sources\n\n2.1.1 Raw FOIA Responses\nThe original FOIA responses are stored in two formats:\n\nPDFs: raw/foia_pdfs/ - Original scanned documents\nHTML: raw/foia_html/ - OCRâ€™d versions for easier extraction\n\n\n\nShow setup code\n# List of required packages\nrequired_packages &lt;- c(\n  \"tidyverse\",    # Data manipulation and visualization\n  \"here\",         # File path management\n  \"knitr\",        # Dynamic report generation\n  \"kableExtra\",   # Enhanced table formatting\n  \"ggplot2\",      # Data visualization\n  \"patchwork\",    # Plot composition and layout\n  \"scales\",       # Axis scaling and formatting\n  \"tidyr\",        # Data tidying and reshaping\n  \"tibble\",       # Modern data frames\n  \"flextable\",    # Advanced table formatting\n  \"DT\",           # Interactive tables\n  \"cowplot\",      # Plotting composition\n  \"sf\",           # Simple Features for spatial data\n  \"usmap\"        # Mapping US states\n)\n  \n\n# Function to install missing packages\ninstall_missing &lt;- function(packages) {\n  for (pkg in packages) {\n    if (!requireNamespace(pkg, quietly = TRUE)) {\n      message(paste(\"Installing missing package:\", pkg))\n      install.packages(pkg, dependencies = TRUE)\n    }\n  }\n}\n\n# Install any missing packages\ninstall_missing(required_packages)\n\n# Load all packages\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(here)\n  library(knitr)\n  library(kableExtra)\n  library(ggplot2)\n  library(patchwork)\n  library(scales)\n  library(tidyr)\n  library(tibble)\n  library(flextable)\n  library(cowplot)\n  library(sf)\n  library(usmap)\n})\n\n# Verify all packages loaded successfully\nloaded_packages &lt;- sapply(required_packages, require, character.only = TRUE)\nif (all(loaded_packages)) {\n  message(\"All packages loaded successfully!\")\n} else {\n  warning(\"The following packages failed to load: \", \n          paste(names(loaded_packages)[!loaded_packages], collapse = \", \"))\n}\n\n# Display options\noptions(tibble.width = Inf)\noptions(dplyr.summarise.inform = FALSE)\n\n# Path to per-state files (run notebook from analysis/)\nbase_dir &lt;- here(\"..\")\nper_state &lt;- here(\"raw\", \"foia_csvs\")\n\n# ------------------------------------------------------------------\n# 1. Discover available per-state CSV files\n# ------------------------------------------------------------------\nstate_files &lt;- list.files(per_state, pattern = \"*_foia_data\\\\.csv$\", full.names = TRUE)\n\nif (length(state_files) == 0) {\n  stop(paste(\"No per-state FOIA files found in\", per_state, \". Check the folder path.\"))\n}\n\nstem_to_state &lt;- function(stem) {\n  toks &lt;- str_split(stem, \"_\")[[1]]\n  if (\"foia\" %in% toks) {\n    toks &lt;- toks[1:(which(toks == \"foia\") - 1)]\n  }\n  paste(tools::toTitleCase(toks), collapse = \" \")\n}\n\nstates_available &lt;- map_chr(basename(state_files), ~ stem_to_state(str_remove(.x, \"_foia_data\\\\.csv\")))\n\ncat(paste(\"âœ“ Found\", length(state_files), \"per-state files:\\n\"))\nfor (s in states_available) {\n  cat(paste(\"  â€¢\", s, \"\\n\"))\n}\n\n# ------------------------------------------------------------------\n# 2. Initialize empty containers for the loop that follows\n# ------------------------------------------------------------------\nfoia_combined &lt;- tibble()\nfoia_state_metadata &lt;- list()\n\n\nâœ“ Found 7 per-state files:\n  â€¢ California \n  â€¢ Florida \n  â€¢ Indiana \n  â€¢ Maine \n  â€¢ Nevada \n  â€¢ South Dakota \n  â€¢ Texas"
  },
  {
    "objectID": "analysis/foia_processing.html#processing-workflow",
    "href": "analysis/foia_processing.html#processing-workflow",
    "title": "FOIA Document OCR Processing",
    "section": "2.2 Processing workflow",
    "text": "2.2 Processing workflow\nFor transparency, each state file is processed independently then merged into a single combined longâ€‘format table (foia_combined):\n\nLoad one file per state from output/foia/per_state/.\nAppend its rows to foia_combined. A parallel dataframe, foia_state_metadata, records what each state reported (counts, percentages, which categories) and any state-specific characteristics (e.g.Â Nevadaâ€™s â€œflagsâ€ terminology).\nQualityâ€‘check each state:\n\nverify that race and gender percentages sum to â‰ˆ 100 % when provided,\nconfirm that demographic counts sum to the stateâ€™s reported total profiles,\ncalculate any missing counts or percentages and tag those rows value_source = \"calculated\".\n\nSave outputs\n\noutput/foia/foia_data_clean.csv â€” the fully combined tidy table with both reported and calculated values,\noutput/foia/foia_state_metadata.csv â€” one row per state summarising coverage and caveats. After QC passes, freeze foia_data_clean.csv to data/v1.0/foia_state_race_v1.0.csv."
  },
  {
    "objectID": "analysis/foia_processing.html#helper-functions",
    "href": "analysis/foia_processing.html#helper-functions",
    "title": "FOIA Document OCR Processing",
    "section": "2.3 Helper Functions",
    "text": "2.3 Helper Functions\nThe functions below perform each transformation required for harmonizing the stateâ€‘level FOIA tables.\n\n2.3.1 Data Processing Helper Functions Reference\n\n\n\n\n\n\n\n\nFunction\nDefinition\nParameters\n\n\n\n\nload_state()\nLoads and preprocesses state FOIA data files, handling numeric conversion and validation\npath: File path to state CSV\n\n\nenhanced_glimpse()\nProvides an enhanced data overview with column types, missing values, unique counts, and unique values\ndf: Input dataframe\n\n\nfill_demographic_gaps()\nFills missing gender counts and adds Unknown race category when totals permit calculation\ndf: Input dataframe\n\n\nadd_combined()\nCreates Combined offender type by summing Convicted Offender and Arrestee counts when missing\ndf: Input dataframe\n\n\nadd_percentages()\nDerives percentage values from counts for all demographic categories\ndf: Input dataframe\n\n\ncounts_consistent()\nVerifies that demographic counts sum to total_profiles for each offender type\ndf: Input dataframe\n\n\npercentages_consistent()\nVerifies that percentages sum to 100 Â± 0.5% for each category\ndf: Input dataframe\n\n\nreport_status()\nReports what data types (counts/percentages/both) are available for a category\ndf: Input dataframe, category: race or gender\n\n\nverify_category_totals()\nCompares demographic sums against reported totals and shows differences\ndf: Input dataframe\n\n\nverify_percentage_consistency()\nCompares reported vs calculated percentages for consistency\ndf_combined: Combined dataframe, state_name: State name\n\n\ncalculate_combined_totals()\nCalculates Combined totals by summing across offender types\ndf: Input dataframe, state_name: State name\n\n\ncalculate_percentages()\nCalculates percentages from counts for demographic categories\ndf_combined: Combined dataframe, state_name: State name\n\n\ncalculate_counts_from_percentages()\nCalculates counts from percentages for demographic categories\ndf_combined: Combined dataframe, state_name: State name\n\n\nstandardize_offender_types()\nStandardizes offender type names to consistent terminology\ndf: Input dataframe\n\n\nprepare_state_for_combined()\nPrepares state data for inclusion in combined dataset with proper columns\ndf: Input dataframe, state_name: State name\n\n\nformat_compact()\nFormats large numbers with K/M suffixes for readability\nx: Numeric value\n\n\ncreate_pie_chart()\nCreates pie charts for specific demographic categories\ndata: Input data, offender_type, category, value_type, title, show_values\n\n\ncreate_state_visualizations()\nCreates comprehensive pie chart visualizations for all metrics\ndf_combined: Combined dataframe, state_name: State name\n\n\ncreate_demographic_bar_charts()\nCreates side-by-side bar charts for gender and race distributions\ndf_combined: Combined dataframe, state_name: State name\n\n\nadd_state_metadata()\nCreates and appends a metadata record capturing state data characteristics including available offender types, demographic categories, data formats, and special features\ndf: Input dataframe, state_name: State name\n\n\nupdate_state_metadata()\nModifies existing state metadata to update QC results (count/percentage consistency) and append validation notes\nstate_name: State name, counts_ok: Count consistency flag, percentages_ok: Percentage consistency flag, notes_text: Additional notes\n\n\n\n\n\nShow helper functions setup\n# Columns retained from every raw table\nCOLS_NEEDED &lt;- c(\"state\", \"offender_type\", \"variable_category\",\n                 \"variable_detailed\", \"value\", \"value_type\")\n\n# ------------------------------------------------------------------\n# 1. Load and preprocess state files\n# ------------------------------------------------------------------\nload_state &lt;- function(path) {\n  \"\n  Read a *_foia_data.csv* file, enforce column order,\n  and convert &lt;1 to 0.5 so that trace counts are retained.\n  Execution halts if non-numeric values remain.\n  \"\n  df &lt;- read_csv(path, show_col_types = FALSE)\n  if (!\"state\" %in% colnames(df)) {\n    df &lt;- df %&gt;%\n      mutate(state = str_remove(basename(path), \"_foia_data\\\\.csv\") %&gt;%\n        str_replace_all(\"_\", \" \") %&gt;%\n        tools::toTitleCase())\n  }\n  df &lt;- df %&gt;% select(all_of(COLS_NEEDED))\n  df$value_source &lt;- \"reported\"\n\n  df &lt;- df %&gt;%\n    mutate(value = ifelse(value == \"&lt;1\", 0.5, value),\n           value = as.numeric(value))\n  \n  nonnumeric &lt;- df %&gt;% filter(is.na(value))\n  if (nrow(nonnumeric) &gt; 0) {\n    cat(paste(\"**Non-numeric rows in\", basename(path), \"; please amend**\\n\"))\n    print(nonnumeric)\n    stop(\"Numeric coercion failure\")\n  }\n  return(df)\n}\n\n\n# ------------------------------------------------------------------\n# 2. Enhanced glimpse\n# ------------------------------------------------------------------\n# Display data types for each column with unique values\nenhanced_glimpse &lt;- function(df) {\n  glimpse_data &lt;- data.frame(\n    Column = names(df),\n    Type = sapply(df, function(x) paste(class(x), collapse = \", \")),\n    Rows = nrow(df),\n    Missing = sapply(df, function(x) sum(is.na(x))),\n    Unique = sapply(df, function(x) length(unique(x))),\n    Unique_Values = sapply(df, function(x) {\n      unique_vals &lt;- unique(x)\n      if (length(unique_vals) &gt; 10) {\n        paste(encodeString(as.character(unique_vals[1:10])), collapse = \", \", \"...\")\n      } else {\n        paste(encodeString(as.character(unique_vals)), collapse = \", \")\n      }\n    })\n  )\n  \n  ft &lt;- flextable(glimpse_data) %&gt;%\n    theme_zebra() %&gt;%\n    set_caption(paste(\"Enhanced Data Glimpse:\", deparse(substitute(df)))) %&gt;%\n    autofit() %&gt;%\n    align(align = \"left\", part = \"all\") %&gt;%\n    colformat_num(j = c(\"Rows\", \"Missing\", \"Unique\"), big.mark = \"\") %&gt;%\n    bg(j = \"Missing\", bg = function(x) ifelse(x &gt; 0, \"#FFF3CD\", \"transparent\")) %&gt;%\n    bg(j = \"Unique\", bg = function(x) ifelse(x == 1, \"#FFF3CD\", \"transparent\")) %&gt;%\n    add_footer_lines(paste(\"Data frame dimensions:\", nrow(df), \"rows Ã—\", ncol(df), \"columns\")) %&gt;%\n    fontsize(size = 10, part = \"all\") %&gt;%\n    set_table_properties(layout = \"autofit\", width = 1)\n  \n  return(ft)\n}\n\n# ------------------------------------------------------------------\n# 3. Fill missing Male counts and Unknown race counts\n# ------------------------------------------------------------------\nfill_demographic_gaps &lt;- function(df) {\n  \"If exactly one gender or the Unknown race category is absent and\n  totals permit a residual, calculate and insert the missing count.\n  \"\n  inserts &lt;- list()\n  \n  for (ot in unique(df$offender_type)) {\n    tot &lt;- df %&gt;%\n      filter(offender_type == ot,\n             variable_category == \"total\",\n             variable_detailed == \"total_profiles\",\n             value_type == \"count\")\n    \n    if (nrow(tot) == 0) next\n    \n    total &lt;- tot$value[1]\n    \n    # gender residual ----------------------------------------------\n    g &lt;- df %&gt;%\n      filter(offender_type == ot,\n             variable_category == \"gender\",\n             value_type == \"count\")\n    \n    missing_gender &lt;- setdiff(c(\"Male\", \"Female\"), unique(g$variable_detailed))\n    if (nrow(g) == 1 && length(missing_gender) == 1) {\n      inserts[[length(inserts) + 1]] &lt;- tibble(\n        state = df$state[1],\n        offender_type = ot,\n        variable_category = \"gender\",\n        variable_detailed = missing_gender,\n        value = total - sum(g$value),\n        value_type = \"count\",\n        value_source = \"calculated\"\n      )\n    }\n    \n    # race residual -----------------------------------------------\n    r &lt;- df %&gt;%\n      filter(offender_type == ot,\n             variable_category == \"race\",\n             value_type == \"count\")\n    \n    if (nrow(r) &gt; 0 && !\"Unknown\" %in% r$variable_detailed) {\n      gap &lt;- total - sum(r$value)\n      if (gap &gt; 0) {\n        inserts[[length(inserts) + 1]] &lt;- tibble(\n          state = df$state[1],\n          offender_type = ot,\n          variable_category = \"race\",\n          variable_detailed = \"Unknown\",\n          value = gap,\n          value_type = \"count\",\n          value_source = \"calculated\"\n        )\n      }\n    }\n  }\n  \n  if (length(inserts) &gt; 0) {\n    df &lt;- bind_rows(df, bind_rows(inserts))\n  }\n  return(df)\n}\n\n# ------------------------------------------------------------------\n# 4. Construct Combined offender type if absent (add_combined)\n# ------------------------------------------------------------------\nadd_combined &lt;- function(df) {\n  \"\n  When a state reports Convicted Offender and Arrestee counts but\n  omits Combined, create a Combined block by summing the two.\n  \"\n  if (\"Combined\" %in% df$offender_type) return(df)\n  \n  required &lt;- c(\"Convicted Offender\", \"Arrestee\")\n  if (!all(required %in% df$offender_type)) return(df)  # cannot construct\n  \n  summed &lt;- df %&gt;%\n    filter(value_type == \"count\") %&gt;%\n    group_by(variable_category, variable_detailed, value_type) %&gt;%\n    summarise(value = sum(value), .groups = \"drop\") %&gt;%\n    mutate(state = df$state[1],\n           offender_type = \"Combined\",\n           value_source = \"calculated\")\n  \n  return(bind_rows(df, summed))\n}\n\n# ------------------------------------------------------------------\n# 5. Derive percentages wherever only counts exist (add_percentages)\n# ------------------------------------------------------------------\nadd_percentages &lt;- function(df) {\n  \"\n  Ensure that every gender and race row has both count and percentage\n  values, derived from the offender-type total if necessary.\n  \"\n  totals &lt;- df %&gt;%\n    filter(variable_category == \"total\",\n           variable_detailed == \"total_profiles\",\n           value_type == \"count\") %&gt;%\n    select(offender_type, value) %&gt;%\n    deframe()\n  \n  need_pct &lt;- df %&gt;%\n    filter(value_type == \"count\",\n           variable_category != \"total\")\n  \n  new_pct_rows &lt;- need_pct %&gt;%\n    rowwise() %&gt;%\n    mutate(has_percentage = nrow(df %&gt;%\n           filter(state == state,\n                  offender_type == offender_type,\n                  variable_category == variable_category,\n                  variable_detailed == variable_detailed,\n                  value_type == \"percentage\"))) %&gt;%\n    filter(has_percentage == 0) %&gt;%\n    mutate(value = round(value / totals[offender_type] * 100, 2),\n           value_type = \"percentage\",\n           value_source = \"calculated\") %&gt;%\n    select(-has_percentage)\n  \n  if (nrow(new_pct_rows) &gt; 0) {\n    df &lt;- bind_rows(df, new_pct_rows)\n  }\n  return(df)\n}\n\n# ------------------------------------------------------------------\n# 6. Counts consistency checks\n# ------------------------------------------------------------------\ncounts_consistent &lt;- function(df) {\n  \"\n  Verifies that demographic counts sum to total_profiles for each\n  offender type and category.\n  \"\n  demo_sum &lt;- df %&gt;%\n    filter(value_type == \"count\",\n           variable_category != \"total\") %&gt;%\n    group_by(offender_type, variable_category) %&gt;%\n    summarise(sum_value = sum(value), .groups = \"drop\")\n  \n  totals &lt;- df %&gt;%\n    filter(variable_category == \"total\",\n           variable_detailed == \"total_profiles\",\n           value_type == \"count\") %&gt;%\n    select(offender_type, value)\n  \n  merged &lt;- demo_sum %&gt;%\n    left_join(totals, by = \"offender_type\") %&gt;%\n    mutate(diff = abs(sum_value - value))\n  \n  all(merged$diff &lt; 1e-6)\n}\n\n# ------------------------------------------------------------------\n# 7. Percentage consistency checks\n# ------------------------------------------------------------------\n\npercentages_consistent &lt;- function(df) {\n  \"\n  Verifies that derived or reported percentages sum to 100 Â± 0.5 %.\n  \"\n  result &lt;- df %&gt;%\n    filter(value_type == \"percentage\") %&gt;%\n    group_by(offender_type, variable_category) %&gt;%\n    summarise(sum_value = sum(value), .groups = \"drop\") %&gt;%\n    mutate(consistent = abs(sum_value - 100) &lt;= 0.5)\n  \n  all(result$consistent)\n}\n\n\n# ------------------------------------------------------------------\n# 8. Report status for each category\n# ------------------------------------------------------------------\n\n# Define columns needed for foia_combined\nreport_status &lt;- function(df, category) {\n  values &lt;- unique(df$value_type[df$variable_category == category])\n  \n  if (all(c(\"count\", \"percentage\") %in% values)) {\n    return(\"both\")\n  } else if (\"count\" %in% values) {\n    return(\"counts\")\n  } else if (\"percentage\" %in% values) {\n    return(\"percentages\")\n  } else {\n    return(\"neither\")\n  }\n}\n\n# ------------------------------------------------------------------\n# 9. Verify category totals\n# ------------------------------------------------------------------\n\nverify_category_totals &lt;- function(df) {\n  # 1 pull total_profiles per offender_type\n  total_map &lt;- df %&gt;%\n    filter(variable_category == \"total\", \n           variable_detailed == \"total_profiles\") %&gt;%\n    select(offender_type, value) %&gt;%\n    deframe() %&gt;%\n    as.list()\n  \n  # 2 sum counts by offender_type and variable_category\n  demo_sum &lt;- df %&gt;%\n    filter(value_type == \"count\",\n           variable_category != \"total\") %&gt;%\n    group_by(offender_type, variable_category) %&gt;%\n    summarise(sum_counts = sum(value, na.rm = TRUE), .groups = \"drop\")\n  \n  # 3 attach total_profiles and compute difference\n  demo_sum &lt;- demo_sum %&gt;%\n    mutate(total_profiles = map_dbl(offender_type, ~total_map[[.x]]),\n           difference = total_profiles - sum_counts)\n  \n  # tidy columns order\n  demo_sum %&gt;%\n    select(offender_type, variable_category, total_profiles, \n           sum_counts, difference)\n}\n\n# ------------------------------------------------------------------\n# 10. Calculate Combined totals\n# ------------------------------------------------------------------\n\ncalculate_combined_totals &lt;- function(df, state_name) {\n  # Get all counts\n  counts_df &lt;- df %&gt;%\n    filter(value_type == 'count') %&gt;%\n    mutate(value_source = 'calculated')\n  \n  # Group by variable_category and variable_detailed, sum values\n  combined_sums &lt;- counts_df %&gt;%\n    group_by(variable_category, variable_detailed) %&gt;%\n    summarise(value = sum(value, na.rm = TRUE), .groups = \"drop\")\n  \n  # Create Combined rows\n  combined_rows &lt;- combined_sums %&gt;%\n    mutate(state = state_name,\n           offender_type = 'Combined',\n           value_type = 'count',\n           value_source = 'calculated') %&gt;%\n    select(all_of(COLS_NEEDED), value_source)\n  \n  return(combined_rows)\n}\n\n# ------------------------------------------------------------------\n# 11. Calculate percentages from counts\n# ------------------------------------------------------------------\n\ncalculate_percentages &lt;- function(df_combined, state_name) {\n  # Get total profiles for each offender type\n  totals_map &lt;- df_combined %&gt;%\n    filter(state == state_name,\n           variable_category == 'total',\n           variable_detailed == 'total_profiles') %&gt;%\n    select(offender_type, value) %&gt;%\n    deframe() %&gt;%\n    as.list()\n  \n  percentage_rows &lt;- list()\n  \n  for (offender_type in names(totals_map)) {\n    total &lt;- totals_map[[offender_type]]\n    \n    # Get all demographic counts\n    demo_data &lt;- df_combined %&gt;%\n      filter(state == state_name,\n             offender_type == !!offender_type,\n             variable_category %in% c('gender', 'race'),\n             value_type == 'count')\n    \n    if (nrow(demo_data) &gt; 0) {\n      # Calculate percentage for each\n      demo_percentages &lt;- demo_data %&gt;%\n        mutate(value = round((value / total) * 100, 2),\n               value_type = 'percentage',\n               value_source = 'calculated') %&gt;%\n        select(all_of(COLS_NEEDED), value_source)\n      \n      percentage_rows &lt;- c(percentage_rows, list(demo_percentages))\n    }\n  }\n  \n  bind_rows(percentage_rows)\n}\n\n# ------------------------------------------------------------------\n# 12. Calculate counts from percentages\n# ------------------------------------------------------------------\n\ncalculate_counts_from_percentages &lt;- function(df_combined, state_name) {\n  # Get total profiles for each offender type\n  totals_map &lt;- df_combined %&gt;%\n    filter(state == state_name,\n           variable_category == 'total',\n           variable_detailed == 'total_profiles') %&gt;%\n    select(offender_type, value) %&gt;%\n    deframe() %&gt;%\n    as.list()\n  \n  count_rows &lt;- list()\n  \n  for (offender_type in names(totals_map)) {\n    total &lt;- totals_map[[offender_type]]\n    \n    # Get all demographic percentages\n    demo_data &lt;- df_combined %&gt;%\n      filter(state == state_name,\n             offender_type == !!offender_type,\n             variable_category %in% c('gender', 'race'),\n             value_type == 'percentage')\n    \n    if (nrow(demo_data) &gt; 0) {\n      # Calculate count for each\n      demo_counts &lt;- demo_data %&gt;%\n        mutate(value = as.integer(round(total * (value / 100))),\n               value_type = 'count',\n               value_source = 'calculated') %&gt;%\n        select(all_of(COLS_NEEDED), value_source)\n      \n      count_rows &lt;- c(count_rows, list(demo_counts))\n    }\n  }\n  \n  bind_rows(count_rows)\n}\n\n# ------------------------------------------------------------------\n# 13. Standardize offender types\n# ------------------------------------------------------------------\n\nstandardize_offender_types &lt;- function(df) {\n  replacements &lt;- c(\n    'Offenders' = 'Convicted Offender',\n    'Convicted offenders' = 'Convicted Offender',\n    'Arrested offender' = 'Arrestee',\n    'All' = 'Combined'\n  )\n  \n  df %&gt;%\n    mutate(offender_type = recode(offender_type, !!!replacements))\n}\n\n# ------------------------------------------------------------------\n# 14. Prepare state data for combined dataset\n# ------------------------------------------------------------------\n\nprepare_state_for_combined &lt;- function(df, state_name) {\n  \n  df_prepared &lt;- df %&gt;%\n    select(any_of(COLS_NEEDED), value_source)\n  \n  df_prepared &lt;- df_prepared %&gt;%\n      mutate(value_source = case_when(\n        is.na(value_source) ~ \"calculated\",\n        value_source == \"\" ~ \"calculated\",\n        TRUE ~ value_source\n      ))\n\n  \n  df_prepared\n}\n\n# ------------------------------------------------------------------\n# 15. Compare reported vs calculated percentages\n# ------------------------------------------------------------------\n\nverify_percentage_consistency &lt;- function(df_combined, state_name) {\n  state_data &lt;- df_combined %&gt;%\n    filter(state == state_name)\n  \n  # Get all offender types that have both counts and percentages\n  offender_types &lt;- unique(state_data$offender_type)\n  \n  consistency_results &lt;- list()\n  \n  for (offender_type in offender_types) {\n    offender_data &lt;- state_data %&gt;%\n      filter(offender_type == !!offender_type)\n    \n    # Check if we have both reported and calculated percentages\n    for (category in c('gender', 'race')) {\n      reported_pcts &lt;- offender_data %&gt;%\n        filter(variable_category == !!category,\n               value_type == 'percentage',\n               value_source == 'reported')\n      \n      calculated_pcts &lt;- offender_data %&gt;%\n        filter(variable_category == !!category,\n               value_type == 'percentage',\n               value_source == 'calculated')\n      \n      if (nrow(reported_pcts) &gt; 0 && nrow(calculated_pcts) &gt; 0) {\n        # Compare each demographic value\n        for (i in 1:nrow(reported_pcts)) {\n          rep_row &lt;- reported_pcts[i, ]\n          calc_match &lt;- calculated_pcts %&gt;%\n            filter(variable_detailed == rep_row$variable_detailed)\n          \n          if (nrow(calc_match) &gt; 0) {\n            diff &lt;- abs(rep_row$value - calc_match$value[1])\n            consistency_results &lt;- c(consistency_results, list(data.frame(\n              offender_type = offender_type,\n              category = category,\n              variable = rep_row$variable_detailed,\n              reported = rep_row$value,\n              calculated = calc_match$value[1],\n              difference = diff,\n              consistent = diff &lt; 0.5\n            )))\n          }\n        }\n      }\n    }\n  }\n  \n  if (length(consistency_results) &gt; 0) {\n    consistency_df &lt;- bind_rows(consistency_results)\n    cat(paste0(\"\\nPercentage consistency check for \", state_name, \":\\n\"))\n    cat(paste0(\"All values consistent: \", all(consistency_df$consistent), \"\\n\"))\n    \n    if (!all(consistency_df$consistent)) {\n      cat(\"\\nInconsistent values:\\n\")\n      print(consistency_df %&gt;% filter(!consistent))\n    }\n    \n    return(all(consistency_df$consistent))\n  } else {\n    # No comparison possible - state only has one type of data\n    return(TRUE)\n  }\n}\n# ------------------------------------------------------------------\n# 16. Add compact formatting for large numbers\n# ------------------------------------------------------------------\n\nformat_compact &lt;- function(x) {\n  sapply(x, function(single_x) {\n    if (single_x &gt;= 1000000) {\n      if (single_x/1000000 == as.integer(single_x/1000000)) {\n        return(paste0(as.integer(single_x/1000000), \"M\"))\n      } else {\n        return(paste0(round(single_x/1000000, 1), \"M\"))\n      }\n    } else if (single_x &gt;= 1000) {\n      return(paste0(as.integer(single_x/1000), \"k\"))\n    } else {\n      return(paste0(as.integer(single_x)))\n    }\n  })\n}\n\n# ------------------------------------------------------------------\n# 17. Pie chart creation function\n# ------------------------------------------------------------------\n\ncreate_pie_chart &lt;- function(data, offender_type, category, value_type, title, show_values = FALSE) {\n  chart_data &lt;- data %&gt;%\n    filter(offender_type == !!offender_type,\n           variable_category == !!category,\n           value_type == !!value_type)\n  \n  # Ensure consistent categories\n  if (category == 'gender') {\n    # Define all possible gender categories\n    all_genders &lt;- data.frame(variable_detailed = c('Male', 'Female', 'Unknown'))\n    chart_data &lt;- chart_data %&gt;%\n      right_join(all_genders, by = \"variable_detailed\") %&gt;%\n      mutate(value = ifelse(is.na(value), 0, value)) %&gt;%\n      arrange(factor(variable_detailed, levels = c('Male', 'Female', 'Unknown')))\n  } else if (category == 'race') {\n    # Define all possible race categories in desired order\n    all_races &lt;- data.frame(variable_detailed = c('White', 'Black', 'Hispanic', \n                                                 'Asian', 'Native American', 'Other', 'Unknown'))\n    chart_data &lt;- chart_data %&gt;%\n      right_join(all_races, by = \"variable_detailed\") %&gt;%\n      mutate(value = ifelse(is.na(value), 0, value)) %&gt;%\n      arrange(factor(variable_detailed, levels = c('White', 'Black', 'Hispanic', \n                                                  'Asian', 'Native American', 'Other', 'Unknown')))\n  }\n  \n  # Remove zero values for cleaner display (optional)\n  chart_data &lt;- chart_data %&gt;% filter(value &gt; 0)\n  \n  if (nrow(chart_data) &gt; 0) {\n    # Define colors based on category\n    if (category == 'gender') {\n      colors &lt;- c('Male' = '#4E79A7', 'Female' = '#E15759', 'Unknown' = '#BAB0AC')\n    } else {\n      colors &lt;- c('White' = '#4E79A7', \n                 'Black' = '#F25E2B', \n                 'Hispanic' = '#E14759',\n                 'Asian' = '#76B7B2',\n                 'Native American' = '#59A14F',\n                 'Other' = '#9C755F',\n                 'Unknown' = '#BAB0AC')\n    }\n    \n    # Create labels\n    if (show_values && value_type == 'count') {\n      labels &lt;- paste0(chart_data$variable_detailed, \"\\n(\", \n                      format(chart_data$value, big.mark = \",\"), \")\")\n    } else if (value_type == 'percentage') {\n      labels &lt;- paste0(chart_data$variable_detailed, \"\\n(\", \n                      round(chart_data$value, 1), \"%)\")\n    } else {\n      labels &lt;- chart_data$variable_detailed\n    }\n    \n    # Use consistent colors based on category\n    pie_colors &lt;- colors[chart_data$variable_detailed]\n    \n    pie(chart_data$value, \n        labels = labels,\n        main = title,\n        col = pie_colors,\n        cex.main = 0.9)\n  } else {\n    plot.new()\n    title(main = title, cex.main = 0.9)\n    text(0.5, 0.5, \"No data\", cex = 0.8)\n  }\n}\n\n# ------------------------------------------------------------------\n# 18. State visualizations with 2 pies per row\n# ------------------------------------------------------------------\n\ncreate_state_visualizations &lt;- function(df_combined, state_name) {\n  state_data &lt;- df_combined %&gt;% filter(state == state_name)\n  \n  offender_types &lt;- sort(unique(state_data$offender_type))\n  plots &lt;- list()\n  \n  for (offender_type in offender_types) {\n    plots &lt;- c(plots, list(\n      create_pie_chart(state_data, offender_type, 'gender', 'count',\n                       paste(offender_type, \"Gender Counts\"), TRUE),\n      create_pie_chart(state_data, offender_type, 'gender', 'percentage',\n                       paste(offender_type, \"Gender Percentages\")),\n      create_pie_chart(state_data, offender_type, 'race', 'count',\n                       paste(offender_type, \"Race Counts\"), TRUE),\n      create_pie_chart(state_data, offender_type, 'race', 'percentage',\n                       paste(offender_type, \"Race Percentages\"))\n    ))\n  }\n}\n\n# ------------------------------------------------------------------\n# 19. Demographic bar chart function\n# ------------------------------------------------------------------\n\ncreate_demographic_bar_charts &lt;- function(df_combined, state_name) {\n  state_data &lt;- df_combined %&gt;%\n    filter(state == state_name)\n  \n  # Get offender types and ensure Combined is last\n  offender_types &lt;- state_data %&gt;%\n    filter(value_type == 'count') %&gt;%\n    pull(offender_type) %&gt;%\n    unique() %&gt;%\n    sort()\n  \n  if ('Combined' %in% offender_types) {\n    offender_types &lt;- c(setdiff(offender_types, 'Combined'), 'Combined')\n  }\n  \n  # Color palettes\n  gender_colors &lt;- c('Male' = '#4E79A7', 'Female' = '#E15759', 'Unknown' = '#BAB0AC')\n  race_colors &lt;- c(\n    'White' = '#4E79A7', \n    'Black' = '#F25E2B', \n    'Hispanic' = '#E14759',\n    'Asian' = '#76B7B2',\n    'Native American' = '#59A14F',\n    'Other' = '#9C755F',\n    'Unknown' = '#BAB0AC'\n  )\n  \n  # Gender data - ensure no duplicates by summing values\n  gender_data &lt;- state_data %&gt;%\n    filter(variable_category == 'gender',\n           value_type == 'count') %&gt;%\n    group_by(offender_type, variable_detailed) %&gt;%\n    summarize(value = sum(value, na.rm = TRUE), .groups = 'drop') %&gt;%\n    complete(offender_type, variable_detailed = c('Male', 'Female', 'Unknown'), \n             fill = list(value = 0))\n  \n  # Race data - ensure no duplicates by summing values\n  race_data &lt;- state_data %&gt;%\n    filter(variable_category == 'race',\n           value_type == 'count') %&gt;%\n    group_by(offender_type, variable_detailed) %&gt;%\n    summarize(value = sum(value, na.rm = TRUE), .groups = 'drop') %&gt;%\n    complete(offender_type, \n             variable_detailed = c('White', 'Black', 'Hispanic', \n                                  'Asian', 'Native American', 'Other', 'Unknown'), \n             fill = list(value = 0))\n  \n  # Create separate plots - one per row\n  par(mfrow = c(2, 1), mar = c(5, 9, 4, 9), oma = c(0, 0, 2, 0)) # Increased right margin for legend\n  \n  # Gender plot - ordered by total volume\n  gender_plot_data &lt;- gender_data %&gt;%\n    filter(variable_detailed %in% c('Male', 'Female', 'Unknown')) %&gt;%\n    mutate(offender_type = factor(offender_type, levels = rev(offender_types)))\n  \n  # Order gender categories by total volume (largest at bottom)\n  gender_order &lt;- gender_plot_data %&gt;%\n    group_by(variable_detailed) %&gt;%\n    summarize(total = sum(value)) %&gt;%\n    arrange(total) %&gt;%\n    pull(variable_detailed)\n  \n  gender_plot_data &lt;- gender_plot_data %&gt;%\n    mutate(variable_detailed = factor(variable_detailed, levels = gender_order))\n  \n  # Reshape for barplot\n  gender_matrix &lt;- gender_plot_data %&gt;%\n    pivot_wider(names_from = variable_detailed, values_from = value) %&gt;%\n    as.data.frame() %&gt;%\n    column_to_rownames(\"offender_type\") %&gt;%\n    as.matrix()\n  \n  # Ensure all columns exist\n  for (gender in gender_order) {\n    if (!gender %in% colnames(gender_matrix)) {\n      gender_matrix &lt;- cbind(gender_matrix, temp = 0)\n      colnames(gender_matrix)[ncol(gender_matrix)] &lt;- gender\n    }\n  }\n  \n  # Reorder columns by volume\n  gender_matrix &lt;- gender_matrix[, as.character(gender_order), drop = FALSE]\n  \n  # Format x-axis labels with \"k\" for thousands\n  max_x &lt;- max(rowSums(gender_matrix))\n  x_breaks &lt;- pretty(c(0, max_x))\n  x_labels &lt;- ifelse(x_breaks &gt;= 1000, \n                    paste0(x_breaks/1000, \"k\"), \n                    as.character(x_breaks))\n  \n  barplot(t(gender_matrix), \n          horiz = TRUE,\n          las = 1,\n          col = gender_colors[colnames(gender_matrix)],\n          main = 'Gender Distribution',\n          xlab = 'Number of Profiles',\n          xaxt = 'n',  # Remove default x-axis\n          legend.text = FALSE,  # Don't show legend in plot area\n          args.legend = list(x = \"right\", bty = \"n\", inset = c(-0.2, 0)))\n  \n  # Add custom x-axis with formatted labels\n  axis(1, at = x_breaks, labels = x_labels)\n  \n  # Add legend outside the plot area\n  legend(\"topright\", \n         legend = colnames(gender_matrix), \n         fill = gender_colors[colnames(gender_matrix)],\n         bty = \"n\", \n         xpd = TRUE,  # Allow plotting outside main area\n         inset = c(-0.25, 0),  # Move legend to the right\n         cex = 0.8)\n  \n  # Race plot - ordered by total volume\n  race_plot_data &lt;- race_data %&gt;%\n    mutate(offender_type = factor(offender_type, levels = rev(offender_types)))\n  \n  # Order race categories by total volume (largest at bottom)\n  race_order &lt;- race_plot_data %&gt;%\n    group_by(variable_detailed) %&gt;%\n    summarize(total = sum(value)) %&gt;%\n    arrange(total) %&gt;%\n    pull(variable_detailed)\n  \n  race_plot_data &lt;- race_plot_data %&gt;%\n    mutate(variable_detailed = factor(variable_detailed, levels = race_order))\n  \n  # Reshape for barplot\n  race_matrix &lt;- race_plot_data %&gt;%\n    pivot_wider(names_from = variable_detailed, values_from = value) %&gt;%\n    as.data.frame() %&gt;%\n    column_to_rownames(\"offender_type\") %&gt;%\n    as.matrix()\n  \n  # Ensure all columns exist\n  for (race in race_order) {\n    if (!race %in% colnames(race_matrix)) {\n      race_matrix &lt;- cbind(race_matrix, temp = 0)\n      colnames(race_matrix)[ncol(race_matrix)] &lt;- race\n    }\n  }\n  \n  # Reorder columns by volume\n  race_matrix &lt;- race_matrix[, as.character(race_order), drop = FALSE]\n  \n  # Format x-axis labels with \"k\" for thousands\n  max_x_race &lt;- max(rowSums(race_matrix))\n  x_breaks_race &lt;- pretty(c(0, max_x_race))\n  x_labels_race &lt;- ifelse(x_breaks_race &gt;= 1000, \n                         paste0(x_breaks_race/1000, \"k\"), \n                         as.character(x_breaks_race))\n  \n  barplot(t(race_matrix), \n          horiz = TRUE,\n          las = 1,\n          col = race_colors[colnames(race_matrix)],\n          main = 'Race Distribution',\n          xlab = 'Number of Profiles',\n          xaxt = 'n',  # Remove default x-axis\n          legend.text = FALSE)  # Don't show legend in plot area\n  \n  # Add custom x-axis with formatted labels\n  axis(1, at = x_breaks_race, labels = x_labels_race)\n  \n  # Add legend outside the plot area\n  legend(\"topright\", \n         legend = colnames(race_matrix), \n         fill = race_colors[colnames(race_matrix)],\n         bty = \"n\", \n         xpd = TRUE,  # Allow plotting outside main area\n         inset = c(-0.25, 0),  # Move legend to the right\n         cex = 0.8)\n  \n  title(paste(state_name, \"Demographic Distribution\"), outer = TRUE, cex.main = 1.5)\n}\n\n# ------------------------------------------------------------------\n# 20. Add state's metadata\n# ------------------------------------------------------------------\n\nadd_state_metadata &lt;- function(state_name, state_df) {\n  \n  raw_data &lt;- state_df %&gt;% filter(value_source == \"reported\")\n  offender_types_reported &lt;- unique(raw_data$offender_type)\n  \n  has_unknown &lt;- any(raw_data$variable_detailed == \"Unknown\", na.rm = TRUE)\n  has_other &lt;- any(raw_data$variable_detailed == \"Other\", na.rm = TRUE)\n  has_crosstab &lt;- any(raw_data$variable_category == \"gender_race\", na.rm = TRUE)\n  \n  nonstandard_terms &lt;- any(\n    grepl(\"All|Offenders\", raw_data$offender_type, ignore.case = TRUE),\n    grepl(\"Caucasian|African American| American Indian\", raw_data$variable_detailed, ignore.case = TRUE),\n    grepl(\"flag\", raw_data$variable_detailed, ignore.case = TRUE))\n  \n  new_row &lt;- tibble(\n    state = state_name,\n    race_data_provided = report_status(raw_data, \"race\"),\n    gender_data_provided = report_status(raw_data, \"gender\"),\n    total_profiles_provided = report_status(\n      raw_data %&gt;% filter(variable_category == \"total\"), \"total\"\n    ),\n    convicted_offender_reported = \"Convicted Offender\" %in% offender_types_reported,\n    arrestee_reported = \"Arrestee\" %in% offender_types_reported,\n    combined_reported = \"Combined\" %in% offender_types_reported,\n    has_unknown_category = has_unknown,\n    has_other_category = has_other,\n    uses_nonstandard_terminology = nonstandard_terms,\n    provides_crosstabulation = has_crosstab,\n    counts_sum_to_total = NA,\n    percentages_sum_to_100 = NA,\n    total_calculated_combined = !(\"Combined\" %in% offender_types_reported),\n    notes = \"\"\n  )\n  \n  foia_state_metadata &lt;&lt;- bind_rows(foia_state_metadata, new_row)\n  \n  cat(\"âœ“ Metadata added for:\", state_name, \"\\n\")\n  return(invisible(TRUE))\n}\n\n# ------------------------------------------------------------------\n# 21. Function to update a state's metadata after QC checks\n# ------------------------------------------------------------------\nupdate_state_metadata &lt;- function(state_name, \n                                  counts_ok = NA, \n                                  percentages_ok = NA, \n                                  notes_text = NULL) {\n  \n  row_index &lt;- which(foia_state_metadata$state == state_name)\n  \n  if (length(row_index) == 0) {\n    warning(\"State not found in metadata: \", state_name)\n    return(FALSE)\n  }\n  \n  if (!is.na(counts_ok)) {\n    foia_state_metadata$counts_sum_to_total[row_index] &lt;&lt;- counts_ok\n  }\n  if (!is.na(percentages_ok)) {\n    foia_state_metadata$percentages_sum_to_100[row_index] &lt;&lt;- percentages_ok\n  }\n  if (!is.null(notes_text)) {\n    current_notes &lt;- foia_state_metadata$notes[row_index]\n    if (current_notes == \"\") {\n      foia_state_metadata$notes[row_index] &lt;&lt;- notes_text\n    } else {\n      foia_state_metadata$notes[row_index] &lt;&lt;- paste(current_notes, notes_text, sep = \"; \")\n    }\n  }\n  \n  cat(\"âœ“ Metadata updated for:\", state_name, \"\\n\")\n}"
  },
  {
    "objectID": "analysis/foia_processing.html#file-structure-and-contents",
    "href": "analysis/foia_processing.html#file-structure-and-contents",
    "title": "FOIA Document OCR Processing",
    "section": "2.4 File Structure and Contents",
    "text": "2.4 File Structure and Contents\n\n2.4.1 State-Specific Files: per_state/[state]_foia_data.csv\nPurpose: Individual files for each state containing only their reported data.\nStructure: Long format with columns:\n\nstate: State name\noffender_type: Category of individuals (Convicted Offender, Arrestee, Combined, etc.)\nvariable_category: Type of data (total, gender, race, gender_race)\nvariable_detailed: Specific value (e.g., Male, Female, African American)\nvalue: The reported number or percentage\nvalue_type: Whether value is a â€œcountâ€ or â€œpercentageâ€\ndate: Date of data snapshot, if reported\n\n\n\nShow per-state files loading code\nca_raw &lt;- load_state(here(per_state, \"california_foia_data.csv\"))\nfl_raw &lt;- load_state(here(per_state, \"florida_foia_data.csv\"))\nin_raw &lt;- load_state(here(per_state, \"indiana_foia_data.csv\"))\nme_raw &lt;- load_state(here(per_state, \"maine_foia_data.csv\"))\nnv_raw &lt;- load_state(here(per_state, \"nevada_foia_data.csv\"))\nsd_raw &lt;- load_state(here(per_state, \"south_dakota_foia_data.csv\"))\ntx_raw &lt;- load_state(here(per_state, \"texas_foia_data.csv\"))\n\n\n\n\n2.4.2 Raw Data Characteristics\nThe following table summarizes the structure and content of the data as originally received from each state prior to any standardization, calculation, or processing.\n\n\n\n\n\n\n\n\n\n\n\nState\nOffender Types\nValue Types\nTotal Profiles\nAction Needed\nKey Reporting Notes\n\n\n\n\nCalifornia\nCO, A\nCounts only\nReported per offender type\nAdd Unknown Race, Calculate % & Combined, Standardize Terminology\nDiscrepancy in Race: counts &lt; total profiles; Non-standard terminology (Caucasian and African American)\n\n\nFlorida\nCOMB\nCounts + %\nReported\nStandardize Terminology\nNon-standard terminology (Caucasian and African American)\n\n\nIndiana\nCO, A, COMB\nPercentage (Counts for totals only)\nReported per offender type\nCalculate Counts & Total Profiles Combined, Fix % inconsistency, Standardize Terminology\nDemographics only for Combined; Other race category as â€œ&lt;1â€; Non-standard terminology (Caucasian)\n\n\nMaine\nCOMB\nCounts + %\nReported\nSolve counts and Percentage inconsistency\n\n\n\nNevada\nCO, A, COMB\nCounts + %\nReported for all types\nStandardize Terminology\nNon-standard terminology (All, total_flags and American Indian)\n\n\nSouth Dakota\nCOMB\nCounts + %\nReported\nStandardize Terminology, Solve counts and % inconsistency\nIncludes genderÃ—race cross-tabulation; Non-standard terminology\n\n\nTexas\nCO, A\nCounts only\nReported per offender type\nCalculate Male counts, Solve counts inconsistency, Calculate % & Combined, Standardize Terminology\nOnly female gender was reported; Non-standard term (Offenders, Caucasian, and African American)\n\n\n\nLegend:\n\nCO: Convicted Offender\nAR: Arrestee\nCOMB: Combined Total (all profiles)\nCounts + %: Both raw numbers and percentages were provided"
  },
  {
    "objectID": "analysis/foia_processing.html#prepare-combined-dataset",
    "href": "analysis/foia_processing.html#prepare-combined-dataset",
    "title": "FOIA Document OCR Processing",
    "section": "2.5 Prepare Combined Dataset",
    "text": "2.5 Prepare Combined Dataset\nThe goal of this step is to transform each stateâ€™s raw data into a standardized format before appending it to the master foia_combined DataFrame. This ensures consistency and enables seamless analysis across all seven states.\nThe ideal, standardized state dataset ready for combination must have the following columns:\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nExample Values\n\n\n\n\nstate\nThe name of the state.\n\"California\", \"Florida\"\n\n\noffender_type\nThe category of offender profile.\n\"Convicted Offender\", \"Arrestee\", \"Combined\"\n\n\nvariable_category\nThe broad demographic category.\n\"race\", \"gender\", \"total\", \"gender_race\"\n\n\nvariable_detailed\nThe specific value within the category.\n\"White\", \"Male\", \"total_profiles\", \"Male_White\"\n\n\nvalue\nThe numerical value for the metric.\n150000, 25.8\n\n\nvalue_type\nThe type of metric the value represents.\n\"count\", \"percentage\"\n\n\nvalue_source\nWhether the data was provided or derived.\n\"reported\", \"calculated\"\n\n\n\n\n\nShow the master foia_combined dataframe elaboration code\n# ------------------------------------------------------------------\n# Initialize the master foia_combined dataframe with correct schema\n# This empty structure ensures all state data is appended consistently\n# ------------------------------------------------------------------\n\n# Define the precise column schema for the final combined dataset\nfoia_combined &lt;- tibble(\n  state = character(),                # e.g., \"California\", \"Florida\"\n  offender_type = character(),        # e.g., \"Convicted Offender\", \"Arrestee\", \"Combined\"\n  variable_category = character(),    # e.g., \"race\", \"gender\", \"total\", \"gender_race\"\n  variable_detailed = character(),    # e.g., \"White\", \"Male\", \"total_profiles\", \"Male_White\"\n  value = numeric(),                  # e.g., 150000, 25.8\n  value_type = character(),           # e.g., \"count\", \"percentage\"\n  value_source = character()          # e.g., \"reported\", \"calculated\"\n)\n\n# Verify the initialized structure\ncat(\"âœ“ Initialized empty foia_combined dataframe with schema:\\n\\n\")\nstr(foia_combined)\n\n\nâœ“ Initialized empty foia_combined dataframe with schema:\n\ntibble [0 Ã— 7] (S3: tbl_df/tbl/data.frame)\n $ state            : chr(0) \n $ offender_type    : chr(0) \n $ variable_category: chr(0) \n $ variable_detailed: chr(0) \n $ value            : num(0) \n $ value_type       : chr(0) \n $ value_source     : chr(0)"
  },
  {
    "objectID": "analysis/foia_processing.html#prepare-metadata-documentation-table",
    "href": "analysis/foia_processing.html#prepare-metadata-documentation-table",
    "title": "FOIA Document OCR Processing",
    "section": "2.6 Prepare Metadata Documentation Table",
    "text": "2.6 Prepare Metadata Documentation Table\nThis section creates a comprehensive metadata table (foia_state_metadata) to document the original content and structure of each stateâ€™s FOIA response before any processing or cleaning was applied.\nThis serves as a permanent record of data provenance, ensuring transparency and reproducibility by clearly distinguishing between what was provided by the states and what was calculated during analysis.\nKey Documentation Captured:\n\nData Types Provided: Whether each state reported counts, percentages, or both for race, gender, and total profiles.\nOffender Categories Reported: Which offender types (Convicted Offender, Arrestee, Combined) were originally included.\nDemographic Granularity: Presence of â€˜Unknownâ€™ or â€˜Otherâ€™ categories and gender-race cross-tabulations.\nTerminology & Anomalies: Use of non-standard terms (e.g., â€œflags,â€ â€œoffendersâ€) and other state-specific reporting notes.\nQC Results: Flags for whether cleaned data passes consistency checks (counts sum to totals, percentages sum to ~100%).\n\n\n\nShow the foia_state_metadata table elaboration code\n# ------------------------------------------------------------------\n# Initialize the foia_state_metadata as a tibble (not a list of lists)\n# This makes it easier to add rows and ensures consistent structure.\n# ------------------------------------------------------------------\n\n# Define the full schema for our metadata table\nfoia_state_metadata &lt;- tibble(\n  state = character(),\n  # What data types were originally provided?\n  race_data_provided = character(),   # \"counts\", \"percentages\", \"both\", \"none\"\n  gender_data_provided = character(), # \"counts\", \"percentages\", \"both\", \"none\"\n  total_profiles_provided = character(), # \"counts\", \"percentages\", \"both\", \"none\"\n  # Which offender types were reported?\n  convicted_offender_reported = logical(),\n  arrestee_reported = logical(),\n  combined_reported = logical(),\n  # Data characteristics and caveats\n  has_unknown_category = logical(),\n  has_other_category = logical(),\n  uses_nonstandard_terminology = logical(),\n  provides_crosstabulation = logical(), # e.g., gender_race like South Dakota\n  # Data quality flags from processing\n  counts_sum_to_total = logical(),      # Did raw counts sum to the reported total?\n  percentages_sum_to_100 = logical(),   # Did raw percentages sum to ~100%?\n  # Calculated fields\n  total_calculated_combined = logical(), # Did we have to calculate the Combined total?\n  # Free-text notes for important state-specific details\n  notes = character()\n)\n\n# Verify the initialized structure\ncat(\"âœ“ Initialized empty foia_state_metadata dataframe with schema:\\n\\n\")\nstr(foia_state_metadata)\n\n\nâœ“ Initialized empty foia_state_metadata dataframe with schema:\n\ntibble [0 Ã— 15] (S3: tbl_df/tbl/data.frame)\n $ state                       : chr(0) \n $ race_data_provided          : chr(0) \n $ gender_data_provided        : chr(0) \n $ total_profiles_provided     : chr(0) \n $ convicted_offender_reported : logi(0) \n $ arrestee_reported           : logi(0) \n $ combined_reported           : logi(0) \n $ has_unknown_category        : logi(0) \n $ has_other_category          : logi(0) \n $ uses_nonstandard_terminology: logi(0) \n $ provides_crosstabulation    : logi(0) \n $ counts_sum_to_total         : logi(0) \n $ percentages_sum_to_100      : logi(0) \n $ total_calculated_combined   : logi(0) \n $ notes                       : chr(0)"
  },
  {
    "objectID": "analysis/foia_processing.html#california-ca",
    "href": "analysis/foia_processing.html#california-ca",
    "title": "FOIA Document OCR Processing",
    "section": "3.1 California (CA)",
    "text": "3.1 California (CA)\nOverview: California supplies counts only for gender and race plus a separate total for each offender type; no percentages are reported.\n\n3.1.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter1601Californiaoffender_typecharacter1602Convicted Offender, Arresteevariable_categorycharacter1603total, gender, racevariable_detailedcharacter1608total_profiles, Female, Male, Unknown, African American, Caucasian, Hispanic, Asianvaluenumeric160162019899 ..., 751822 ..., 309827 ..., 1603222 ..., 106850 ..., 208225 ..., 524231 ..., 19366 ..., 368952 ..., 588555 ...value_typecharacter1601countvalue_sourcecharacter1601reportedData frame dimensions: 16 rows Ã— 7 columns\n\n\n\n\n3.1.2 Verify Data Consistency\nRuns the first quality check using the verify_category_totals() and counts_consistent() functions.\nThis identifies any immediate discrepancies, such as the sum of demographic counts not matching the reported total profiles, which flags data issues that need to be resolved.\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nArrestee\ngender\n751822\n751822\n0\n\n\nArrestee\nrace\n751822\n655695\n96127\n\n\nConvicted Offender\ngender\n2019899\n2019899\n0\n\n\nConvicted Offender\nrace\n2019899\n1626012\n393887\n\n\n\n\n\n\nCounts consistency check on raw data:\n\n\nAll counts consistent: FALSE \n\n\n\n\n3.1.3 Address Data Gaps\n\n3.1.3.1 Create Unknown Category\n\nâ€œRacial classification is not considered a required field on the collection card; thus, an unknown number of offenders may have no racial classification listed.â€ â€” California DOJ FOIA letter, July 10 2018 (raw/foia_pdfs/FOIA_RacialComp_California.pdf)\n\nThe 393,887 Convicted Offender profiles and 96,127 Arrestee profiles that do not appear in any of the four reported race categories must belong to an unreported â€œUnknownâ€ category.\nThe calculated values are added with a value_source = \"calculated\" tag to maintain transparency about what was provided versus what was derived.\n\n\nShow unknown addition code\n# Start with the raw data\nca_clean &lt;- ca_raw\n\n# Add Unknown race category to reconcile totals\nca_clean &lt;- fill_demographic_gaps(ca_clean)\n\n# Verify the fix\ncat(\"Category totals after adding Unknown race category:\\n\")\nverify_category_totals(ca_clean) %&gt;% kable() %&gt;% kable_styling()\n\ncat(\"\\nCounts consistency after adding Unknown:\\n\")\ncat(paste(\"All counts consistent:\", counts_consistent(ca_clean), \"\\n\"))\n\n\nCategory totals after adding Unknown race category:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nArrestee\ngender\n751822\n751822\n0\n\n\nArrestee\nrace\n751822\n751822\n0\n\n\nConvicted Offender\ngender\n2019899\n2019899\n0\n\n\nConvicted Offender\nrace\n2019899\n2019899\n0\n\n\n\n\n\n\nCounts consistency after adding Unknown:\nAll counts consistent: TRUE \n\n\n\n\n3.1.3.2 Create Combined Totals\nSince California only reported data for â€œConvicted Offenderâ€ and â€œArresteeâ€ separately.\nThis step uses the add_combined() helper function to calculate a new â€œCombinedâ€ offender type by summing the counts from the other two categories.\n\n\nShow combined addition code\n# Calculate Combined totals using helper function\nca_clean &lt;- add_combined(ca_clean)\n\ncat(\"âœ“ Created Combined totals for California\\n\")\n\n# Show the Combined total\ncombined_total &lt;- ca_clean %&gt;%\n  filter(offender_type == \"Combined\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\") %&gt;%\n  pull(value)\n\ncat(paste(\"Combined total profiles:\", format(combined_total, big.mark = \",\"), \"\\n\"))\n\n\nâœ“ Created Combined totals for California\nCombined total profiles: 2,771,721 \n\n\n\n\n3.1.3.3 Calculate Percentages\nTransforms the data from counts into percentages for comparative analysis.\nThe add_percentages() helper function calculates each demographic groupâ€™s proportion relative to its offender typeâ€™s total.\nA final consistency check ensures all percentages logically sum to approximately 100%.\n\n\nShow percentage calculation code\n# Derive percentages from counts\nca_clean &lt;- add_percentages(ca_clean)\n\ncat(\"âœ“ Added percentages for all demographic categories\\n\")\n\n# Check percentage consistency\ncat(\"Percentage consistency check:\\n\")\ncat(paste(\"All percentages sum to ~100%:\", percentages_consistent(ca_clean), \"\\n\\n\"))\n\n# Show current data availability\ncat(\"Final data availability:\\n\")\ncat(paste(\"Race data:\", report_status(ca_clean, \"race\"), \"\\n\"))\ncat(paste(\"Gender data:\", report_status(ca_clean, \"gender\"), \"\\n\"))\n\n\nâœ“ Added percentages for all demographic categories\nPercentage consistency check:\nAll percentages sum to ~100%: TRUE \n\nFinal data availability:\nRace data: both \nGender data: both \n\n\n\n\n3.1.3.4 Standardize Terminology\nCalifornia uses â€œAfrican Americanâ€ instead of â€œBlackâ€ and â€œCaucasianâ€ instead of â€œWhiteâ€.\n\n\nShow terminology standardization code\n# Standardize racial terminology\nca_clean &lt;- ca_clean %&gt;%\n  mutate(variable_detailed = case_when(\n    variable_detailed == \"African American\" ~ \"Black\",\n    TRUE ~ variable_detailed\n  ))\n\ncat(\"âœ“ Standardized terminology: 'African American' â†’ 'Black'\\n\")\n\nca_clean &lt;- ca_clean %&gt;%\n  mutate(variable_detailed = case_when(\n    variable_detailed == \"Caucasian\" ~ \"White\",\n    TRUE ~ variable_detailed\n  ))\n\ncat(\"âœ“ Standardized terminology: 'Caucasian' â†’ 'White'\\n\")\n\n\nâœ“ Standardized terminology: 'African American' â†’ 'Black'\nâœ“ Standardized terminology: 'Caucasian' â†’ 'White'\n\n\n\n\n\n3.1.4 Prepare for Combined Dataset\nThe cleaned data is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow California data preparation to combined dataset\n# Prepare the cleaned data for the combined dataset\nca_prepared &lt;- prepare_state_for_combined(ca_clean, \"California\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, ca_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(ca_prepared), \" California rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 51 California rows to foia_combined\nâœ“ Total rows in foia_combined: 51\n\n\n\n\n3.1.5 Document Metadata\nThe metadata is added with the raw information and updated with the results of the quality checks and a note on the processing steps taken.\n\n\nShow California data preparation and addition to metadata table\n# Add California to the metadata table using the helper function\nadd_state_metadata(\"California\", ca_raw)\n\n# Update metadata with QC results\nupdate_state_metadata(\"California\", \n                      counts_ok = counts_consistent(ca_clean),\n                      percentages_ok = percentages_consistent(ca_clean),\n                      notes_text = \"Added Unknown race category to reconcile totals; calculated Combined totals and all percentages\")\n\n\nâœ“ Metadata added for: California \nâœ“ Metadata updated for: California \n\n\n\n\n3.1.6 Visualizations\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\nCalifornia DNA Database Demographic Distributions\n\n\n\n\n\n\n\n\n\nCalifornia Demographic Distributions by Offender Type\n\n\n\n\n\n\n3.1.7 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"California DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"California\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness\ncat(\"\\nData completeness:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"California\") %&gt;%\n  group_by(offender_type, value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"California\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"California\")), \"\\n\"))\n\n\nCalifornia DNA Database Summary:\n= ======================================== \n# A tibble: 3 Ã— 3\n  offender_type        value value_formatted\n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;          \n1 Convicted Offender 2019899 \"2,019,899\"    \n2 Arrestee            751822 \"  751,822\"    \n3 Combined           2771721 \"2,771,721\"    \n\nData completeness:\n# A tibble: 5 Ã— 3\n  offender_type      value_source n_values\n  &lt;chr&gt;              &lt;chr&gt;           &lt;int&gt;\n1 Arrestee           calculated          9\n2 Arrestee           reported            8\n3 Combined           calculated         17\n4 Convicted Offender calculated          9\n5 Convicted Offender reported            8\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.1.8 Summary of California Processing\nCalifornia data processing complete. The dataset now includes:\n\nâœ… Reported data: Counts for Convicted Offender and Arrestee\nâœ… Calculated additions:\n\nUnknown race category to reconcile reported totals\nCombined totals across all offender types\nPercentage values for all demographic categories\nâ€œCaucasianâ€ and â€œAfrican Americanâ€ converted to â€œWhiteâ€ and â€œBlackâ€.\n\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: All values include appropriate value_source indicators\n\nThe California data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#florida-fl",
    "href": "analysis/foia_processing.html#florida-fl",
    "title": "FOIA Document OCR Processing",
    "section": "3.2 Florida (FL)",
    "text": "3.2 Florida (FL)\nOverview: Florida provides both counts and percentages for gender and race categories and already includes a â€œCombinedâ€ total for all offender types, making it one of the most complete and straightforward datasets.\nOnly requires to standardize terminology for gender and race categories to match the common data model.\n\n3.2.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter2201Floridaoffender_typecharacter2201Combinedvariable_categorycharacter2203total, gender, racevariable_detailedcharacter22010total_profiles, Female, Male, Unknown, African American, Asian, Caucasian, Hispanic, Native American, Othervaluenumeric220221175391 ..., 100 ..., 260885 ..., 22.2 ..., 901126 ..., 76.67 ..., 13380 ..., 1.14 ..., 413733 ..., 35.2 ...value_typecharacter2202count, percentagevalue_sourcecharacter2201reportedData frame dimensions: 22 rows Ã— 7 columns\n\n\n\n\n3.2.2 Verify Data Consistency\nRuns the first quality check using the Verify_category_totals() and counts_consistent() functions.\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n1175391\n1175391\n0\n\n\nCombined\nrace\n1175391\n1175391\n0\n\n\n\n\n\n\nCounts consistency check on raw data:\n\n\nAll counts consistent: TRUE \n\n\n\nPercentage consistency check on raw data:\n\n\nAll percentages sum to ~100%: TRUE \n\n\n\n\n3.2.3 Address Data Gaps\n\n3.2.3.1 Standardize Terminology\nFlorida uses â€œAfrican Americanâ€ instead of â€œBlackâ€ and â€œCaucasianâ€ instead of â€œWhiteâ€.\n\n\nShow terminology standardization code\nfl_clean &lt;- fl_raw\n\n# Standardize racial terminology\nfl_clean &lt;- fl_clean %&gt;%\n  mutate(variable_detailed = case_when(\n    variable_detailed == \"African American\" ~ \"Black\",\n    TRUE ~ variable_detailed\n  ))\n\ncat(\"âœ“ Standardized terminology: 'African American' â†’ 'Black'\\n\")\n\nfl_clean &lt;- fl_clean %&gt;%\n  mutate(variable_detailed = case_when(\n    variable_detailed == \"Caucasian\" ~ \"White\",\n    TRUE ~ variable_detailed\n  ))\n\ncat(\"âœ“ Standardized terminology: 'Caucasian' â†’ 'White'\\n\")\n\n\nâœ“ Standardized terminology: 'African American' â†’ 'Black'\nâœ“ Standardized terminology: 'Caucasian' â†’ 'White'\n\n\n\n\n\n3.2.4 Prepare for Combined Dataset\nThe Florida data is already complete and consistent. It is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow Florida data preparation to combined dataset\n# Prepare the data for the combined dataset\nfl_prepared &lt;- prepare_state_for_combined(fl_clean, \"Florida\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, fl_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(fl_prepared), \" Florida rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 22 Florida rows to foia_combined\nâœ“ Total rows in foia_combined: 73\n\n\n\n\n3.2.5 Document Metadata\nThe metadata is added with a note that the data was complete and required no processing.\n\n\nShow Florida data preparation and addition to metadata table\n# Add Florida to the metadata table using the helper function\nadd_state_metadata(\"Florida\", fl_raw)\n\n# Update metadata with QC results\nupdate_state_metadata(\"Florida\", \n                      counts_ok = counts_consistent(fl_clean),\n                      percentages_ok = percentages_consistent(fl_clean),\n                      notes_text = \"Complete dataset provided. No processing or calculations required. All values are reported.\")\n\n\nâœ“ Metadata added for: Florida \nâœ“ Metadata updated for: Florida \n\n\n\n\n3.2.6 Visualizations\n\n\n\n\n\nFlorida DNA Database Demographic Distributions\n\n\n\n\n\n\n\nFlorida DNA Database Demographic Distributions\n\n\n\n\n\n\n\nFlorida DNA Database Demographic Distributions\n\n\n\n\n\n\n\nFlorida DNA Database Demographic Distributions\n\n\n\n\n\n\n3.2.7 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"Florida DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"Florida\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness\ncat(\"\\nData completeness:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"Florida\") %&gt;%\n  group_by(offender_type, value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"Florida\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"Florida\")), \"\\n\"))\n\n\nFlorida DNA Database Summary:\n= ======================================== \n# A tibble: 1 Ã— 3\n  offender_type   value value_formatted\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Combined      1175391 1,175,391      \n\nData completeness:\n# A tibble: 1 Ã— 3\n  offender_type value_source n_values\n  &lt;chr&gt;         &lt;chr&gt;           &lt;int&gt;\n1 Combined      reported           22\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.2.8 Summary of Florida Processing\nFlorida data processing complete. The dataset is exemplary and required no adjustments:\n\nâœ… Reported data: Both counts and percentages for all Convicted Offender, Arrestee, and Combined categories.\nâœ… Terminology standardization: â€œCaucasianâ€ and â€œAfrican Americanâ€ converted to â€œWhiteâ€ and â€œBlackâ€.\nâœ… No calculated additions needed: All values are sourced directly from the state report (value_source = \"reported\").\nâœ… Quality checks: All counts and percentages pass consistency validation.\nâœ… Provenance tracking: All values maintain their original value_source as â€œreportedâ€.\n\nThe Florida data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#indiana-in",
    "href": "analysis/foia_processing.html#indiana-in",
    "title": "FOIA Document OCR Processing",
    "section": "3.3 Indiana (IN)",
    "text": "3.3 Indiana (IN)\nOverview: Indiana presents a unique reporting pattern where total counts are provided by offender type, but demographic breakdowns are given only as percentages for the Combined total.\nValues were provided as strings, including a â€œ&lt;1â€ notation, requiring conversion.\n\n3.3.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter801Indianaoffender_typecharacter803Convicted Offender, Arrestee, Combinedvariable_categorycharacter803total, gender, racevariable_detailedcharacter807total_profiles, Female, Male, Caucasian, Black, Hispanic, Othervaluenumeric808279654, 21087, 20, 80, 70, 26, 4, 0.5value_typecharacter802count, percentagevalue_sourcecharacter801reportedData frame dimensions: 8 rows Ã— 7 columns\n\n\n\n\n3.3.2 Verify Data Consistency\nInitial checks reveal Indianaâ€™s unique structure: counts for totals, percentages only for Combined demographics.\n\n\nInitial data availability:\n\n\nRace data: percentages \n\n\nGender data: percentages \n\n\n\nValue types in raw data:\n\n\ncount, percentage\n\n\n\n\n3.3.3 Address Data Gaps\n\n3.3.3.1 Convert String Values to Numeric\nThe raw data contains string values including â€œ&lt;1â€ which we convert to 0.5.\n\n\nShow value conversion code\n# Start with raw data\nin_clean &lt;- in_raw\n\n# Convert string values to numeric, handling \"&lt;1\" as 1\nin_clean$value &lt;- sapply(in_clean$value, function(x) {\n  if (x == \"&lt;1\") {\n    0.5\n  } else {\n    as.numeric(x)\n  }\n})\n\n# Update value_type for converted percentages\nin_clean &lt;- in_clean %&gt;%\n  mutate(value_type = ifelse(value_type == \"percentage\", \"percentage\", value_type))\n\ncat(\"âœ“ Converted Indiana values from String to numeric\\n\")\ncat(paste(\"Unique values after conversion:\", paste(unique(in_clean$value), collapse = \", \"), \"\\n\"))\n\n\nâœ“ Converted Indiana values from String to numeric\nUnique values after conversion: 279654, 21087, 20, 80, 70, 26, 4, 0.5 \n\n\n\n\n3.3.3.2 Solve Percentages Inconsistency\nRacial percentages summed to 100.5% instead of 100%\nProportional scaling was applied and value_source was updated to â€œcalculatedâ€ for all adjusted values.\n\n\nShow percentage recalculation code\n# Adjust percentages to ensure they sum to 100% and mark as calculated\nin_clean &lt;- in_clean %&gt;%\n  group_by(value_type, variable_category) %&gt;%\n  mutate(\n    value = ifelse(\n      value_type == \"percentage\" & variable_category == \"race\",\n      value * (100 / sum(value, na.rm = TRUE)),\n      value\n    ),\n    value_source = ifelse(\n      value_type == \"percentage\" & variable_category == \"race\",\n      \"calculated\",\n      value_source\n    )\n  ) %&gt;%\n  ungroup()\n\n# Verify the new sum\npercentage_sum &lt;- in_clean %&gt;%\n  filter(value_type == \"percentage\" & variable_category == \"race\") %&gt;%\n  summarise(total = sum(value, na.rm = TRUE))\n\ncat(\"âœ“ Recalculated percentages for Indiana - New sum:\", percentage_sum$total, \"%\\n\")\n\n\nâœ“ Recalculated percentages for Indiana - New sum: 100 %\n\n\n\n\n3.3.3.3 Standardize Terminology\nIndiana uses â€œCaucasianâ€ instead of â€œWhiteâ€.\n\n\nShow terminology standardization code\n# Standardize racial terminology\nin_clean &lt;- in_clean %&gt;%\n  mutate(variable_detailed = case_when(\n    variable_detailed == \"Caucasian\" ~ \"White\",\n    TRUE ~ variable_detailed\n  ))\n\ncat(\"âœ“ Standardized terminology: 'Caucasian' â†’ 'White'\\n\")\n\n\nâœ“ Standardized terminology: 'Caucasian' â†’ 'White'\n\n\n\n\n3.3.3.4 Create Combined Total Profiles\nIndiana provides separate totals for Convicted Offenders and Arrestees, but we need a Combined total to match the demographic percentages.\n\n\nShow combined total calculation code\n# Calculate Combined total from separate offender type totals\nconvicted_total &lt;- in_clean %&gt;%\n  filter(offender_type == \"Convicted Offender\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\") %&gt;%\n  pull(value)\n\narrestee_total &lt;- in_clean %&gt;%\n  filter(offender_type == \"Arrestee\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\") %&gt;%\n  pull(value)\n\ncombined_total &lt;- convicted_total + arrestee_total\n\n# Add Combined total to the data\ncombined_row &lt;- data.frame(\n  state = \"Indiana\",\n  offender_type = \"Combined\",\n  variable_category = \"total\",\n  variable_detailed = \"total_profiles\",\n  value = combined_total,\n  value_type = \"count\",\n  value_source = \"calculated\"\n)\n\nin_clean &lt;- bind_rows(in_clean, combined_row)\n\ncat(paste(\"Combined total profiles:\", format(combined_total, big.mark = \",\"), \"\\n\"))\ncat(\"âœ“ Added Combined total profiles\\n\")\n\n\nCombined total profiles: 300,741 \nâœ“ Added Combined total profiles\n\n\n\n\n3.3.3.5 Calculate Counts from Percentages\nIndiana only provides percentages for demographic categories. We calculate the actual counts using the Combined total.\n\n\nShow count calculation code\n# Calculate counts from percentages for Combined offender type\nin_clean &lt;- bind_rows(in_clean, calculate_counts_from_percentages(in_clean, \"Indiana\"))\n\ncat(\"âœ“ Calculated demographic counts from percentages\\n\")\n\n# Verify the calculations\ncat(\"Category totals after calculating counts:\\n\")\nverify_category_totals(in_clean) %&gt;% kable() %&gt;% kable_styling()\n\n\nâœ“ Calculated demographic counts from percentages\nCategory totals after calculating counts:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n300741\n300741\n0\n\n\nCombined\nrace\n300741\n300741\n0\n\n\n\n\n\n\n\n\n3.3.4 Verify Data Consistency\nFinal checks to ensure all data is now consistent and complete.\n\n\nFinal data consistency checks:\n\n\nCounts consistent: TRUE \n\n\nPercentages consistent: TRUE \n\n\n\nFinal data availability:\n\n\nRace data: both \n\n\nGender data: both \n\n\n\n\n3.3.5 Prepare for Combined Dataset\nThe cleaned data is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow Indiana data preparation to combined dataset\n# Prepare the cleaned data for the combined dataset\nin_prepared &lt;- prepare_state_for_combined(in_clean, \"Indiana\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, in_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(in_prepared), \" Indiana rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 15 Indiana rows to foia_combined\nâœ“ Total rows in foia_combined: 88\n\n\n\n\n3.3.6 Document Metadata\nThe metadata is added with details on all processing steps performed.\n\n\nShow Indiana data preparation and addition to metadata table\n# Add Indiana to the metadata table using the helper function\nadd_state_metadata(\"Indiana\", in_raw)\n\n# Update metadata with QC results and processing notes\nupdate_state_metadata(\"Indiana\", \n                      counts_ok = counts_consistent(in_clean),\n                      percentages_ok = percentages_consistent(in_clean),\n                      notes_text = \"Converted string values to numeric; standardized 'Black' to 'African American'; calculated Combined total profiles; derived all demographic counts from reported percentages\")\n\n\nâœ“ Metadata added for: Indiana \nâœ“ Metadata updated for: Indiana \n\n\n\n\n3.3.7 Visualizations\n\n\n\n\n\nIndiana DNA Database Demographic Distributions\n\n\n\n\n\n\n\nIndiana DNA Database Demographic Distributions\n\n\n\n\n\n\n\nIndiana DNA Database Demographic Distributions\n\n\n\n\n\n\n\nIndiana DNA Database Demographic Distributions\n\n\n\n\n\n\n3.3.8 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"Indiana DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"Indiana\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value, value_source) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness by value source\ncat(\"\\nData completeness by source:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"Indiana\") %&gt;%\n  group_by(value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"Indiana\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"Indiana\")), \"\\n\"))\n\n\nIndiana DNA Database Summary:\n= ======================================== \n# A tibble: 3 Ã— 4\n  offender_type       value value_source value_formatted\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;          \n1 Convicted Offender 279654 reported     \"279,654\"      \n2 Arrestee            21087 reported     \" 21,087\"      \n3 Combined           300741 calculated   \"300,741\"      \n\nData completeness by source:\n# A tibble: 2 Ã— 2\n  value_source n_values\n  &lt;chr&gt;           &lt;int&gt;\n1 calculated         11\n2 reported            4\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.3.9 Summary of Indiana Processing\nIndiana data processing complete. The unique dataset required:\n\nâœ… Data conversion: String values converted to numeric, handling â€œ&lt;1â€ as 0.5\nâœ… Terminology standardization: â€œCaucasianâ€ converted to â€œWhiteâ€\nâœ… Calculated additions:\n\nCombined total profiles across offender types\nAll demographic counts derived from reported percentages\n\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: Clear distinction between reported and calculated values\n\nThe Indiana data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#maine-me",
    "href": "analysis/foia_processing.html#maine-me",
    "title": "FOIA Document OCR Processing",
    "section": "3.4 Maine (ME)",
    "text": "3.4 Maine (ME)\nOverview: Maine provides comprehensive reporting with both counts and percentages for all gender and race categories across all offender types, including pre-calculated Combined totals. The data is complete and requires no processing.\n\n3.4.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter1901Maineoffender_typecharacter1901Combinedvariable_categorycharacter1903total, gender, racevariable_detailedcharacter1909total_profiles, Male, Female, Unknown, White, Black, Native American, Hispanic, Asianvaluenumeric1901933711 ..., 27694 ..., 82.7 ..., 5734 ..., 17 ..., 83 ..., 0.2 ..., 31298 ..., 92.8 ..., 1299 ...value_typecharacter1902count, percentagevalue_sourcecharacter1901reportedData frame dimensions: 19 rows Ã— 7 columns\n\n\n\n\n3.4.2 Verify Data Consistency\nRuns quality checks using the verify_category_totals(), counts_consistent(), and percentages_consistent() functions.\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n33711\n33511\n200\n\n\nCombined\nrace\n33711\n33711\n0\n\n\n\n\n\n\nCounts consistency check on raw data:\n\n\nAll counts consistent: FALSE \n\n\n\nPercentage consistency check on raw data:\n\n\nAll percentages sum to ~100%: TRUE \n\n\n\n\n3.4.3 Address Data Gaps\n\n3.4.3.1 Solve Percentages Inconsistency\nRacial percentages summed to 99.9% instead of 100%\nProportional scaling was applied and value_source was updated to â€œcalculatedâ€ for all adjusted values.\n\n\nShow percentage recalculation code\n# Start with the raw data\nme_clean &lt;- me_raw\n\n# Adjust percentages to ensure they sum to 100% and mark as calculated\nme_clean &lt;- me_clean %&gt;%\n  group_by(value_type, variable_category) %&gt;%\n  mutate(\n    value = ifelse(\n      value_type == \"percentage\" & variable_category == \"gender\",\n      value * (100 / sum(value, na.rm = TRUE)),\n      value\n    ),\n    value_source = ifelse(\n      value_type == \"percentage\" & variable_category == \"gender\",\n      \"calculated\",\n      value_source\n    )\n  ) %&gt;%\n  ungroup()\n\n# Verify the new sum\npercentage_sum &lt;- me_clean %&gt;%\n  filter(value_type == \"percentage\" & variable_category == \"gender\") %&gt;%\n  summarise(total = sum(value, na.rm = TRUE))\n\ncat(\"âœ“ Recalculated percentages for Maine - New sum:\", round(percentage_sum$total, 2), \"%\\n\")\n\n\nâœ“ Recalculated percentages for Maine - New sum: 100 %\n\n\n\n\n3.4.3.2 Recalculate Counts from Percentages\nMaineâ€™s reported gender counts sum were inconsistent with the total_profiles.\nWe removed existing gender count data and recalculated counts using percentage values and combined totals.\nAll recalculated values flagged with value_source = \"calculated\"\n\n\nShow count recalculation code\n# Remove existing gender count rows to avoid duplication\nme_clean &lt;- me_clean %&gt;%\n  filter(!(variable_category == \"gender\" & value_type == \"count\"))\n\ncat(\"âœ“ Removed existing gender count data\\n\")\n\nme_gender &lt;- me_clean %&gt;%\n    filter(variable_category == \"gender\" | variable_category == \"total\")\n\n# Calculate counts from percentages for Combined offender type\nme_gender &lt;- calculate_counts_from_percentages(me_gender, \"Maine\")\n\n# Append recalculated gender counts to the main dataset\nme_clean &lt;- bind_rows(me_clean, me_gender)\n\ncat(\"âœ“ Calculated demographic counts from percentages\\n\")\n\n# Verify the calculations\ncat(\"Category totals after calculating counts:\\n\")\nverify_category_totals(me_clean) %&gt;% kable() %&gt;% kable_styling()\n\n\nâœ“ Removed existing gender count data\nâœ“ Calculated demographic counts from percentages\nCategory totals after calculating counts:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n33711\n33711\n0\n\n\nCombined\nrace\n33711\n33711\n0\n\n\n\n\n\n\n\n\n3.4.4 Verify Data Consistency\nFinal checks to ensure all data is now consistent and complete.\n\n\nFinal data consistency checks:\n\n\nCounts consistent: TRUE \n\n\nPercentages consistent: TRUE \n\n\n\nFinal data availability:\n\n\nRace data: both \n\n\nGender data: both \n\n\n\n\n3.4.5 Prepare for Combined Dataset\nThe Maine data is already complete and consistent. It is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow Maine data preparation to combined dataset\n# Prepare the data for the combined dataset\nme_prepared &lt;- prepare_state_for_combined(me_clean, \"Maine\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, me_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(me_prepared), \" Maine rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 19 Maine rows to foia_combined\nâœ“ Total rows in foia_combined: 107\n\n\n\n\n3.4.6 Document Metadata\nThe metadata is added with a note that the data was complete and required no processing.\n\n\nShow Maine data preparation and addition to metadata table\n# Add Maine to the metadata table using the helper function\nadd_state_metadata(\"Maine\", me_raw)\n\n# Update metadata with QC results\nupdate_state_metadata(\"Maine\", \n                      counts_ok = counts_consistent(me_clean),\n                      percentages_ok = percentages_consistent(me_clean),\n                      notes_text = \"Complete dataset provided with both counts and percentages. No processing or calculations required. All values are reported.\")\n\n\nâœ“ Metadata added for: Maine \nâœ“ Metadata updated for: Maine \n\n\n\n\n3.4.7 Visualizations\n\n\n\n\n\nMaine DNA Database Demographic Distributions\n\n\n\n\n\n\n\nMaine DNA Database Demographic Distributions\n\n\n\n\n\n\n\nMaine DNA Database Demographic Distributions\n\n\n\n\n\n\n\nMaine DNA Database Demographic Distributions\n\n\n\n\n\n\n3.4.8 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"Maine DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"Maine\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness\ncat(\"\\nData completeness:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"Maine\") %&gt;%\n  group_by(offender_type, value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"Maine\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"Maine\")), \"\\n\"))\n\n\nMaine DNA Database Summary:\n= ======================================== \n# A tibble: 1 Ã— 3\n  offender_type value value_formatted\n  &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;          \n1 Combined      33711 33,711         \n\nData completeness:\n# A tibble: 2 Ã— 3\n  offender_type value_source n_values\n  &lt;chr&gt;         &lt;chr&gt;           &lt;int&gt;\n1 Combined      calculated          6\n2 Combined      reported           13\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.4.9 Summary of Maine Processing\nMaine data processing complete. The dataset is exemplary and required no adjustments:\n\nâœ… Reported data: Both counts and percentages for all Convicted Offender, Arrestee, and Combined categories\nâœ… No calculated additions needed: All values are sourced directly from the state report (value_source = \"reported\")\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: All values maintain their original value_source as â€œreportedâ€\n\nThe Maine data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#nevada-nv",
    "href": "analysis/foia_processing.html#nevada-nv",
    "title": "FOIA Document OCR Processing",
    "section": "3.5 Nevada (NV)",
    "text": "3.5 Nevada (NV)\nOverview: Nevada provides both counts and percentages for gender and race categories but uses non-standard terminology that requires conversion for consistency with our schema.\n\n3.5.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter2101Nevadaoffender_typecharacter2104All, Arrestee, Convicted Offender, Combinedvariable_categorycharacter2103total, gender, racevariable_detailedcharacter2109total_flags, total_profiles, Female, Male, Unknown, White, American Indian, Black, Asianvaluenumeric21021344097 ..., 185074 ..., 53.785 ..., 159023 ..., 46.215 ..., 63287 ..., 18.392 ..., 280738 ..., 81.587 ..., 72 ...value_typecharacter2102count, percentagevalue_sourcecharacter2101reportedData frame dimensions: 21 rows Ã— 7 columns\n\n\n\n\n3.5.2 Verify Data Consistency\nInitial check reveals Nevadaâ€™s non-standard terminology.\n\n\nInitial data availability:\n\n\nRace data: both \n\n\nGender data: both \n\n\n\nNon-standard terminology found:\n\n\nOffender types: All, Arrestee, Convicted Offender, Combined \n\n\n\n\n3.5.3 Address Data Gaps\n\n3.5.3.1 Standardize Terminology\nNevada uses â€œAllâ€ instead of â€œCombinedâ€, â€œtotal_flagsâ€ instead of â€œtotal_profilesâ€ and â€œAmerican Indianâ€ instead of â€œNative Americanâ€.\n\n\nShow terminology standardization code\n# Start with raw data\nnv_clean &lt;- nv_raw\n\n# Standardize offender types and racial terminology\nnv_clean &lt;- nv_clean %&gt;%\n  mutate(\n    offender_type = case_when(\n      offender_type == \"All\" ~ \"Combined\",\n      TRUE ~ offender_type\n    ),\n    variable_detailed = case_when(\n      variable_detailed == \"total_flags\" ~ \"total_profiles\",\n      TRUE ~ variable_detailed\n    ),\n    variable_detailed = case_when(\n      variable_detailed == \"American Indian\" ~ \"Native American\",\n      TRUE ~ variable_detailed\n    )\n  )\n\ncat(\"âœ“ Standardized terminology:\\n\")\ncat(\"  - 'All' â†’ 'Combined'\\n\")\ncat(\"  - 'total_flags' â†’ 'total_profiles'\\n\")\ncat(\"  - 'American Indian' â†’ 'Native American'\\n\")\n\n\nâœ“ Standardized terminology:\n  - 'All' â†’ 'Combined'\n  - 'total_flags' â†’ 'total_profiles'\n  - 'American Indian' â†’ 'Native American'\n\n\n\n\n3.5.3.2 Verify Consistency\nNow that the offender types are standardized, we can verify the counts and percentages.\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n344097\n344097\n0\n\n\nCombined\nrace\n344097\n344097\n0\n\n\n\n\n\n\nCounts consistency check on raw data:\n\n\nAll counts consistent: TRUE \n\n\n\nPercentage consistency check on raw data:\n\n\nAll percentages sum to ~100%: TRUE \n\n\nSum of 'race' percentages: 100 %\n\n\nSum of 'gender' percentages: 100 %\n\n\n\n\n\n3.5.4 Prepare for Combined Dataset\nThe cleaned data is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow Nevada data preparation to combined dataset\n# Prepare the cleaned data for the combined dataset\nnv_prepared &lt;- prepare_state_for_combined(nv_clean, \"Nevada\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, nv_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(nv_prepared), \" Nevada rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 21 Nevada rows to foia_combined\nâœ“ Total rows in foia_combined: 128\n\n\n\n\n3.5.5 Document Metadata\nThe metadata is added with details on the terminology standardization performed.\n\n\nShow Nevada data preparation and addition to metadata table\n# Add Nevada to the metadata table using the helper function\nadd_state_metadata(\"Nevada\", nv_raw)\n\n# Update metadata with QC results and processing notes\nupdate_state_metadata(\"Nevada\", \n                      counts_ok = counts_consistent(nv_clean),\n                      percentages_ok = percentages_consistent(nv_clean),\n                      notes_text = \"Standardized terminology: 'All' to 'Combined' and 'American Indian' to 'Native American'. All values remain reported.\")\n\n\nâœ“ Metadata added for: Nevada \nâœ“ Metadata updated for: Nevada \n\n\n\n\n3.5.6 Visualizations\n\n\n\n\n\nNevada DNA Database Demographic Distributions\n\n\n\n\n\n\n\nNevada DNA Database Demographic Distributions\n\n\n\n\n\n\n\nNevada DNA Database Demographic Distributions\n\n\n\n\n\n\n\nNevada DNA Database Demographic Distributions\n\n\n\n\n\n\n3.5.7 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"Nevada DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"Nevada\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness\ncat(\"\\nData completeness:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"Nevada\") %&gt;%\n  group_by(offender_type, value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"Nevada\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"Nevada\")), \"\\n\"))\n\n\nNevada DNA Database Summary:\n= ======================================== \n# A tibble: 3 Ã— 3\n  offender_type       value value_formatted\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;          \n1 Combined           344097 344,097        \n2 Arrestee           185074 185,074        \n3 Convicted Offender 159023 159,023        \n\nData completeness:\n# A tibble: 3 Ã— 3\n  offender_type      value_source n_values\n  &lt;chr&gt;              &lt;chr&gt;           &lt;int&gt;\n1 Arrestee           reported            2\n2 Combined           reported           17\n3 Convicted Offender reported            2\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: FALSE \n\n\n\n\n3.5.8 Summary of Nevada Processing\nNevada data processing complete. The dataset required minimal adjustments:\n\nâœ… Terminology standardization:\n\nâ€œAllâ€ â†’ â€œCombinedâ€ (offender type)\nâ€œAmerican Indianâ€ â†’ â€œNative Americanâ€ (race category)\n\nâœ… Reported data: Both counts and percentages for all categories\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: All values maintain value_source = \"reported\" as only terminology changes were made\n\nThe Nevada data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#south-dakota-sd",
    "href": "analysis/foia_processing.html#south-dakota-sd",
    "title": "FOIA Document OCR Processing",
    "section": "3.6 South Dakota (SD)",
    "text": "3.6 South Dakota (SD)\nOverview: South Dakota provides the most comprehensive reporting with both counts and percentages for all standard categories plus unique intersectional genderÃ—race data. Minor terminology standardization is required for consistency.\n\n3.6.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter4101South Dakotaoffender_typecharacter4101Combinedvariable_categorycharacter4104total, gender, race, gender_racevariable_detailedcharacter41021total_profiles ..., Male ..., Female ..., Asian ..., Black ..., Hispanic ..., Native American ..., Other/Unknown ..., White/Caucasian ..., Male_Asian ...valuenumeric4103867753 ..., 51197 ..., 75.56 ..., 16556 ..., 24.44 ..., 5 ..., 0.08 ..., 4041 ..., 5.96 ..., 2949 ...value_typecharacter4102count, percentagevalue_sourcecharacter4101reportedData frame dimensions: 41 rows Ã— 7 columns\n\n\n\n\n3.6.2 Gender-race intersection analysis\nSince South Dakota is the only state that reported gender-race intersection data, we can analyze it in detail.\n\n\n\n\n\n\nSouth Dakota Intersectional Gender Ã— Race Analysis\n\n\n\n\n\n\n\n3.6.3 Verify Data Consistency\nInitial check reveals South Dakotaâ€™s comprehensive data structure with some non-standard terminology.\n\n\nInitial data availability:\n\n\nRace data: both \n\n\nGender data: both \n\n\n\nNon-standard terminology found:\n\n\nRace terms: Asian, Black, Hispanic, Native American, Other/Unknown, White/Caucasian \n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n67753\n67753\n0\n\n\nCombined\nrace\n67753\n67702\n51\n\n\n\n\n\n\nCounts consistency check on raw data:\n\n\nAll counts consistent: FALSE \n\n\n\nPercentage consistency check on raw data:\n\n\nAll percentages sum to ~100%: TRUE \n\n\nSum of 'race' percentages: 100 %\n\n\nSum of 'gender' percentages: 100 %\n\n\n\n\n3.6.4 Address Data Gaps\n\n3.6.4.1 Standardize Terminology\nSouth Dakota uses â€œWhite/Caucasianâ€ and â€œOther/Unknownâ€ which need standardization.\n\n\nShow terminology standardization code\n# Standardize racial terminology\nsd_clean &lt;- sd_clean %&gt;%\n  mutate(\n    variable_detailed = case_when(\n      variable_detailed == \"White/Caucasian\" ~ \"White\",\n      variable_detailed == \"Other/Unknown\" ~ \"Unknown\",\n      TRUE ~ variable_detailed\n    )\n  )\n\ncat(\"âœ“ Standardized terminology:\\n\")\ncat(\"  - 'White/Caucasian' â†’ 'White'\\n\")\ncat(\"  - 'Other/Unknown' â†’ 'Unknown'\\n\")\n\n# Verify the changes\ncat(\"\\nRace categories after standardization:\\n\")\nsd_clean %&gt;%\n  filter(variable_category == \"race\") %&gt;%\n  distinct(variable_detailed) %&gt;%\n  pull() %&gt;%\n  paste(collapse = \", \") %&gt;%\n  cat()\n\n\nâœ“ Standardized terminology:\n  - 'White/Caucasian' â†’ 'White'\n  - 'Other/Unknown' â†’ 'Unknown'\n\nRace categories after standardization:\nAsian, Black, Hispanic, Native American, Unknown, White\n\n\n\n\n3.6.4.2 Recalculate Counts from Percentages\nSouth Dakotaâ€™s reported race counts sum were inconsistent with the total_profiles.\nWe removed existing gender count data and recalculated counts using percentage values and combined totals.\nAll recalculated values flagged with value_source = \"calculated\"\n\n\nShow count recalculation code\n# Remove existing gender count rows to avoid duplication\nsd_clean &lt;- sd_clean %&gt;%\n  filter(!(variable_category == \"race\" & value_type == \"count\"))\n\ncat(\"âœ“ Removed existing race count data\\n\")\n\nsd_race &lt;- sd_clean %&gt;%\n    filter(variable_category == \"race\" | variable_category == \"total\")\n\n# Calculate counts from percentages for Combined offender type\nsd_race &lt;- calculate_counts_from_percentages(sd_race, \"South Dakota\")\n\n# Append recalculated race counts to the main dataset\nsd_clean &lt;- bind_rows(sd_clean, sd_race)\n\ncat(\"âœ“ Calculated demographic counts from percentages\\n\")\n\n# Verify the calculations\ncat(\"Category totals after calculating counts:\\n\")\nverify_category_totals(sd_clean) %&gt;% kable() %&gt;% kable_styling()\n\n\nâœ“ Removed existing race count data\nâœ“ Calculated demographic counts from percentages\nCategory totals after calculating counts:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n67753\n67753\n0\n\n\nCombined\nrace\n67753\n67752\n1\n\n\n\n\n\nWe handled this diffence of 1 by adding it to the most representative race (White).\n\n\nShow difference handle code\n# Handle the difference of 1 by adding it to the most representative race\nsd_clean &lt;- sd_clean %&gt;%\n  mutate(value = ifelse(variable_detailed == \"White\" & value_type == \"count\", value + 1, value))\n\n\n\n\n\n3.6.5 Verify Data Consistency\nFinal checks to ensure standardization didnâ€™t affect data integrity.\n\n\nFinal data consistency checks after standardization:\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nCombined\ngender\n67753\n67753\n0\n\n\nCombined\nrace\n67753\n67753\n0\n\n\n\n\n\n\nCounts consistency check:\n\n\nAll counts consistent: TRUE \n\n\n\nPercentage consistency check:\n\n\nAll percentages sum to ~100%: TRUE \n\n\n\n\n3.6.6 Prepare for Combined Dataset\nThe cleaned data is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow South Dakota data preparation to combined dataset\n# Prepare the cleaned data for the combined dataset\nsd_prepared &lt;- prepare_state_for_combined(sd_clean, \"South Dakota\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, sd_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(sd_prepared), \" South Dakota rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n# Show the comprehensive nature of South Dakota's data\ncat(\"\\nSouth Dakota's comprehensive data structure:\\n\")\nsd_prepared %&gt;%\n  group_by(variable_category) %&gt;%\n  summarise(n_rows = n(), .groups = \"drop\") %&gt;%\n  kable() %&gt;% kable_styling()\n\n\nâœ“ Appended 17 South Dakota rows to foia_combined\nâœ“ Total rows in foia_combined: 145\n\nSouth Dakota's comprehensive data structure:\n\n\n\n\n\nvariable_category\nn_rows\n\n\n\n\ngender\n4\n\n\nrace\n12\n\n\ntotal\n1\n\n\n\n\n\n\n\n3.6.7 Document Metadata\nThe metadata is added with details on South Dakotaâ€™s comprehensive reporting and the terminology standardization performed.\n\n\nShow South Dakota data preparation and addition to metadata table\n# Add South Dakota to the metadata table using the helper function\nadd_state_metadata(\"South Dakota\", sd_raw)\n\n# Update metadata with QC results and processing notes\nupdate_state_metadata(\"South Dakota\", \n                      counts_ok = counts_consistent(sd_clean),\n                      percentages_ok = percentages_consistent(sd_clean),\n                      notes_text = \"Standardized terminology: 'White/Caucasian' to 'White' and 'Other/Unknown' to 'Unknown'. Includes comprehensive gender_race intersectional data. All values remain reported.\")\n\n\nâœ“ Metadata added for: South Dakota \nâœ“ Metadata updated for: South Dakota \n\n\n\n\n3.6.8 Visualizations\n\n\n\n\n\nSouth Dakota DNA Database Demographic Distributions\n\n\n\n\n\n\n\nSouth Dakota DNA Database Demographic Distributions\n\n\n\n\n\n\n\nSouth Dakota DNA Database Demographic Distributions\n\n\n\n\n\n\n\nSouth Dakota DNA Database Demographic Distributions\n\n\n\n\n\n\n3.6.9 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"South Dakota DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"South Dakota\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness by category\ncat(\"\\nData completeness by category:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"South Dakota\") %&gt;%\n  group_by(variable_category) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"South Dakota\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"South Dakota\")), \"\\n\"))\n\n\nSouth Dakota DNA Database Summary:\n= ======================================== \n# A tibble: 1 Ã— 3\n  offender_type value value_formatted\n  &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;          \n1 Combined      67753 67,753         \n\nData completeness by category:\n# A tibble: 3 Ã— 2\n  variable_category n_values\n  &lt;chr&gt;                &lt;int&gt;\n1 gender                   4\n2 race                    12\n3 total                    1\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.6.10 Summary of South Dakota Processing\nSouth Dakota data processing complete. The state provided exemplary data with minimal adjustments needed:\n\nâœ… Terminology standardization:\n\nâ€œWhite/Caucasianâ€ â†’ â€œWhiteâ€\nâ€œOther/Unknownâ€ â†’ â€œUnknownâ€\n\nâœ… Comprehensive reporting: Standard demographics plus unique genderÃ—race intersectional data\nâœ… Reported data: Both counts and percentages for all categories\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: All values maintain value_source = \"reported\" as only terminology changes were made\n\nSouth Dakotaâ€™s data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#texas-tx",
    "href": "analysis/foia_processing.html#texas-tx",
    "title": "FOIA Document OCR Processing",
    "section": "3.7 Texas (TX)",
    "text": "3.7 Texas (TX)\nOverview: Texas provides counts only for gender and race categories. The Male gender is missing in the dataset. The state uses non-standard terminology that requires conversion and needs Combined totals and percentages calculated.\n\n3.7.1 Examine Raw Data\nEstablish a baseline understanding of the data exactly as it was received.\n\n\nColumnTypeRowsMissingUniqueUnique_Valuesstatecharacter1601Texasoffender_typecharacter1602Offenders, Arresteevariable_categorycharacter1603total, gender, racevariable_detailedcharacter1608total_profiles, Female, Asian, African American, Caucasian, Hispanic, Native American, Othervaluenumeric16016845322 ..., 73631 ..., 121434 ..., 18721 ..., 3361 ..., 254366 ..., 309010 ..., 276245 ..., 138 ..., 2173 ...value_typecharacter1601countvalue_sourcecharacter1601reportedData frame dimensions: 16 rows Ã— 7 columns\n\n\n\n\n3.7.2 Verify Data Consistency\nInitial checks reveal Texasâ€™s reporting structure and terminology differences.\n\n\nInitial data availability:\n\n\nRace data: counts \n\n\nGender data: counts \n\n\n\nNon-standard terminology found:\n\n\nOffender types: Offenders, Arrestee \n\n\nRace terms: Asian, African American, Caucasian, Hispanic, Native American, Other \n\n\n\n\n3.7.3 Address Data Gaps\n\n3.7.3.1 Add Missing Male category\nTexas data reports only Female counts explicitly. We calculated Male counts by subtracting Female counts from total profiles, assuming binary gender classification in the dataset.\n\n\nShow male addition code\n# First, let's examine the current structure of gender data\ngender_data &lt;- tx_raw %&gt;%\n  filter(variable_category == \"gender\")\n\ncat(\"Current gender structure:\\n\")\nprint(unique(gender_data$variable_detailed))\n\n# Get total profiles for each offender type\ntotal_profiles &lt;- tx_raw %&gt;%\n  filter(variable_category == \"total\" & variable_detailed == \"total_profiles\") %&gt;%\n  select(offender_type, total_value = value)\n\n# Join total profiles with gender data\ngender_with_totals &lt;- gender_data %&gt;%\n  left_join(total_profiles, by = \"offender_type\")\n\n# Create Male entries for each offender type\nmale_entries &lt;- gender_with_totals %&gt;%\n  filter(variable_detailed == \"Female\") %&gt;%\n  mutate(\n    variable_detailed = \"Male\",\n    value = total_value - value, \n    value_source = \"calculated\",\n    total_value = NULL \n  )\n\n# Add these entries to the original dataset\ntx_raw_with_male &lt;- tx_raw %&gt;%\n  bind_rows(male_entries)\n\n# Update the tx_raw object\ntx_clean &lt;- tx_raw_with_male\n\n# Verify the addition\ncat(\"\\nAfter adding Male entries - gender categories:\\n\")\nprint(unique(tx_clean %&gt;% \n       filter(variable_category == \"gender\") %&gt;% \n       pull(variable_detailed)))\n\n\nCurrent gender structure:\n[1] \"Female\"\n\nAfter adding Male entries - gender categories:\n[1] \"Female\" \"Male\"  \n\n\n\n\n3.7.3.2 Standardize Terminology\nTexas uses â€œOffendersâ€ instead of â€œConvicted Offenderâ€ and â€œCaucasianâ€ instead of â€œWhiteâ€.\n\n\nShow terminology standardization code\n# Standardize offender types and racial terminology\ntx_clean &lt;- tx_clean %&gt;%\n  mutate(\n    offender_type = case_when(\n      offender_type == \"Offenders\" ~ \"Convicted Offender\",\n      TRUE ~ offender_type\n    ),\n    variable_detailed = case_when(\n      variable_detailed == \"Caucasian\" ~ \"White\",\n      variable_detailed == \"African American\" ~ \"Black\",\n      TRUE ~ variable_detailed\n    )\n  )\n\ncat(\"âœ“ Standardized terminology:\\n\")\ncat(\"  - 'Offenders' â†’ 'Convicted Offender'\\n\")\ncat(\"  - 'Caucasian' â†’ 'White'\\n\")\ncat(\"  - 'African American' â†’ 'Black'\\n\")\ncat(paste(\"Offender types after standardization:\", paste(sort(unique(tx_clean$offender_type)), collapse = \", \"), \"\\n\"))\n\n\nâœ“ Standardized terminology:\n  - 'Offenders' â†’ 'Convicted Offender'\n  - 'Caucasian' â†’ 'White'\n  - 'African American' â†’ 'Black'\nOffender types after standardization: Arrestee, Convicted Offender \n\n\n\n\n3.7.3.3 Create Unknown Category\nTexas race count is inconsistent, with a significant number of profiles not reported in any racial category.\nUnknown category was created to account for these missing profiles.\nThe calculated values are added with a value_source = \"calculated\" tag to maintain transparency about what was provided versus what was derived.\n\n\nShow unknown addition code\n# Add Unknown race category to reconcile totals\ntx_clean &lt;- fill_demographic_gaps(tx_clean)\n\n# Verify the fix\ncat(\"Category totals after adding Unknown race category:\\n\")\nverify_category_totals(tx_clean) %&gt;% kable() %&gt;% kable_styling()\n\ncat(\"\\nCounts consistency after adding Unknown:\\n\")\ncat(paste(\"All counts consistent:\", counts_consistent(tx_clean), \"\\n\"))\n\n\nCategory totals after adding Unknown race category:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nArrestee\ngender\n73631\n73631\n0\n\n\nArrestee\nrace\n73631\n73631\n0\n\n\nConvicted Offender\ngender\n845322\n845322\n0\n\n\nConvicted Offender\nrace\n845322\n845322\n0\n\n\n\n\n\n\nCounts consistency after adding Unknown:\nAll counts consistent: TRUE \n\n\n\n\n3.7.3.4 Create Combined Totals\nTexas only reported data for â€œConvicted Offenderâ€ and â€œArresteeâ€ separately. We calculate Combined totals.\n\n\nShow combined addition code\n# Calculate Combined totals using helper function\ntx_clean &lt;- add_combined(tx_clean)\n\ncat(\"âœ“ Created Combined totals for Texas\\n\")\n\n# Show the Combined total\ncombined_total &lt;- tx_clean %&gt;%\n  filter(offender_type == \"Combined\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\") %&gt;%\n  pull(value)\n\ncat(paste(\"Combined total profiles:\", format(combined_total, big.mark = \",\"), \"\\n\"))\n\n\nâœ“ Created Combined totals for Texas\nCombined total profiles: 918,953 \n\n\n\n\n3.7.3.5 Calculate Percentages\nTransforms the data from counts into percentages for comparative analysis.\n\n\nShow percentage calculation code\n# Derive percentages from counts\ntx_clean &lt;- add_percentages(tx_clean)\n\ncat(\"âœ“ Added percentages for all demographic categories\\n\")\n\n# Check percentage consistency\ncat(\"Percentage consistency check:\\n\")\ncat(paste(\"All percentages sum to ~100%:\", percentages_consistent(tx_clean), \"\\n\\n\"))\n\n# Show current data availability\ncat(\"Final data availability:\\n\")\ncat(paste(\"Race data:\", report_status(tx_clean, \"race\"), \"\\n\"))\ncat(paste(\"Gender data:\", report_status(tx_clean, \"gender\"), \"\\n\"))\n\n\nâœ“ Added percentages for all demographic categories\nPercentage consistency check:\nAll percentages sum to ~100%: TRUE \n\nFinal data availability:\nRace data: both \nGender data: both \n\n\n\n\n\n3.7.4 Verify Data Consistency\nFinal checks to ensure all processing maintained data integrity.\n\n\nFinal data consistency checks:\n\n\nVerifying that demographic counts match reported totals:\n\n\n\n\n\noffender_type\nvariable_category\ntotal_profiles\nsum_counts\ndifference\n\n\n\n\nArrestee\ngender\n73631\n73631\n0\n\n\nArrestee\nrace\n73631\n73631\n0\n\n\nCombined\ngender\n918953\n918953\n0\n\n\nCombined\nrace\n918953\n918953\n0\n\n\nConvicted Offender\ngender\n845322\n845322\n0\n\n\nConvicted Offender\nrace\n845322\n845322\n0\n\n\n\n\n\n\nCounts consistency check:\n\n\nAll counts consistent: TRUE \n\n\n\nPercentage consistency check:\n\n\nAll percentages sum to ~100%: TRUE \n\n\n\n\n3.7.5 Prepare for Combined Dataset\nThe cleaned data is formatted to match the master schema and appended to the foia_combined dataframe.\n\n\nShow Texas data preparation to combined dataset\n# Prepare the cleaned data for the combined dataset\ntx_prepared &lt;- prepare_state_for_combined(tx_clean, \"Texas\")\n\n# Append to the master combined dataframe\nfoia_combined &lt;- bind_rows(foia_combined, tx_prepared)\n\ncat(paste0(\"âœ“ Appended \", nrow(tx_prepared), \" Texas rows to foia_combined\\n\"))\ncat(paste0(\"âœ“ Total rows in foia_combined: \", nrow(foia_combined), \"\\n\"))\n\n\nâœ“ Appended 57 Texas rows to foia_combined\nâœ“ Total rows in foia_combined: 202\n\n\n\n\n3.7.6 Document Metadata\nThe metadata is added with details on all processing steps performed.\n\n\nShow Texas data preparation and addition to metadata table\n# Add Texas to the metadata table using the helper function\nadd_state_metadata(\"Texas\", tx_raw)\n\n# Update metadata with QC results and processing notes\nupdate_state_metadata(\"Texas\", \n                      counts_ok = counts_consistent(tx_clean),\n                      percentages_ok = percentages_consistent(tx_clean),\n                      notes_text = \"Standardized terminology: 'Offenders' to 'Convicted Offender', 'Caucasian' to 'White', 'African American' to 'Black'; calculated Combined totals and all percentages\")\n\n\nâœ“ Metadata added for: Texas \nâœ“ Metadata updated for: Texas \n\n\n\n\n3.7.7 Visualizations\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\nTexas DNA Database Demographic Distributions\n\n\n\n\n\n\n\n\n\nTexas Demographic Distributions by Offender Type\n\n\n\n\n\n\n3.7.8 Summary Statistics\n\n\nShow the summary statistics code\ncat(\"Texas DNA Database Summary:\\n\")\ncat(\"=\", strrep(\"=\", 40), \"\\n\")\n\n# Total profiles by offender type\ntotals &lt;- foia_combined %&gt;%\n  filter(state == \"Texas\",\n         variable_category == \"total\",\n         variable_detailed == \"total_profiles\",\n         value_type == \"count\") %&gt;%\n  select(offender_type, value, value_source) %&gt;%\n  mutate(value_formatted = format(value, big.mark = \",\"))\n\nprint(totals)\n\n# Data completeness by value source\ncat(\"\\nData completeness by source:\\n\")\ncompleteness &lt;- foia_combined %&gt;%\n  filter(state == \"Texas\") %&gt;%\n  group_by(value_source) %&gt;%\n  summarise(n_values = n(), .groups = \"drop\")\n\nprint(completeness)\n\n# Final verification\ncat(\"\\nFinal verification:\\n\")\ncat(paste(\"Counts consistent:\", counts_consistent(foia_combined %&gt;% filter(state == \"Texas\")), \"\\n\"))\ncat(paste(\"Percentages consistent:\", percentages_consistent(foia_combined %&gt;% filter(state == \"Texas\")), \"\\n\"))\n\n\nTexas DNA Database Summary:\n= ======================================== \n# A tibble: 3 Ã— 4\n  offender_type       value value_source value_formatted\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;          \n1 Convicted Offender 845322 reported     \"845,322\"      \n2 Arrestee            73631 reported     \" 73,631\"      \n3 Combined           918953 calculated   \"918,953\"      \n\nData completeness by source:\n# A tibble: 2 Ã— 2\n  value_source n_values\n  &lt;chr&gt;           &lt;int&gt;\n1 calculated         41\n2 reported           16\n\nFinal verification:\nCounts consistent: TRUE \nPercentages consistent: TRUE \n\n\n\n\n3.7.9 Summary of Texas Processing\nTexas data processing complete. The dataset required several adjustments:\n\nâœ… Male Category Addition:\n\nâ€œMaleâ€ added to variable_detailed\n\nâœ… Terminology standardization:\n\nâ€œOffendersâ€ â†’ â€œConvicted Offenderâ€\nâ€œCaucasianâ€ â†’ â€œWhiteâ€\nâ€œAfrican Americanâ€ â†’ â€œBlackâ€\n\nâœ… Calculated additions:\n\nCombined totals across all offender types\nPercentage values for all demographic categories\n\nâœ… Quality checks: All counts and percentages pass consistency validation\nâœ… Provenance tracking: Clear distinction between reported and calculated values\n\nThe Texas data is now standardized and ready for cross-state analysis."
  },
  {
    "objectID": "analysis/foia_processing.html#combined-dataset",
    "href": "analysis/foia_processing.html#combined-dataset",
    "title": "FOIA Document OCR Processing",
    "section": "3.8 Combined Dataset",
    "text": "3.8 Combined Dataset"
  },
  {
    "objectID": "analysis/foia_processing.html#metadata-table",
    "href": "analysis/foia_processing.html#metadata-table",
    "title": "FOIA Document OCR Processing",
    "section": "3.9 Metadata table",
    "text": "3.9 Metadata table"
  }
]